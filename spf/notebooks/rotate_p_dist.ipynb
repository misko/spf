{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "def rotate_dist(input_dist: torch.Tensor, rotations: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Rotate discrete distributions defined over angles -pi to +pi by the\n",
    "    specified rotations (in radians).\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    input_dist : (B, 65) tensor\n",
    "        Each row is a discrete distribution over 65 equally spaced angles in [-pi, pi].\n",
    "    rotations : (B,) or (B, 1) tensor\n",
    "        The rotation (in radians) for each distribution in the batch.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    rotated : (B, 65) tensor\n",
    "        The input distributions rotated by the specified angles (with interpolation).\n",
    "    \"\"\"\n",
    "\n",
    "    rotations = rotations.view(-1)  # Make sure rotations has shape (B,)\n",
    "\n",
    "    B, n_bins = input_dist.shape\n",
    "    assert n_bins == 65, \"Expected distributions of size 65 along axis=1.\"\n",
    "\n",
    "    # 1) Define the angle grid for the 65 bins\n",
    "    # angles = torch.linspace(-math.pi, math.pi, steps=n_bins, device=input_dist.device)\n",
    "    dtheta = 2.0 * math.pi / n_bins  # 2π / 65\n",
    "    angles = (\n",
    "        torch.arange(n_bins, device=input_dist.device, dtype=input_dist.dtype) * dtheta\n",
    "    )\n",
    "\n",
    "    # Bin width\n",
    "    bin_width = angles[1] - angles[0]  # ~ 2*pi/64\n",
    "\n",
    "    # 2) For each bin j in [0..64], the \"rotated\" angle is angles[j] - rotation.\n",
    "    angles_2d = angles.unsqueeze(0)  # shape (1, 65)\n",
    "    rotations_2d = rotations.unsqueeze(1)  # shape (B, 1)\n",
    "\n",
    "    # (B, 65)\n",
    "    target_angles = angles_2d - rotations_2d  # %(2*torch.pi)\n",
    "\n",
    "    # 3) Convert these target angles to float indices in [0..64]\n",
    "    float_indices = torch.round(\n",
    "        (target_angles - angles[0]) / bin_width, decimals=4\n",
    "    )  # shape (B, 65)\n",
    "\n",
    "    # 4) Floor to get lower bin index, then +1 for upper bin\n",
    "    idx0 = torch.floor(float_indices).long()  # can be negative\n",
    "    idx1 = idx0 + 1\n",
    "\n",
    "    # Wrap both with modulo 65\n",
    "    idx0_mod = idx0 % n_bins\n",
    "    idx1_mod = idx1 % n_bins\n",
    "\n",
    "    # 5) Interpolation weights\n",
    "    w1 = float_indices - idx0.float()\n",
    "    w0 = 1.0 - w1\n",
    "\n",
    "    # 6) Gather the corresponding values from input_dist\n",
    "    dist_gather_0 = input_dist.gather(1, idx0_mod)\n",
    "    dist_gather_1 = input_dist.gather(1, idx1_mod)\n",
    "\n",
    "    # 7) Linear interpolation\n",
    "    rotated = w0 * dist_gather_0 + w1 * dist_gather_1\n",
    "\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Fake data: random distributions of size (B,65)\n",
    "# We'll normalize them to sum to 1 across each row just for demonstration.\n",
    "p = torch.rand(batch_size, 65) ** 10\n",
    "p = p / p.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Random rotations in [-pi, pi]\n",
    "alpha = 2 * math.pi * torch.rand(batch_size) - math.pi\n",
    "alpha = alpha * 0 + math.pi\n",
    "\n",
    "q = rotate_dist(p, alpha)\n",
    "\n",
    "print(\"p shape:\", p.shape)  # (8, 65)\n",
    "print(\"alpha shape:\", alpha.shape)  # (8,)\n",
    "print(\"q shape:\", q.shape)  # (8, 65)\n",
    "\n",
    "# q is the rotated distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.remainder(torch.tensor(1), torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test for 2π identity\n",
    "\n",
    "B = 4\n",
    "N = 65\n",
    "\n",
    "# Make four \"one-hot\" distributions, each peaking in a different bin\n",
    "p_test = torch.zeros(B, N)\n",
    "p_test[0, 0] = 1.0  # peak in bin 0\n",
    "p_test[1, 30] = 1.0\n",
    "p_test[2, 64] = 1.0\n",
    "p_test[3, 10] = 1.0\n",
    "\n",
    "alpha_2pi = torch.full((B,), 2.0 * math.pi, dtype=torch.float32)\n",
    "\n",
    "q_test = rotate_distributions(p_test, alpha_2pi)\n",
    "\n",
    "# They should match p_test exactly (barring any tiny floating error).\n",
    "print(\"Original p:\")\n",
    "print(p_test)\n",
    "print(\"Rotated by 2π -> q:\")\n",
    "print(q_test)\n",
    "print(\"Difference:\")\n",
    "print((q_test - p_test).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
