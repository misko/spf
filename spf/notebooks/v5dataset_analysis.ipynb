{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "ds = v5spfdataset(\n",
    "    # \"/mnt/md2/rovers/merged_test/rover_2025_03_29_16_16_59_nRX2_center_spacing0p043_tag_RO3.rover_2025_03_29_16_11_30_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    # \"/mnt/md2/rovers/merged/rover_2025_03_29_16_14_54_nRX2_diamond_spacing0p035_tag_RO1.rover_2025_03_29_16_11_30_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    \"/mnt/md2/rovers/merged/rover_2025_03_22_19_55_11_nRX2_diamond_spacing0p035_tag_RO1.rover_2025_03_22_19_55_02_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    # \"/mnt/md2/rovers/merged/rover_2025_03_29_16_14_54_nRX2_diamond_spacing0p035_tag_RO1.rover_2025_03_29_16_11_30_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    # \"/mnt/md2/rovers/merged/rover_2025_03_29_17_34_29_nRX2_diamond_spacing0p035_tag_RO1.rover_2025_03_29_17_34_21_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    # \"/mnt/md2/2d_wallarray_v2_data/march_nuand/wallarrayv3_2025_03_29_19_03_59_nRX2_rx_random_circle_spacing0p025.zarr\",\n",
    "    # \"/mnt/md2/2d_wallarray_v2_data/march/wallarrayv3_2025_03_15_11_18_30_nRX2_rx_random_circle_spacing0p043.zarr\",\n",
    "    # \"/mnt/md2/2d_wallarray_v2_data/march_nuand/wallarrayv3_2025_03_29_14_52_33_nRX2_rx_random_circle_spacing0p025.zarr\",\n",
    "    nthetas=65,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/mnt/md2/cache/precompute_cache_3p5_chunk1/\",\n",
    "    gpu=True,\n",
    "    snapshots_per_session=1,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    segmentation_version=3.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tx_pos = np.vstack([ds.z.receivers.r0.tx_pos_x_mm, ds.z.receivers.r0.tx_pos_y_mm])\n",
    "rx_pos = np.vstack([ds.z.receivers.r0.rx_pos_x_mm, ds.z.receivers.r0.rx_pos_y_mm])\n",
    "dists = np.sqrt((rx_pos - tx_pos) ** 2).sum(axis=0)\n",
    "\n",
    "\n",
    "start_idx = 10\n",
    "end_idx = min(6000, len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "step = int((end_idx - start_idx) / 40)\n",
    "sessions = [ds[idx][0] for idx in range(start_idx, end_idx, step)]\n",
    "\n",
    "axs[0].scatter(\n",
    "    [session[\"tx_pos_x_mm\"] for session in sessions],\n",
    "    [session[\"tx_pos_y_mm\"] for session in sessions],\n",
    "    label=\"tx\",\n",
    ")\n",
    "axs[0].scatter(\n",
    "    [session[\"rx_pos_x_mm\"] for session in sessions],\n",
    "    [session[\"rx_pos_y_mm\"] for session in sessions],\n",
    "    label=\"rx\",\n",
    ")\n",
    "axs[0].set_ylabel(\"x_position(mm)\")\n",
    "axs[0].set_xlabel(\"y_position(mm)\")\n",
    "axs[0].set_title(\"Position plot\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot([session[\"tx_pos_x_mm\"] for session in sessions], label=\"tx_x\")\n",
    "axs[1].plot([session[\"tx_pos_y_mm\"] for session in sessions], label=\"tx_y\")\n",
    "axs[1].plot([session[\"rx_pos_x_mm\"] for session in sessions], label=\"rx_x\")\n",
    "axs[1].plot([session[\"rx_pos_y_mm\"] for session in sessions], label=\"rx_y\")\n",
    "axs[1].plot(rx_pos[0][start_idx:end_idx:step], label=\"rx_xx\")\n",
    "axs[1].set_title(\"Position vs time\")\n",
    "axs[1].set_ylabel(\"value\")\n",
    "axs[1].set_xlabel(\"sample_idx (time)\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from spf.rf import torch_pi_norm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# show the beamformer vs expected\n",
    "\n",
    "\n",
    "def normalize(x, dim):\n",
    "    # return x\n",
    "    # return x / x.sum(axis=dim, keepdims=True)\n",
    "    return x / x.max(axis=dim, keepdims=True)\n",
    "\n",
    "\n",
    "for rx_idx in range(2):\n",
    "    fig, axs = plt.subplots(5, 1, figsize=(14, 10))\n",
    "\n",
    "    fig.suptitle(f\"{os.path.basename(ds.zarr_fn)}:{start_idx}-{end_idx}\")\n",
    "    ax_idx = 0\n",
    "    axs[ax_idx].set_title(f\"rx_idx{rx_idx} : theta\")\n",
    "    axs[ax_idx].plot(\n",
    "        ds.ground_truth_thetas[rx_idx][start_idx:end_idx], label=\"ground truth\"\n",
    "    )\n",
    "    axs[ax_idx].plot(ds.absolute_thetas[rx_idx][start_idx:end_idx], label=\"absolute\")\n",
    "    axs[ax_idx].plot(\n",
    "        torch_pi_norm(\n",
    "            ds.cached_keys[rx_idx][\"rx_heading_in_pis\"][start_idx:end_idx] * torch.pi\n",
    "        ),\n",
    "        label=\"rx_heading\",\n",
    "    )\n",
    "    axs[ax_idx].plot(\n",
    "        ds.cached_keys[rx_idx][\"rx_theta_in_pis\"][start_idx:end_idx] * torch.pi,\n",
    "        label=\"rx_theta\",\n",
    "    )\n",
    "    axs[ax_idx].set_yticks([-torch.pi, 0, torch.pi], [\"-pi\", \"0\", \"pi\"])\n",
    "    axs[ax_idx].legend()\n",
    "    axs[ax_idx].set_xlim([0, end_idx - start_idx])\n",
    "    ax_idx += 1\n",
    "\n",
    "    axs[ax_idx].set_title(f\"rx_idx{rx_idx} : windowed beamformer\")\n",
    "    x = normalize(\n",
    "        ds.precomputed_zarr[f\"r{rx_idx}\"].windowed_beamformer[:].astype(np.float32),\n",
    "        2,\n",
    "    ).mean(axis=1)[start_idx:end_idx]\n",
    "    x /= x.sum(axis=1, keepdims=True)\n",
    "    axs[ax_idx].imshow(x.T, origin=\"lower\", aspect=\"auto\")\n",
    "    axs[ax_idx].set_yticks([0, 32, 64], [\"-pi\", \"0\", \"pi\"])\n",
    "    ax_idx += 1\n",
    "\n",
    "    axs[ax_idx].set_title(f\"rx_idx{rx_idx} : dist rx to tx\")\n",
    "    axs[ax_idx].plot(dists[start_idx:end_idx])\n",
    "    axs[ax_idx].set_xlim([0, end_idx - start_idx])\n",
    "    ax_idx += 1\n",
    "\n",
    "    axs[ax_idx].set_title(f\"rx_idx{rx_idx} : gain\")\n",
    "    axs[ax_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].gains[start_idx:end_idx, 0],\n",
    "        label=f\"R{rx_idx}-Gain0\",\n",
    "    )\n",
    "    axs[ax_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].gains[start_idx:end_idx, 1],\n",
    "        label=f\"R{rx_idx}-Gain1\",\n",
    "    )\n",
    "    axs[ax_idx].set_xlim([0, end_idx - start_idx])\n",
    "    axs[ax_idx].legend()\n",
    "    ax_idx += 1\n",
    "\n",
    "    axs[ax_idx].set_title(f\"rx_idx{rx_idx} : RSSI\")\n",
    "    axs[ax_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].rssis[start_idx:end_idx, 0],\n",
    "        label=f\"R{rx_idx}-RSSI0\",\n",
    "    )\n",
    "    axs[ax_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].rssis[start_idx:end_idx, 1],\n",
    "        label=f\"R{rx_idx}-RSSI1\",\n",
    "    )\n",
    "    axs[ax_idx].set_xlim([0, end_idx - start_idx])\n",
    "    axs[ax_idx].legend()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.sdrpluto.detrend import detrend_np\n",
    "from spf.rf import beamformer_given_steering_nomean, get_phase_diff\n",
    "import matplotlib.pyplot as plt\n",
    "from spf.dataset.segmentation import default_segment_args, simple_segment\n",
    "\n",
    "# look at radio rx_idx\n",
    "rx_idx = 0\n",
    "# load up the session_idx'th buffer in this recording and plot parts of it\n",
    "session_idx = 4\n",
    "offset = 0  # offset inside of buffer\n",
    "\n",
    "data = ds[session_idx][rx_idx]\n",
    "\n",
    "n = data[\"signal_matrix\"].shape[3]\n",
    "\n",
    "#\n",
    "raw_radio_values = detrend_np(\n",
    "    data[\"signal_matrix\"][0, 0, :, offset : offset + n].numpy()\n",
    ")\n",
    "phase_difference = get_phase_diff(raw_radio_values)\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 6))\n",
    "fig.suptitle(\n",
    "    f\"Raw signal + Phase offsets: {os.path.basename(ds.zarr_fn)} rx_idx{rx_idx} sessionidx:{session_idx}\"\n",
    ")\n",
    "axs[0].scatter(np.arange(n), np.abs(raw_radio_values[0]), alpha=0.1, s=1, label=\"ant0\")\n",
    "axs[0].scatter(np.arange(n), raw_radio_values[0].real, alpha=0.1, s=1, label=\"ant0 r\")\n",
    "axs[0].scatter(np.arange(n), raw_radio_values[0].imag, alpha=0.1, s=1, label=\"ant0 i\")\n",
    "axs[0].set_title(\"Raw signal ant0\")\n",
    "axs[1].scatter(np.arange(n), np.abs(raw_radio_values[1]), alpha=0.1, s=1, label=\"ant0\")\n",
    "axs[1].scatter(np.arange(n), raw_radio_values[1].real, alpha=0.1, s=1, label=\"ant0 r\")\n",
    "axs[1].scatter(np.arange(n), raw_radio_values[1].imag, alpha=0.1, s=1, label=\"ant0 i\")\n",
    "axs[1].set_title(\"Raw signal ant1\")\n",
    "axs[0].set_xlabel(\"Sample# (time)\")\n",
    "axs[1].set_xlabel(\"Sample# (time)\")\n",
    "axs[2].set_xlabel(\"Sample# (time)\")\n",
    "axs[2].set_title(\"Phase estimates\")\n",
    "axs[2].scatter(np.arange(n), phase_difference, s=1, alpha=0.01)\n",
    "\n",
    "beamformer_output = [\n",
    "    beamformer_given_steering_nomean(\n",
    "        steering_vectors=ds.steering_vectors[receiver_idx],\n",
    "        signal_matrix=raw_radio_values,\n",
    "    )\n",
    "    for receiver_idx in range(2)\n",
    "]\n",
    "\n",
    "window_sds = []\n",
    "for window in simple_segment(raw_radio_values, **default_segment_args)[\n",
    "    \"simple_segmentation\"\n",
    "]:\n",
    "    print(window)\n",
    "    if window[\"type\"] == \"signal\":\n",
    "        axs[1].plot(\n",
    "            [window[\"start_idx\"], window[\"end_idx\"]],\n",
    "            [window[\"mean\"], window[\"mean\"]],\n",
    "            color=\"red\",\n",
    "        )\n",
    "    else:\n",
    "        axs[1].plot(\n",
    "            [window[\"start_idx\"], window[\"end_idx\"]],\n",
    "            [window[\"mean\"], window[\"mean\"]],\n",
    "            color=\"orange\",\n",
    "        )\n",
    "    _beam_sds = beamformer_output[0][:, window[\"start_idx\"] : window[\"end_idx\"]].mean(\n",
    "        axis=1\n",
    "    )\n",
    "    window_sds.append(_beam_sds)\n",
    "window_sds = np.array(window_sds)\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed = torch.nn.functional.normalize(\n",
    "    ds[session_idx][rx_idx][\"windowed_beamformer\"][0, 0, :], p=1, dim=1\n",
    ")\n",
    "unnormed = ds[session_idx][rx_idx][\"windowed_beamformer\"][0, 0, :]\n",
    "buffer_size = ds[session_idx][rx_idx][\"signal_matrix\"].shape[-1]\n",
    "window_size = buffer_size // normed.shape[0]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "axs[0].imshow(normed.T, aspect=\"auto\", origin=\"lower\")\n",
    "axs[1].imshow(unnormed.T, aspect=\"auto\", origin=\"lower\")\n",
    "y_ticks = [0, 32, 64]\n",
    "y_labels = [r\"$-\\pi$\", \"0\", r\"$\\pi$\"]\n",
    "x_labels = np.arange(0, buffer_size, 100000)\n",
    "x_indices = x_labels // 2048\n",
    "for idx in [0, 1]:\n",
    "    axs[idx].set_yticks(y_ticks)\n",
    "    axs[idx].set_yticklabels(y_labels)\n",
    "    axs[idx].set_xticks(x_indices)  # Show every 8th tick\n",
    "    axs[idx].set_xticklabels(x_labels)\n",
    "    axs[idx].set_xlabel(\"Sample # (time)\")\n",
    "    axs[idx].set_ylabel(\"power at angle (rad)\")\n",
    "    if idx == 0:\n",
    "        axs[idx].set_title(\"Normalized Beamformer mean by window (size=2048)\")\n",
    "    else:\n",
    "        axs[idx].set_title(\"Beamformer mean by window (size=2048)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 70000\n",
    "n = 1024 * 8\n",
    "offset = 208896\n",
    "offset = 470000\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[1].plot(\n",
    "    data[\"signal_matrix\"][0, 0, 1, offset : (offset + 1024 * 16)].imag,\n",
    "    label=\"ant1 imag\",\n",
    ")\n",
    "axs[0].plot(\n",
    "    data[\"signal_matrix\"][0, 0, 1, offset : (offset + 1024 * 16)].real,\n",
    "    label=\"ant1 real\",\n",
    ")\n",
    "axs[1].plot(\n",
    "    data[\"signal_matrix\"][0, 0, 0, offset : (offset + 1024 * 16)].imag,\n",
    "    label=\"ant0 imag\",\n",
    ")\n",
    "axs[0].plot(\n",
    "    data[\"signal_matrix\"][0, 0, 0, offset : (offset + 1024 * 16)].real,\n",
    "    label=\"ant0 real\",\n",
    ")\n",
    "axs[0].set_ylabel(\"I value\")\n",
    "axs[1].set_ylabel(\"Q value\")\n",
    "for idx in [0, 1]:\n",
    "    axs[idx].set_xlabel(\"idx in buffer\")\n",
    "    axs[idx].legend()\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"{os.path.basename(ds.zarr_fn)}:{session_idx}:{offset}+{n} rx_idx{rx_idx} IQ values\"\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.sdrpluto import detrend\n",
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "def high_pass_filter(data, cutoff=10, fs=16000000, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype=\"high\", analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "offset = 75000\n",
    "# offset = 50000\n",
    "n = 5000\n",
    "# session_idx = 287  # 395#+790\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "for rx_idx in range(2):\n",
    "    _data = ds[session_idx][rx_idx]\n",
    "    axs[rx_idx].set_title(\n",
    "        f\"{os.path.basename(ds.zarr_fn)}:{session_idx}:{offset}+{n} PlutoPlus:{rx_idx}, signal phase\"\n",
    "    )\n",
    "    rx0_mean = _data[\"signal_matrix\"][0, 0, 0, offset : (offset + n)].mean()\n",
    "    rx1_mean = _data[\"signal_matrix\"][0, 0, 1, offset : (offset + n)].mean()\n",
    "    axs[rx_idx].plot(\n",
    "        (_data[\"signal_matrix\"][0, 0] - rx0_mean).angle()[0, offset : (offset + n)],\n",
    "        label=\"rx0\",\n",
    "    )\n",
    "    axs[rx_idx].plot(\n",
    "        (_data[\"signal_matrix\"][0, 0] - rx1_mean).angle()[1, offset : (offset + n)],\n",
    "        label=\"rx1\",\n",
    "    )\n",
    "    axs[rx_idx].set_xlabel(\"IDX in captured buffer\")\n",
    "    axs[rx_idx].set_ylabel(\"Measured phase\")\n",
    "    axs[rx_idx].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ds[session_idx][0]\n",
    "sessions = [ds[idx][0] for idx in range(session_idx - 600, session_idx + 600, 20)]\n",
    "plt.scatter(\n",
    "    [session[\"tx_pos_x_mm\"] for session in sessions],\n",
    "    [session[\"tx_pos_y_mm\"] for session in sessions],\n",
    ")\n",
    "plt.scatter(\n",
    "    [session[\"rx_pos_x_mm\"] for session in sessions],\n",
    "    [session[\"rx_pos_y_mm\"] for session in sessions],\n",
    "    label=\"rx\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "session[\"tx_pos_x_mm\"], session[\"tx_pos_y_mm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"signal_matrix\"][0, 0][1, offset : (offset + n)].mean()\n",
    "offset = 75000\n",
    "# offset = 50000\n",
    "n = 15000\n",
    "offset = 208896\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "for rx_idx in range(2):\n",
    "    data = ds[session_idx][rx_idx]\n",
    "    axs[rx_idx].set_title(\n",
    "        f\"{os.path.basename(ds.zarr_fn)}:{session_idx}:{offset}+{n} PlutoPlus:{rx_idx}\"\n",
    "    )\n",
    "    raw_radio_values = detrend_np(data[\"signal_matrix\"][0, 0])\n",
    "    # v = data[\"signal_matrix\"][0, 0]\n",
    "    axs[rx_idx].plot(raw_radio_values[0, offset : (offset + n)].real, label=\"ant0-real\")\n",
    "    axs[rx_idx].plot(raw_radio_values[0, offset : (offset + n)].imag, label=\"ant0-imag\")\n",
    "    axs[rx_idx].plot(raw_radio_values[1, offset : (offset + n)].real, label=\"ant1-real\")\n",
    "    axs[rx_idx].plot(raw_radio_values[1, offset : (offset + n)].imag, label=\"ant1-imag\")\n",
    "    axs[rx_idx].set_xlabel(\"IDX in captured buffer\")\n",
    "    axs[rx_idx].set_ylabel(\"Measured real/imag (IQ)\")\n",
    "    axs[rx_idx].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "dists = (\n",
    "    (ds.cached_keys[0][\"tx_pos_mm\"] / 1000 - ds.cached_keys[0][\"rx_pos_mm\"] / 1000)\n",
    "    .pow(2)\n",
    "    .sum(axis=1)\n",
    "    .sqrt()\n",
    ")\n",
    "# plt.plot(dists)\n",
    "s = 900\n",
    "e = 1100\n",
    "s = 0\n",
    "e = -1\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "for rx_idx in range(2):\n",
    "    axs[rx_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].gains[s:e, 0], label=f\"R{rx_idx}-Gain0\"\n",
    "    )\n",
    "    axs[rx_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].gains[s:e, 1], label=f\"R{rx_idx}-Gain1\"\n",
    "    )\n",
    "    axs[rx_idx].legend()\n",
    "    axs[rx_idx].set_xlabel(\"Buffer capture # / IDX\")\n",
    "    axs[rx_idx].set_ylabel(\"Gain\")\n",
    "    axs[rx_idx].set_title(\n",
    "        f\"{os.path.basename(ds.zarr_fn)}:{session_idx}:{offset}+{n} PlutoPlus:{rx_idx}, Gain\"\n",
    "    )\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "dists = (\n",
    "    (ds.cached_keys[0][\"tx_pos_mm\"] / 1000 - ds.cached_keys[0][\"rx_pos_mm\"] / 1000)\n",
    "    .pow(2)\n",
    "    .sum(axis=1)\n",
    "    .sqrt()\n",
    ")\n",
    "# plt.plot(dists)\n",
    "s = 900\n",
    "e = 1100\n",
    "s = 0\n",
    "e = -1\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "for rx_idx in range(2):\n",
    "    axs[rx_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].rssis[s:e, 0], label=f\"R{rx_idx}-RSSI0\"\n",
    "    )\n",
    "    axs[rx_idx].plot(\n",
    "        ds.z.receivers[f\"r{rx_idx}\"].rssis[s:e, 1], label=f\"R{rx_idx}-RSSI1\"\n",
    "    )\n",
    "    axs[rx_idx].legend()\n",
    "    axs[rx_idx].set_xlabel(\"Buffer capture # / IDX\")\n",
    "    axs[rx_idx].set_ylabel(\"RSSI\")\n",
    "    axs[rx_idx].set_title(\n",
    "        f\"{os.path.basename(ds.zarr_fn)}:{session_idx}:{offset}+{n} PlutoPlus:{rx_idx}, RSSI\"\n",
    "    )\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = simple_segment(raw_radio_values, **default_segment_args)[\n",
    "    \"simple_segmentation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "dists = (\n",
    "    (ds.cached_keys[0][\"tx_pos_mm\"] / 1000 - ds.cached_keys[0][\"rx_pos_mm\"] / 1000)\n",
    "    .pow(2)\n",
    "    .sum(axis=1)\n",
    "    .sqrt()\n",
    ")\n",
    "plt.plot(dists)  # [670:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ds.z.receivers.r0.gains[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = (\n",
    "    (ds.cached_keys[0][\"tx_pos_mm\"] / 1000 - ds.cached_keys[0][\"rx_pos_mm\"] / 1000)\n",
    "    .pow(2)\n",
    "    .sum(axis=1)\n",
    "    .sqrt()\n",
    ")\n",
    "plt.plot(dists)\n",
    "plt.plot(ds.z.receivers.r0.rssis[:, 0], label=\"R0-rssi0\")\n",
    "plt.plot(ds.z.receivers.r0.rssis[:, 1], label=\"R0-rssi1\")\n",
    "plt.plot(ds.z.receivers.r1.rssis[:, 0], label=\"R1-rssi0\")\n",
    "plt.plot(ds.z.receivers.r1.rssis[:, 1], label=\"R1-rssi1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "dists = (\n",
    "    (ds.cached_keys[0][\"tx_pos_mm\"] / 1000 - ds.cached_keys[0][\"rx_pos_mm\"] / 1000)\n",
    "    .pow(2)\n",
    "    .sum(axis=1)\n",
    "    .sqrt()\n",
    ")\n",
    "\n",
    "r1_err = torch_pi_norm(ds.mean_phase[\"r1\"] - ds.ground_truth_phis[1]).abs()\n",
    "r0_err = torch_pi_norm(ds.mean_phase[\"r0\"] - ds.ground_truth_phis[0]).abs()\n",
    "plt.title(\"Distance vs phi error\")\n",
    "plt.scatter(dists, r1_err, s=1, label=\"R1\")\n",
    "plt.scatter(dists, r0_err, s=1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance (m)\")\n",
    "plt.ylabel(\"abs phi error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.sin(ds.ground_truth_thetas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ground_truth_thetas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "r1_err = torch_pi_norm(ds.mean_phase[\"r1\"] - ds.ground_truth_phis[1])\n",
    "r0_err = torch_pi_norm(ds.mean_phase[\"r0\"] - ds.ground_truth_phis[0])\n",
    "plt.hist(r1_err)\n",
    "plt.hist(r0_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "r1_err = torch_pi_norm(ds.mean_phase[\"r1\"] - ds.ground_truth_phis[1]).abs()\n",
    "r0_err = torch_pi_norm(ds.mean_phase[\"r0\"] - ds.ground_truth_phis[0]).abs()\n",
    "plt.title(\"Tx pos x vs phi error\")\n",
    "plt.scatter(ds.cached_keys[0][\"tx_pos_mm\"][:, 0], r1_err, s=1)\n",
    "plt.scatter(ds.cached_keys[0][\"tx_pos_mm\"][:, 0], r0_err, s=1)\n",
    "plt.xlabel(\"Distance (m)\")\n",
    "plt.ylabel(\"abs phi error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import mean_phase_mean\n",
    "\n",
    "mean_phases = []\n",
    "means = []\n",
    "weights = []\n",
    "for x in segmentation:\n",
    "    if x[\"type\"] == \"signal\":\n",
    "        means.append(x[\"mean\"])\n",
    "        weights.append(\n",
    "            (x[\"end_idx\"] - x[\"start_idx\"])\n",
    "            * x[\"abs_signal_median\"]\n",
    "            / (x[\"stddev\"] + 1e-6)  # weight by signal strength and region\n",
    "        )\n",
    "if len(means) == 0:\n",
    "    mean_phases.append(torch.nan)\n",
    "else:\n",
    "    means = np.array(means)\n",
    "    weights = np.array(weights)\n",
    "    # weights /= weights.sum()\n",
    "    mean_phases.append(mean_phase_mean(angles=means, weights=weights))\n",
    "mean_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed = torch.nn.functional.normalize(\n",
    "    ds[session_idx][0][\"windowed_beamformer\"][0, 0, :], p=1, dim=1\n",
    ")\n",
    "plt.imshow(normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds[session_idx][0][\"windowed_beamformer\"][0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[session_idx][0][\"windowed_beamformer\"][0, 0, :].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.receiver_data[0][\"rx_pos_x_mm\"][0], ds.receiver_data[0][\"rx_pos_y_mm\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import pi_norm\n",
    "\n",
    "\n",
    "ridx = 0\n",
    "rx_theta_in_pis = ds.receiver_data[ridx][\"rx_theta_in_pis\"]\n",
    "tx_pos = np.array(\n",
    "    [\n",
    "        ds.receiver_data[ridx][\"tx_pos_x_mm\"],\n",
    "        ds.receiver_data[ridx][\"tx_pos_y_mm\"],\n",
    "    ]\n",
    ")\n",
    "rx_pos = np.array(\n",
    "    [\n",
    "        ds.receiver_data[ridx][\"rx_pos_x_mm\"],\n",
    "        ds.receiver_data[ridx][\"rx_pos_y_mm\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compute the angle of the tx with respect to rx\n",
    "d = tx_pos - rx_pos\n",
    "\n",
    "rx_to_tx_theta = np.arctan2(d[0], d[1])\n",
    "# theta = pi_norm(rx_to_tx_theta - rx_theta_in_pis[:] * np.pi)\n",
    "# theta, ds.get_ground_truth_thetas()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((ds.mean_phase[\"r0\"] == 0.0000) * 1.0).mean(), (\n",
    "    (ds.mean_phase[\"r0\"].isfinite()) * 1.0\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cached_keys[0][\"rx_heading_in_pis\"].shape, ds.ground_truth_phis[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "\n",
    "def get_ground_truth_phisX(ds):\n",
    "    ground_truth_phis = []\n",
    "    for ridx in range(ds.n_receivers):\n",
    "        ground_truth_phis.append(\n",
    "            torch_pi_norm(\n",
    "                -torch.sin(\n",
    "                    ds.ground_truth_thetas[ridx]  # this is theta relative to our array!\n",
    "                    # + self.receiver_data[ridx][\"rx_theta_in_pis\"][:] * np.pi\n",
    "                )  # up to negative sign, which way do we spin?\n",
    "                # or maybe this is the order of the receivers 0/1 vs 1/0 on the x-axis\n",
    "                # pretty sure this (-) is more about which receiver is closer to x+/ish\n",
    "                # a -1 here is the same as -rx_spacing!\n",
    "                * ds.rx_wavelength_spacing\n",
    "                * 2\n",
    "                * torch.pi\n",
    "            )\n",
    "        )\n",
    "    return torch.vstack(ground_truth_phis)\n",
    "\n",
    "\n",
    "# z=get_ground_truth_phis(ds)\n",
    "# z==ds.ground_truth_phis\n",
    "# ds.cached_keys[0][\"rx_heading_in_pis\"][:first_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cached_keys[0][\"rx_heading_in_pis\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ground_truth_thetas[0][20], ds.ground_truth_phis[0][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import torch_pi_norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# segmentation = ds.get_segmentation()\n",
    "\n",
    "\n",
    "first_n = 500 * 4  # 12 * 8\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].scatter(range(first_n), ds.mean_phase[\"r0\"][:first_n], s=3, label=\"Rx0\")\n",
    "axs[1].scatter(range(first_n), ds.mean_phase[\"r1\"][:first_n], s=3, label=\"Rx1\")\n",
    "axs[0].scatter(\n",
    "    range(first_n),\n",
    "    ds.ground_truth_phis[0][:first_n],\n",
    "    s=3,\n",
    "    label=\"Rx0 (GT)\",\n",
    ")\n",
    "axs[1].scatter(range(first_n), ds.ground_truth_phis[1][:first_n], s=3, label=\"Rx1 (GT)\")\n",
    "for idx in range(2):\n",
    "    axs[idx].legend()\n",
    "    # axs.axvline(x=115)\n",
    "    axs[idx].set_title(\"Mean segmented phase diff\")\n",
    "    axs[idx].set_xlabel(\"Chunk (time)\")\n",
    "    axs[idx].set_ylabel(\"Mean phase diff of seg. chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation_by_receiver.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get_segmentation_mean_phase()\n",
    "ds.get_estimated_thetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mean_phase[\"r0\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import pi_norm\n",
    "from spf.rf import c as speed_of_light\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "estimated_thetas = ds.get_estimated_thetas()\n",
    "for rx_idx in [0, 1]:\n",
    "\n",
    "    axs[rx_idx].scatter(\n",
    "        range(estimated_thetas[f\"r{rx_idx}\"][0].shape[0]),\n",
    "        pi_norm(estimated_thetas[f\"r{rx_idx}\"][0]),\n",
    "        s=0.4,\n",
    "    )\n",
    "    axs[rx_idx].scatter(\n",
    "        range(estimated_thetas[f\"r{rx_idx}\"][1].shape[0]),\n",
    "        pi_norm(estimated_thetas[f\"r{rx_idx}\"][1]),\n",
    "        s=0.4,\n",
    "    )\n",
    "    axs[rx_idx].scatter(\n",
    "        range(estimated_thetas[f\"r{rx_idx}\"][2].shape[0]),\n",
    "        pi_norm(estimated_thetas[f\"r{rx_idx}\"][2]),\n",
    "        s=0.4,\n",
    "    )\n",
    "    axs[rx_idx].set_xlabel(\"Chunk\")\n",
    "    axs[rx_idx].set_ylabel(\"estimated theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import pi_norm\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "first_n = 1500\n",
    "estimated_thetas = ds.get_estimated_thetas()\n",
    "for rx_idx in [0, 1]:\n",
    "    expected_theta = ds.ground_truth_thetas[rx_idx]\n",
    "    axs[rx_idx].plot(\n",
    "        expected_theta[:first_n],\n",
    "        alpha=0.5,\n",
    "        color=\"red\",\n",
    "        label=\"ground truth\",\n",
    "    )\n",
    "    axs[rx_idx].plot(\n",
    "        reduce_theta_to_positive_y(expected_theta[:first_n]),\n",
    "        alpha=0.5,\n",
    "        color=\"green\",\n",
    "        label=\"reduced ground truth\",\n",
    "    )\n",
    "\n",
    "    n = estimated_thetas[f\"r{rx_idx}\"][0].shape[0]\n",
    "    axs[rx_idx].scatter(\n",
    "        range(first_n),\n",
    "        pi_norm(estimated_thetas[f\"r{rx_idx}\"][0])[:first_n],\n",
    "        s=3,\n",
    "        label=f\"Rx{rx_idx}_peak1\",\n",
    "    )\n",
    "    axs[rx_idx].scatter(\n",
    "        range(first_n),\n",
    "        pi_norm(estimated_thetas[f\"r{rx_idx}\"][1])[:first_n],\n",
    "        s=3,\n",
    "        label=f\"Rx{rx_idx}_peak2\",\n",
    "    )\n",
    "    axs[rx_idx].set_xlabel(\"Chunk\")\n",
    "    axs[rx_idx].set_ylabel(\"estimated theta\")\n",
    "    axs[rx_idx].legend()\n",
    "    axs[rx_idx].set_title(f\"Receiver (Rx) {rx_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = \"/Users/miskodzamba/Dropbox/research/gits/spf/\"\n",
    "import sys\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)  # go to parent dir\n",
    "\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "\n",
    "ds = v5spfdataset(\n",
    "    \"/Volumes/SPFData/missions/april5/wallarrayv3_2024_05_06_19_04_15_nRX2_bounce\",\n",
    "    nthetas=11,\n",
    ")\n",
    "\n",
    "from functools import cache\n",
    "import gc\n",
    "\n",
    "from spf.dataset.spf_dataset import v5_collate_beamsegnet, v5_thetas_to_targets\n",
    "from spf.model_training_and_inference.models.beamsegnet import (\n",
    "    BeamNSegNetDirect,\n",
    "    BeamNSegNetDiscrete,\n",
    "    # BeamNetDirect,\n",
    "    UNet1D,\n",
    "    ConvNet,\n",
    ")\n",
    "\n",
    "torch_device = torch.device(\"cpu\")\n",
    "nthetas = 11\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": 4,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0,\n",
    "    \"collate_fn\": v5_collate_beamsegnet,\n",
    "}\n",
    "torch.manual_seed(1337)\n",
    "train_dataloader = torch.utils.data.DataLoader(ds, **dataloader_params)\n",
    "\n",
    "import random\n",
    "\n",
    "w = False\n",
    "if w:\n",
    "\n",
    "    import wandb\n",
    "\n",
    "    # start a new wandb run to track this script\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"projectspf\",\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": \"beamsegnet1\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "@cache\n",
    "def mean_guess(shape):\n",
    "    return torch.nn.functional.normalize(torch.ones(shape), p=1, dim=1)\n",
    "\n",
    "\n",
    "X, Y_rad, segmentation = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "def batch_to_gt_segmentation(X, Y_rad, segmentation):\n",
    "    n, _, samples_per_session = X.shape\n",
    "    window_size = 2048\n",
    "    stride = 2048\n",
    "    assert window_size == stride\n",
    "    assert samples_per_session % window_size == 0\n",
    "    n_windows = samples_per_session // window_size\n",
    "    window_status = torch.zeros(n, n_windows)\n",
    "    for row_idx in range(len(segmentation)):\n",
    "        for window in segmentation[row_idx][\"simple_segmentation\"]:\n",
    "            window_status[\n",
    "                row_idx,\n",
    "                window[\"start_idx\"] // window_size : window[\"end_idx\"] // window_size,\n",
    "            ] = 1\n",
    "    return window_status[:, None]\n",
    "\n",
    "\n",
    "def segmentation_mask(X, segmentations):\n",
    "    seg_mask = torch.zeros(\n",
    "        X.shape[0], X.shape[2], device=X.device\n",
    "    )  # X.new(X.shape[0], X.shape[2])\n",
    "    for row_idx in range(seg_mask.shape[0]):\n",
    "        for w in segmentations[row_idx][\"simple_segmentation\"]:\n",
    "            seg_mask[row_idx, w[\"start_idx\"] : w[\"end_idx\"]] = 1\n",
    "    return seg_mask[:, None]  # orch.nn.functional.normalize(seg_mask, p=1, dim=1)\n",
    "\n",
    "\n",
    "# m = BeamNSegNetDiscrete(nthetas=nthetas, symmetry=False).to(torch_device)\n",
    "# m = BeamNSegNetDirect(nthetas=nthetas, symmetry=False).to(torch_device)\n",
    "# print(\"ALL\", segmentation[0][\"all_windows_stats\"].shape)\n",
    "m = UNet1D().to(torch_device).double()\n",
    "# m = ConvNet(in_channels=3, out_channels=1, hidden=32)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.00001, weight_decay=0)\n",
    "step = 0\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "X = X.double().to(torch_device)\n",
    "# X[:, :2] /= 500\n",
    "for epoch in range(10000):\n",
    "    # for X, Y_rad, segmentation in train_dataloader:\n",
    "    if True:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # full\n",
    "        input = X.clone().to(torch_device)\n",
    "        output = m(input)\n",
    "\n",
    "        seg_mask = segmentation_mask(X, segmentation)\n",
    "        print(input.shape, output.shape, seg_mask.shape)\n",
    "\n",
    "        # downsampled\n",
    "        # input = torch.Tensor(\n",
    "        #     np.vstack(\n",
    "        #         [\n",
    "        #             segmentation[idx][\"all_windows_stats\"].transpose()[None]\n",
    "        #             for idx in range(len(segmentation))\n",
    "        #         ]\n",
    "        #     )\n",
    "        # )\n",
    "        # input[:, 2] /= 50\n",
    "        # output = m(input)\n",
    "        # seg_mask = batch_to_gt_segmentation(X, Y_rad, segmentation)\n",
    "\n",
    "        loss = ((output - seg_mask) ** 2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        to_log = {\"loss\": loss.item()}\n",
    "\n",
    "        _input = input.cpu()\n",
    "        _output = output.cpu().detach().numpy()\n",
    "        first_n = 3000\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(loss.item())\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "            s = 0.3\n",
    "            axs[0].set_title(\"input (track 0/1)\")\n",
    "            axs[0].scatter(range(first_n), _input[0, 0, :first_n], s=s)\n",
    "            axs[0].scatter(range(first_n), _input[0, 1, :first_n], s=s)\n",
    "            axs[1].set_title(\"input (track 2)\")\n",
    "            axs[1].scatter(range(first_n), _input[0, 2, :first_n], s=s)\n",
    "            # mw = mask_weights.cpu().detach().numpy()\n",
    "\n",
    "            axs[2].set_title(\"output vs gt\")\n",
    "            axs[2].scatter(range(first_n), _output[0, 0, :first_n], s=s)\n",
    "            axs[2].scatter(\n",
    "                range(first_n), seg_mask.cpu().detach().numpy()[0, 0, :first_n], s=s\n",
    "            )\n",
    "            to_log[\"fig\"] = fig\n",
    "        if w:\n",
    "            wandb.log(to_log)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, seg_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = \"/Users/miskodzamba/Dropbox/research/gits/spf/\"\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)  # go to parent dir\n",
    "\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch_device = torch.device(\"cpu\")\n",
    "nthetas = 11\n",
    "lr = 0.001\n",
    "batch_size = 8\n",
    "\n",
    "ds = v5spfdataset(\n",
    "    \"/Volumes/SPFData/missions/april5/wallarrayv3_2024_05_06_19_04_15_nRX2_bounce\",\n",
    "    nthetas=11,\n",
    ")\n",
    "\n",
    "from functools import cache\n",
    "import gc\n",
    "\n",
    "from spf.dataset.spf_dataset import v5_collate_beamsegnet, v5_thetas_to_targets\n",
    "from spf.model_training_and_inference.models.beamsegnet import (\n",
    "    BeamNSegNet,\n",
    "    BeamNetDirect,\n",
    "    BeamNetDiscrete,\n",
    "    ConvNet,\n",
    "    UNet1D,\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0,\n",
    "    \"collate_fn\": v5_collate_beamsegnet,\n",
    "}\n",
    "torch.manual_seed(1337)\n",
    "train_dataloader = torch.utils.data.DataLoader(ds, **dataloader_params)\n",
    "w = False\n",
    "if w:\n",
    "    import wandb\n",
    "\n",
    "    # start a new wandb run to track this script\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"projectspf\",\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": \"beamsegnet1\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_instance(_x, _output_seg, _seg_mask, idx=0):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "    s = 0.3\n",
    "    axs[0].set_title(\"input (track 0/1)\")\n",
    "    axs[0].scatter(range(first_n), _x[idx, 0, :first_n], s=s)\n",
    "    axs[0].scatter(range(first_n), _x[idx, 1, :first_n], s=s)\n",
    "    axs[1].set_title(\"input (track 2)\")\n",
    "    axs[1].scatter(range(first_n), _x[idx, 2, :first_n], s=s)\n",
    "    # mw = mask_weights.cpu().detach().numpy()\n",
    "\n",
    "    axs[2].set_title(\"output vs gt\")\n",
    "    axs[2].scatter(range(first_n), _output_seg[idx, 0, :first_n], s=s)\n",
    "    axs[2].scatter(range(first_n), _seg_mask[idx, 0, :first_n], s=s)\n",
    "    return fig\n",
    "\n",
    "\n",
    "batch_data = next(iter(train_dataloader))\n",
    "import pickle\n",
    "\n",
    "pickle.dump(batch_data, open(\"test_batch.pkl\", \"wb\"))\n",
    "skip_segmentation = False\n",
    "segmentation_level = \"downsampled\"\n",
    "if segmentation_level == \"full\":\n",
    "    first_n = 10000\n",
    "    seg_m = UNet1D().to(torch_device)\n",
    "elif segmentation_level == \"downsampled\":\n",
    "    first_n = 256\n",
    "    seg_m = ConvNet(3, 1, 32, bn=True).to(torch_device)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "beam_m = BeamNetDirect(\n",
    "    nthetas=nthetas, hidden=16, symmetry=True, other=True, act=nn.SELU, bn=True\n",
    ").to(torch_device)\n",
    "# beam_m = BeamNetDiscrete(nthetas=nthetas, hidden=16, symmetry=False).to(torch_device)\n",
    "m = BeamNSegNet(segnet=seg_m, beamnet=beam_m, circular_mean=True).to(torch_device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(seg_m.parameters(), lr=0.01, weight_decay=0)\n",
    "\n",
    "step = 0\n",
    "head_start = 200\n",
    "for epoch in range(10000):\n",
    "    if step == head_start:\n",
    "        optimizer = torch.optim.AdamW(beam_m.parameters(), lr=0.001, weight_decay=0)\n",
    "        optimizer.zero_grad()\n",
    "    # for X, Y_rad in train_dataloader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # copy to torch device\n",
    "    if segmentation_level == \"full\":\n",
    "        x = batch_data[\"x\"].to(torch_device)\n",
    "        y_rad = batch_data[\"y_rad\"].to(torch_device)\n",
    "        seg_mask = batch_data[\"segmentation_mask\"].to(torch_device)\n",
    "    elif segmentation_level == \"downsampled\":\n",
    "        x = batch_data[\"all_windows_stats\"].to(torch_device)\n",
    "        y_rad = batch_data[\"y_rad\"].to(torch_device)\n",
    "        seg_mask = batch_data[\"downsampled_segmentation_mask\"].to(torch_device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    assert seg_mask.ndim == 3 and seg_mask.shape[1] == 1\n",
    "\n",
    "    # run beamformer and segmentation\n",
    "    if not skip_segmentation:\n",
    "        output = m(x)\n",
    "    else:\n",
    "        output = m(x, seg_mask)\n",
    "\n",
    "    # x to beamformer loss (indirectly including segmentation)\n",
    "    x_to_beamformer_loss = -beam_m.loglikelihood(output[\"pred_theta\"], y_rad)\n",
    "    assert x_to_beamformer_loss.shape == (batch_size, 1)\n",
    "    x_to_beamformer_loss = x_to_beamformer_loss.mean()\n",
    "\n",
    "    # segmentation loss\n",
    "    x_to_segmentation_loss = (output[\"segmentation\"] - seg_mask) ** 2\n",
    "    assert x_to_segmentation_loss.ndim == 3 and x_to_segmentation_loss.shape[1] == 1\n",
    "    x_to_segmentation_loss = x_to_segmentation_loss.mean()\n",
    "\n",
    "    if skip_segmentation:\n",
    "        loss = x_to_beamformer_loss\n",
    "    else:\n",
    "        if step >= head_start:\n",
    "            loss = x_to_beamformer_loss\n",
    "        else:\n",
    "            loss = x_to_segmentation_loss\n",
    "    # if step in [799, 780]:\n",
    "    #     print(step, output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    to_log = {\n",
    "        \"loss\": loss.item(),\n",
    "        \"segmentation_loss\": x_to_segmentation_loss.item(),\n",
    "        \"beam_former_loss\": x_to_beamformer_loss.item(),\n",
    "    }\n",
    "    if step % 500 == 0:\n",
    "        # beam outputs\n",
    "        img_beam_output = (\n",
    "            (beam_m.render_discrete_x(output[\"pred_theta\"]) * 255).cpu().byte()\n",
    "        )\n",
    "        img_beam_gt = (beam_m.render_discrete_y(y_rad) * 255).cpu().byte()\n",
    "        train_target_image = torch.zeros(\n",
    "            (img_beam_output.shape[0] * 2, img_beam_output.shape[1]),\n",
    "        ).byte()\n",
    "        for row_idx in range(img_beam_output.shape[0]):\n",
    "            train_target_image[row_idx * 2] = img_beam_output[row_idx]\n",
    "            train_target_image[row_idx * 2 + 1] = img_beam_gt[row_idx]\n",
    "        if w:\n",
    "            output_image = wandb.Image(\n",
    "                train_target_image, caption=\"train vs target (interleaved)\"\n",
    "            )\n",
    "            to_log[\"output\"] = output_image\n",
    "\n",
    "        # segmentation output\n",
    "        _x = x.detach().cpu().numpy()\n",
    "        _seg_mask = seg_mask.detach().cpu().numpy()\n",
    "        # _output_seg = output_segmentation_upscaled.detach().cpu().numpy()\n",
    "        _output_seg = output[\"segmentation\"].detach().cpu().numpy()\n",
    "\n",
    "        fig = plot_instance(_x, _output_seg, _seg_mask, idx=0)\n",
    "        if w:\n",
    "            to_log[\"fig\"] = fig\n",
    "    if w:\n",
    "        wandb.log(to_log)\n",
    "    else:\n",
    "        # if step > 760 and step < 800:\n",
    "        if step % 20 == 0:\n",
    "            print(\n",
    "                step,\n",
    "                loss.item(),\n",
    "                x_to_beamformer_loss.item(),\n",
    "                x_to_segmentation_loss.item(),\n",
    "            )\n",
    "    step += 1\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "if w:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "z = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z(torch.Tensor([-10, 0, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_input = torch.mul(x, output[\"segmentation\"]).sum(axis=2) / output[\n",
    "    \"segmentation\"\n",
    "].sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = m.beamnet.fixify(m.beamnet.beam_net(weighted_input), sign=1)\n",
    "\n",
    "m.beamnet.likelihood(param, y_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param, y_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_param = param.clone()\n",
    "_param[:, 1] = 100\n",
    "m.beamnet.likelihood(_param, y_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rad.clamp(min=0, max=0.1)\n",
    "y_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.beamnet.beam_net(weighted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.beamnet.beam_net(weighted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"pred_theta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_input = torch.mul(x, output[\"segmentation\"]).sum(axis=2) / output[\n",
    "    \"segmentation\"\n",
    "].sum(axis=2)\n",
    "weighted_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output[\"pred_theta\"][:, 0] - y_rad).shape, x_to_beamformer_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_m.loglikelihood(output[\"pred_theta\"], y_rad).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mul(output[\"beam_former\"], output[\"segmentation\"]).sum(axis=2) / output[\n",
    "    \"segmentation\"\n",
    "].sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = output[\"pred_theta\"]\n",
    "y = y_rad\n",
    "(x[:, 3] * torch.exp(-((x[:, 0] - y) ** 2) / x[:, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"pred_theta\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"beam_former\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    output_segmentation_upscaled = output[\"segmentation\"] * seg_mask.sum(\n",
    "        axis=2, keepdim=True\n",
    "    )\n",
    "    x_to_segmentation_loss = (output_segmentation_upscaled - seg_mask) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"mask_weights\"].shape, output[\"segmentation\"].shape, output[\"beam_former\"].shape\n",
    "k = torch.mul(output[\"beam_former\"], output[\"segmentation\"]) / output[\n",
    "    \"segmentation\"\n",
    "].sum(axis=2, keepdim=True)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_segmentation_upscaled = output[\"segmentation\"] * seg_mask.sum()\n",
    "# x_to_segmentation_loss = (output_segmentation_upscaled - seg_mask) ** 2\n",
    "(output[\"segmentation\"] * seg_mask.sum(axis=2, keepdim=True)).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask.sum(axis=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = output[\"segmentation\"].detach().cpu().numpy()[0, 0]\n",
    "# =_p_seg_mask[0,0]\n",
    "# z=_output_seg[0,0]\n",
    "plt.scatter(range(len(z)), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"segmentation\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1, :].mean(), X[:, 1, :].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, Y_rad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation[0][\"all_windows_stats\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mask(X, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = X.clone().to(torch_device)\n",
    "_X[:, :2] /= 500\n",
    "batch_size, input_channels, session_size = _X.shape\n",
    "beam_former_input = _X.transpose(1, 2).reshape(\n",
    "    batch_size * session_size, input_channels\n",
    ")\n",
    "print(_X.device, beam_former_input)\n",
    "beam_former = m.beam_net(beam_former_input).reshape(\n",
    "    batch_size, session_size, 5  # mu, o1, o2, k1, k2\n",
    ")\n",
    "mask_weights = m.softmax(m.unet1d(_X)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_former_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask.cpu().detach().numpy()[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n = 40000\n",
    "x = X[0].cpu()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axs[0].scatter(range(first_n), x[0, :first_n], s=0.3)\n",
    "axs[0].scatter(range(first_n), x[1, :first_n], s=0.3)\n",
    "axs[1].scatter(range(first_n), x[2, :first_n], s=0.3)\n",
    "# mw = mask_weights.cpu().detach().numpy()\n",
    "mw = m(X).cpu().detach().numpy()[0]\n",
    "axs[2].scatter(range(first_n), mw[0, :first_n], s=0.3)\n",
    "axs[2].scatter(range(first_n), seg_mask.cpu().detach().numpy()[0, :first_n], s=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.model_training_and_inference.models.beamsegnet import BeamNSegNetDirect\n",
    "\n",
    "\n",
    "m = BeamNSegNetDirect(nthetas=nthetas)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=0.01)\n",
    "\n",
    "m.beam_net.beam_net[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = x[[0]]\n",
    "k_y = y[[0]]\n",
    "k[:, 2] = -k[:, 2].sign() * k[:, 2]\n",
    "# k[:, 2] = k[:, 2].sign() * k[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "m.train()\n",
    "m.beam_net.beam_net[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(k)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "l = loss_fn(output, k_y)\n",
    "l.backward()\n",
    "# mean_loss = output\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.beam_net.beam_net[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def detrend_iq(iq_tensor):\n",
    "    print(iq_tensor.shape)\n",
    "    \"\"\"\n",
    "    Remove linear trends from the I and Q components of a 1D complex PyTorch tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - iq_tensor (torch.Tensor): 1D complex tensor of shape (N,), dtype=torch.complex64 or torch.complex128.\n",
    "    \n",
    "    Returns:\n",
    "    - detrended_iq (torch.Tensor): 1D complex tensor of shape (N,), with linear trends removed from I and Q.\n",
    "    \"\"\"\n",
    "    if not torch.is_complex(iq_tensor):\n",
    "        raise ValueError(\"Input tensor must be a complex tensor.\")\n",
    "    if iq_tensor.dim() != 1:\n",
    "        raise ValueError(\"Input tensor must be 1D.\")\n",
    "\n",
    "    # Number of samples\n",
    "    N = iq_tensor.shape[0]\n",
    "\n",
    "    # Time vector\n",
    "    t = torch.linspace(0, 1, steps=N, device=iq_tensor.device).unsqueeze(\n",
    "        1\n",
    "    )  # Shape: (N, 1)\n",
    "\n",
    "    # Design the design matrix for linear regression [t, 1]\n",
    "    X = torch.cat([t, torch.ones_like(t)], dim=1)  # Shape: (N, 2)\n",
    "\n",
    "    # Separate I and Q components\n",
    "    I = iq_tensor.real  # Shape: (N,)\n",
    "    Q = iq_tensor.imag  # Shape: (N,)\n",
    "\n",
    "    # Add a dimension for matrix operations\n",
    "    I = I.unsqueeze(1)  # Shape: (N, 1)\n",
    "    Q = Q.unsqueeze(1)  # Shape: (N, 1)\n",
    "\n",
    "    # Perform least squares linear regression to find slope and intercept\n",
    "    # Using torch.linalg.lstsq (available in PyTorch >=1.9)\n",
    "    coeffs_I = torch.linalg.lstsq(X, I).solution  # Shape: (2, 1)\n",
    "    coeffs_Q = torch.linalg.lstsq(X, Q).solution  # Shape: (2, 1)\n",
    "\n",
    "    # Compute the fitted trends\n",
    "    trend_I = X @ coeffs_I  # Shape: (N, 1)\n",
    "    trend_Q = X @ coeffs_Q  # Shape: (N, 1)\n",
    "\n",
    "    # Subtract the trends to detrend\n",
    "    I_detrended = I - trend_I  # Shape: (N, 1)\n",
    "    Q_detrended = Q - trend_Q  # Shape: (N, 1)\n",
    "\n",
    "    # Remove the extra dimension and combine into complex tensor\n",
    "    I_detrended = I_detrended.squeeze(1)  # Shape: (N,)\n",
    "    Q_detrended = Q_detrended.squeeze(1)  # Shape: (N,)\n",
    "    detrended_iq = torch.complex(I_detrended, Q_detrended)  # Shape: (N,)\n",
    "\n",
    "    return detrended_iq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
