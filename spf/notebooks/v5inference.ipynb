{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77359cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_to_record_matrix(self, thread_idx, record_idx, data):\n",
    "#     tx_pos = self.position_controller.controller.position[\"xy\"][\n",
    "#         self.yaml_config[\"emitter\"][\"motor_channel\"]\n",
    "#     ]\n",
    "#     rx_pos = self.position_controller.controller.position[\"xy\"][\n",
    "#         self.rx_configs[0].motor_channel\n",
    "#     ]\n",
    "\n",
    "#     data.tx_pos_x_mm = tx_pos[0]\n",
    "#     data.tx_pos_y_mm = tx_pos[1]\n",
    "#     data.rx_pos_x_mm = rx_pos[0]\n",
    "#     data.rx_pos_y_mm = rx_pos[1]\n",
    "#     assert data.rx_lo > 1\n",
    "\n",
    "#     if not self.yaml_config[\"dry-run\"]:\n",
    "#         z = self.zarr[f\"receivers/r{thread_idx}\"]\n",
    "#         z.signal_matrix[record_idx] = data.signal_matrix\n",
    "#         for k in v5rx_f64_keys + v5rx_2xf64_keys:\n",
    "#             z[k][record_idx] = getattr(data, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c504d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "from spf.dataset.v5_data import v5rx_2xf64_keys, v5rx_f64_keys, v5rx_new_dataset\n",
    "\n",
    "ds = v5spfdataset(\n",
    "    \"/mnt/md2/2d_wallarray_v2_data/april_nuand/wallarrayv3_2025_04_04_21_06_04_nRX2_rx_random_circle_spacing0p08.zarr\",\n",
    "    nthetas=65,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/mnt/md2/cache/precompute_cache_3p5_chunk1/\",\n",
    "    gpu=False,\n",
    "    snapshots_per_session=1,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    segmentation_version=3.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(100):\n",
    "#     ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffcaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v5_raw_keys = v5rx_f64_keys + v5rx_2xf64_keys + [\"signal_matrix\"]\n",
    "\n",
    "\n",
    "def data_single_radio_to_raw(d):\n",
    "    return {k: d[k] for k in v5_raw_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16982148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pickle\n",
    "from typing import List\n",
    "from spf.dataset.segmentation import (\n",
    "    DEFAULT_SEGMENT_ARGS,\n",
    "    mean_phase_from_simple_segmentation,\n",
    "    segment_session,\n",
    ")\n",
    "from spf.dataset.spf_dataset import (\n",
    "    data_from_precomputed,\n",
    "    encode_vehicle_type,\n",
    "    get_empirical_dist,\n",
    "    uri_to_device_type,\n",
    ")\n",
    "from spf.scripts.train_single_point import (\n",
    "    global_config_to_keys_used,\n",
    "    load_config_from_fn,\n",
    ")\n",
    "from spf.sdrpluto.sdr_controller import rx_config_from_receiver_yaml\n",
    "from spf.utils import SEGMENTATION_VERSION, load_config, to_bin\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from spf.rf import (\n",
    "    precompute_steering_vectors,\n",
    "    speed_of_light,\n",
    "    torch_get_phase_diff,\n",
    ")\n",
    "\n",
    "training_only_keys = [\n",
    "    \"ground_truth_theta\",\n",
    "    \"ground_truth_phi\",\n",
    "    \"craft_ground_truth_theta\",\n",
    "    \"y_rad\",\n",
    "    \"y_phi\",\n",
    "    \"craft_y_rad\",\n",
    "    \"y_rad_binned\",\n",
    "]\n",
    "\n",
    "segmentation_based_keys = [\n",
    "    \"weighted_beamformer\",\n",
    "    \"all_windows_stats\",\n",
    "    \"weighted_windows_stats\",\n",
    "    \"downsampled_segmentation_mask\",\n",
    "    \"simple_segmentations\",\n",
    "    \"mean_phase_segmentation\",\n",
    "]\n",
    "\n",
    "\n",
    "class v5inferencedataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        yaml_fn: str,\n",
    "        nthetas: int,  # Number of theta angles for beamforming discretization\n",
    "        model_config_fn: str = \"\",\n",
    "        paired: bool = False,  # If True, return paired samples from all receivers at once\n",
    "        gpu: bool = False,  # Use GPU for segmentation computation if available\n",
    "        skip_fields: List[\n",
    "            str\n",
    "        ] = [],  # Data fields to exclude during loading to save memory\n",
    "        n_parallel: int = 20,  # Number of parallel processes for segmentation\n",
    "        empirical_data_fn: (\n",
    "            str | None\n",
    "        ) = None,  # Path to empirical distribution data file for phase-to-angle mapping\n",
    "        empirical_individual_radio: bool = False,  # Use per-radio empirical distributions if True\n",
    "        empirical_symmetry: bool = True,  # Use symmetric empirical distributions if True\n",
    "        target_dtype=torch.float32,  # Target dtype for tensor conversion (memory optimization)\n",
    "        distance_normalization: int = 1000,  # Divisor to normalize distance measurements (mm to meters)\n",
    "        target_ntheta: (\n",
    "            bool | None\n",
    "        ) = None,  # Target number of theta bins for classification (defaults to nthetas)\n",
    "        windows_per_snapshot: int = 256,  # Maximum number of windows per snapshot to use\n",
    "        skip_detrend: bool = False,\n",
    "        skip_segmentation: bool = True,\n",
    "        vehicle_type: str = \"\",\n",
    "        max_in_memory: int = 10,\n",
    "    ):\n",
    "        # Store configuration parameters\n",
    "        self.yaml_fn = yaml_fn\n",
    "        self.n_parallel = n_parallel\n",
    "        self.nthetas = nthetas  # Number of angles to discretize space for beamforming\n",
    "        self.target_ntheta = self.nthetas if target_ntheta is None else target_ntheta\n",
    "\n",
    "        self.max_in_memory = max_in_memory\n",
    "        self.min_idx = 0\n",
    "        self.condition = multiprocessing.Condition()\n",
    "        self.lock = multiprocessing.Lock()\n",
    "        self.store = {}\n",
    "\n",
    "        # Segmentation parameters control how raw signal is processed into windows\n",
    "        # and how phase difference is computed between antenna elements\n",
    "        self.skip_detrend = skip_detrend\n",
    "        self.windows_per_snapshot = windows_per_snapshot\n",
    "\n",
    "        self.distance_normalization = distance_normalization\n",
    "        self.skip_fields = skip_fields\n",
    "        self.skip_segmentation = skip_segmentation\n",
    "        if self.skip_segmentation:\n",
    "            self.skip_fields += segmentation_based_keys\n",
    "        self.paired = paired\n",
    "        assert self.paired\n",
    "        self.gpu = gpu  # Whether to use GPU acceleration for beamforming calculations\n",
    "        self.target_dtype = target_dtype\n",
    "        self.precomputed_entries = 0\n",
    "        self.precomputed_zarr = (\n",
    "            None  # Will hold preprocessed beamforming and segmentation data\n",
    "        )\n",
    "\n",
    "        self.yaml_config = load_config(self.yaml_fn)\n",
    "\n",
    "        if model_config_fn != \"\":\n",
    "            self.model_config = load_config_from_fn(model_config_fn)\n",
    "            self.keys_to_get = global_config_to_keys_used(self.model_config[\"global\"])\n",
    "        else:\n",
    "            self.keys_to_get = global_config_to_keys_used(None)\n",
    "\n",
    "        # Get system metadata\n",
    "        self.vehicle_type = vehicle_type\n",
    "\n",
    "        # Extract receiver properties - important for beamforming calculations\n",
    "        self.wavelengths = [\n",
    "            speed_of_light / receiver[\"f-carrier\"]  # λ = c/f\n",
    "            for receiver in self.yaml_config[\"receivers\"]\n",
    "        ]\n",
    "        self.carrier_frequencies = [\n",
    "            receiver[\"f-carrier\"] for receiver in self.yaml_config[\"receivers\"]\n",
    "        ]\n",
    "        self.rf_bandwidths = [\n",
    "            receiver[\"bandwidth\"] for receiver in self.yaml_config[\"receivers\"]\n",
    "        ]\n",
    "\n",
    "        # Validate that all receivers have consistent configurations\n",
    "        for rx_idx in range(1, 2):\n",
    "            assert (\n",
    "                self.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "                == self.yaml_config[\"receivers\"][rx_idx][\"antenna-spacing-m\"]\n",
    "            )\n",
    "            assert self.wavelengths[0] == self.wavelengths[rx_idx]\n",
    "            assert self.rf_bandwidths[0] == self.rf_bandwidths[rx_idx]\n",
    "\n",
    "        # Set up receiver spacing properties - critical for beamforming\n",
    "        # Spacing between antenna elements affects phase difference and angle estimation\n",
    "        self.rx_spacing = self.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "        assert self.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"] == self.rx_spacing\n",
    "\n",
    "        # rx_wavelength_spacing (d/λ) is a key parameter for beamforming\n",
    "        # It determines how phase differences map to arrival angles\n",
    "        self.rx_wavelength_spacing = self.rx_spacing / self.wavelengths[0]\n",
    "\n",
    "        # Create receiver configs and determine device types\n",
    "        self.rx_configs = [\n",
    "            rx_config_from_receiver_yaml(receiver)\n",
    "            for receiver in self.yaml_config[\"receivers\"]\n",
    "        ]\n",
    "        self.sdr_device_types = [\n",
    "            uri_to_device_type(rx_config.uri) for rx_config in self.rx_configs\n",
    "        ]\n",
    "\n",
    "        # Ensure all receivers use the same device type\n",
    "        if len(self.sdr_device_types) > 1:\n",
    "            for device_type in self.sdr_device_types:\n",
    "                assert device_type == self.sdr_device_types[0]\n",
    "        self.sdr_device_type = self.sdr_device_types[0]\n",
    "\n",
    "        # Precompute steering vectors for beamforming\n",
    "        # Steering vectors are complex weights applied to each antenna element\n",
    "        # They're used to \"steer\" the array to look in a specific direction\n",
    "        # For each possible angle (theta), calculate the appropriate phase shifts\n",
    "        self.steering_vectors = [\n",
    "            precompute_steering_vectors(\n",
    "                receiver_positions=rx_config.rx_pos,\n",
    "                carrier_frequency=rx_config.lo,\n",
    "                spacing=nthetas,\n",
    "            )\n",
    "            for rx_config in self.rx_configs\n",
    "        ]\n",
    "\n",
    "        # Define keys to load per session\n",
    "        self.keys_per_session = (\n",
    "            v5rx_f64_keys + v5rx_2xf64_keys + [\"rx_wavelength_spacing\"]\n",
    "        )\n",
    "        if \"signal_matrix\" not in self.skip_fields:\n",
    "            self.keys_per_session.append(\"signal_matrix\")\n",
    "\n",
    "        # Load empirical distribution data if provided\n",
    "        # These are learned phase-to-angle mappings that can improve angle estimation\n",
    "        if empirical_data_fn is not None:\n",
    "            self.empirical_data_fn = empirical_data_fn\n",
    "            self.empirical_data = pickle.load(open(empirical_data_fn, \"rb\"))\n",
    "            self.empirical_individual_radio = empirical_individual_radio\n",
    "            self.empirical_symmetry = empirical_symmetry\n",
    "        else:\n",
    "            self.empirical_data_fn = None\n",
    "            self.empirical_data = None\n",
    "\n",
    "    # ASSUMING EVERYTHING WILL BE REQUESTED IN SEQUENCE!!\n",
    "    def __getitem__(self, idx):\n",
    "        if \n",
    "        return [\n",
    "            self.render_session(receiver_idx, idx)\n",
    "            for receiver_idx in range(self.n_receivers)\n",
    "        ]\n",
    "\n",
    "    def write_to_idx(self, idx, ridx, raw):\n",
    "        if idx < self.min_idx:\n",
    "            return  # we dont need this sample\n",
    "        rendered_data = self.render_session(idx, ridx, raw)\n",
    "\n",
    "        self.lock.acquire()\n",
    "        if idx not in self.store:\n",
    "            self.store[idx] = {\"count\": 0, \"data\": [None, None]}  # entry not ready\n",
    "        self.store[idx][\"data\"][ridx] = rendered_data\n",
    "        self.store[idx][\"count\"] += 1\n",
    "        self.lock.release()\n",
    "\n",
    "        with self.condition:\n",
    "            self.condition.notify_all()\n",
    "\n",
    "    def render_session(self, idx, ridx, data):\n",
    "        snapshot_idxs = [0]  # which snapshots to get\n",
    "\n",
    "        data[\"rx_wavelength_spacing\"] = torch.tensor(self.rx_wavelength_spacing)\n",
    "\n",
    "        data[\"gains\"] = data[\"gains\"][:, None]\n",
    "        data[\"receiver_idx\"] = torch.tensor([[ridx]], dtype=torch.int)\n",
    "\n",
    "        data[\"ground_truth_theta\"] = torch.tensor([torch.inf])  # unknown\n",
    "        data[\"y_rad\"] = data[\"ground_truth_theta\"]  # torch.inf\n",
    "\n",
    "        data[\"ground_truth_phi\"] = torch.tensor([torch.inf])  # unkown\n",
    "        data[\"y_phi\"] = data[\"ground_truth_phi\"]  # torch.inf\n",
    "\n",
    "        data[\"craft_ground_truth_theta\"] = torch.tensor([torch.inf])  # unknown\n",
    "        data[\"craft_y_rad\"] = data[\"craft_ground_truth_theta\"]  # torch.inf\n",
    "\n",
    "        data[\"vehicle_type\"] = torch.tensor(\n",
    "            [encode_vehicle_type(self.vehicle_type)]\n",
    "        ).reshape(1)\n",
    "        data[\"sdr_device_type\"] = torch.tensor([self.sdr_device_type.value]).reshape(1)\n",
    "\n",
    "        if \"signal_matrix\" not in self.skip_fields:\n",
    "            # WARNGING this does not respect flipping!\n",
    "            abs_signal = data[\"signal_matrix\"].abs().to(torch.float32)\n",
    "            assert data[\"signal_matrix\"].shape[0] == 1\n",
    "            pd = torch_get_phase_diff(data[\"signal_matrix\"][0]).to(torch.float32)\n",
    "            data[\"abs_signal_and_phase_diff\"] = torch.concatenate(\n",
    "                [abs_signal, pd[None, :, None]], dim=2\n",
    "            )\n",
    "\n",
    "        data[\"rx_pos_mm\"] = torch.vstack(\n",
    "            [\n",
    "                data[\"rx_pos_x_mm\"],\n",
    "                data[\"rx_pos_y_mm\"],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "        data[\"tx_pos_mm\"] = torch.vstack(\n",
    "            [\n",
    "                data[\"tx_pos_x_mm\"],\n",
    "                data[\"tx_pos_y_mm\"],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "        data[\"rx_pos_xy\"] = (\n",
    "            data[\"rx_pos_mm\"][snapshot_idxs].unsqueeze(0) / self.distance_normalization\n",
    "        )\n",
    "\n",
    "        data[\"tx_pos_xy\"] = (\n",
    "            data[\"tx_pos_mm\"][snapshot_idxs].unsqueeze(0) / self.distance_normalization\n",
    "        )\n",
    "\n",
    "        segmentation = segment_session(\n",
    "            data[\"signal_matrix\"][0][ridx],\n",
    "            gpu=False,\n",
    "            skip_beamformer=False,\n",
    "            skip_detrend=False,\n",
    "            skip_segmentation=self.skip_segmentation,\n",
    "            **{\n",
    "                \"steering_vectors\": self.steering_vectors[ridx],\n",
    "                **DEFAULT_SEGMENT_ARGS,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        data.update(\n",
    "            data_from_precomputed(\n",
    "                v5ds=self,\n",
    "                precomputed_data=segmentation,\n",
    "                segmentation=[segmentation],\n",
    "                snapshot_idxs=[0],\n",
    "            )\n",
    "        )\n",
    "        if not self.skip_segmentation:\n",
    "            data[\"mean_phase_segmentation\"] = torch.tensor(\n",
    "                mean_phase_from_simple_segmentation([segmentation])\n",
    "            ).unsqueeze(0)\n",
    "\n",
    "            if self.empirical_data is not None:\n",
    "                empirical_dist = get_empirical_dist(self, ridx)\n",
    "                #  ~ 1, snapshots, ntheta(empirical_dist.shape[0])\n",
    "                data[\"empirical\"] = empirical_dist[\n",
    "                    to_bin(data[\"mean_phase_segmentation\"][0], empirical_dist.shape[0])\n",
    "                ].unsqueeze(0)\n",
    "                mask = data[\"mean_phase_segmentation\"].isnan()\n",
    "                data[\"empirical\"][mask] = 1.0 / empirical_dist.shape[0]\n",
    "\n",
    "        data[\"y_rad_binned\"] = (\n",
    "            to_bin(data[\"y_rad\"], self.target_ntheta).unsqueeze(0).to(torch.long)\n",
    "        )\n",
    "        data[\"craft_y_rad_binned\"] = (\n",
    "            to_bin(data[\"craft_y_rad\"], self.target_ntheta).unsqueeze(0).to(torch.long)\n",
    "        )\n",
    "\n",
    "        # convert to target dtype on CPU!\n",
    "        for key in data:\n",
    "            if isinstance(data[key], torch.Tensor) and data[key].dtype in (\n",
    "                torch.float16,\n",
    "                torch.float32,\n",
    "                torch.float64,\n",
    "            ):\n",
    "                data[key] = data[key].to(self.target_dtype)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0][0][\"mean_phase_segmentation\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.segmentation import DEFAULT_SEGMENT_ARGS, segment_session\n",
    "\n",
    "v5inf = v5inferencedataset(\n",
    "    yaml_fn=\"/mnt/md2/2d_wallarray_v2_data/april_nuand/wallarrayv3_2025_04_04_21_06_04_nRX2_rx_random_circle_spacing0p08.yaml\",\n",
    "    nthetas=65,\n",
    "    gpu=False,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    model_config_fn=\"\",\n",
    "    vehicle_type=\"wallarray\",\n",
    "    skip_segmentation=True,\n",
    ")\n",
    "a = ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e13b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"receiver_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = v5inf.write_to_idx(0, 0, data_single_radio_to_raw(a))\n",
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65707073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"simple_segmentations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ba944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_entries(a, b):\n",
    "    for k, v in a.items():\n",
    "        if k in training_only_keys:\n",
    "            continue\n",
    "        assert k in b\n",
    "        vp = b[k]\n",
    "        print(k)\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            assert v.isclose(vp, rtol=1e-3).all(), f\"{v} {vp}\"\n",
    "        elif isinstance(v, List):\n",
    "            s = v[0]\n",
    "            sp = vp[0]\n",
    "            assert len(s) == len(sp)\n",
    "            for idx in range(len(s)):\n",
    "                assert s[idx][\"start_idx\"] == sp[idx][\"start_idx\"]\n",
    "                assert s[idx][\"end_idx\"] == sp[idx][\"end_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.segmentation import DEFAULT_SEGMENT_ARGS, segment_session\n",
    "\n",
    "x = v5inf.write_to_idx(0, 0, data_single_radio_to_raw(ds[0][0]))\n",
    "receiver_idx = 0\n",
    "\n",
    "s = segment_session(\n",
    "    x[\"signal_matrix\"][0][receiver_idx],\n",
    "    gpu=False,\n",
    "    skip_beamformer=False,\n",
    "    skip_detrend=False,\n",
    "    skip_segmentation=True,\n",
    "    **{\n",
    "        \"steering_vectors\": v5inf.steering_vectors[receiver_idx],\n",
    "        **DEFAULT_SEGMENT_ARGS,\n",
    "    },\n",
    ")\n",
    "\n",
    "d = data_from_precomputed(\n",
    "    v5ds=v5inf,\n",
    "    precomputed_data=s,\n",
    "    segmentation=[s],\n",
    "    snapshot_idxs=[0],\n",
    ")\n",
    "\n",
    "s.keys(), d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebff2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a single zarr, receiver and session_idx and segment it\n",
    "from spf.dataset.segmentation import simple_segment\n",
    "from spf.rf import beamformer_given_steering_nomean, reduce_theta_to_positive_y\n",
    "from spf.sdrpluto.detrend import detrend_np\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "\n",
    "def segment_single_session(\n",
    "    raw,\n",
    "    receiver_idx,\n",
    "    skip_beamformer=False,\n",
    "    skip_detrend=False,\n",
    "    **kwrgs,\n",
    "):\n",
    "    v = raw[\"signal_matrix\"][0][receiver_idx]\n",
    "\n",
    "    if not skip_detrend:\n",
    "        v = detrend_np(v)\n",
    "\n",
    "    segmentation_results = simple_segment(v, **kwrgs)\n",
    "\n",
    "    segmentation_results[\"all_windows_stats\"] = (\n",
    "        segmentation_results[\"all_windows_stats\"].astype(np.float16).T\n",
    "    )\n",
    "\n",
    "    # Get dimensions for further processing\n",
    "    _, windows = segmentation_results[\"all_windows_stats\"].shape\n",
    "    nthetas = kwrgs[\"steering_vectors\"].shape[0]  # Number of angle bins for beamforming\n",
    "\n",
    "    if not skip_beamformer:\n",
    "\n",
    "        # CPU version of beamforming (same algorithm but slower)\n",
    "        segmentation_results[\"windowed_beamformer\"] = (\n",
    "            beamformer_given_steering_nomean(\n",
    "                steering_vectors=kwrgs[\"steering_vectors\"],\n",
    "                signal_matrix=v.astype(np.complex64),\n",
    "            )\n",
    "            .reshape(nthetas, -1, kwrgs[\"window_size\"])\n",
    "            .mean(axis=2)\n",
    "            .T\n",
    "        )\n",
    "\n",
    "        # Calculate a weighted beamformer output for the entire session\n",
    "        # by combining window-level beamformer outputs, using the segmentation mask\n",
    "        # as weights (so only signal windows contribute)\n",
    "        weighted_beamformer = (\n",
    "            segmentation_results[\"windowed_beamformer\"].astype(np.float32)\n",
    "            * segmentation_results[\"downsampled_segmentation_mask\"][:, None]\n",
    "        ).sum(axis=0) / (\n",
    "            segmentation_results[\"downsampled_segmentation_mask\"].sum() + 0.001\n",
    "        )\n",
    "\n",
    "        # Convert to float16 to save memory\n",
    "        segmentation_results[\"windowed_beamformer\"] = segmentation_results[\n",
    "            \"windowed_beamformer\"\n",
    "        ].astype(np.float16)\n",
    "\n",
    "        # Store the session-level weighted beamformer\n",
    "        segmentation_results[\"weighted_beamformer\"] = weighted_beamformer\n",
    "    else:\n",
    "        # If skipping beamforming, create empty placeholders\n",
    "        windowed_beamformer = np.zeros((windows, nthetas), dtype=np.float16)\n",
    "        windowed_beamformer.fill(np.nan)\n",
    "        segmentation_results[\"windowed_beamformer\"] = windowed_beamformer\n",
    "\n",
    "    # Calculate session-level statistics from the identified signal windows\n",
    "    if segmentation_results[\"downsampled_segmentation_mask\"].sum() > 0:\n",
    "        # Calculate trimmed mean of phase differences from signal windows only\n",
    "        # Trimming removes extreme values to make the mean more robust\n",
    "        mean_phase = trim_mean(\n",
    "            reduce_theta_to_positive_y(segmentation_results[\"all_windows_stats\"][0])[\n",
    "                segmentation_results[\"downsampled_segmentation_mask\"]\n",
    "            ].astype(np.float32),\n",
    "            0.1,  # Trim 10% from both ends\n",
    "        )\n",
    "\n",
    "        # Calculate trimmed mean of standard deviation and signal amplitude\n",
    "        stddev_and_abs_signal = trim_mean(\n",
    "            segmentation_results[\"all_windows_stats\"][1:][\n",
    "                :, segmentation_results[\"downsampled_segmentation_mask\"]\n",
    "            ].astype(np.float32),\n",
    "            0.1,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # Store the session-level statistics\n",
    "        segmentation_results[\"weighted_stats\"] = np.array(\n",
    "            [mean_phase, stddev_and_abs_signal[0], stddev_and_abs_signal[1]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "    else:\n",
    "        # If no signal windows were identified, use placeholder values\n",
    "        segmentation_results[\"weighted_stats\"] = np.array([-1, -1, -1])\n",
    "\n",
    "    return segmentation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebbf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ee39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"signal_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b737bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in v5rx_f64_keys + v5rx_2xf64_keys:\n",
    "    print(k)\n",
    "    if k in ds[0][0]:\n",
    "        print(ds[0][0][k])\n",
    "    # print(k,getattr(ds[0][0],k,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d23cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e08645",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fn = \"/mnt/md0/2d_wallarray_v2_data/oct_batch2/wallarrayv3_2024_10_26_01_14_28_nRX2_rx_circle_spacing0p075.zarr\"\n",
    "\n",
    "ds1 = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=65,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/mnt/md2/cache/precompute_cache_3p5_chunk1/\",\n",
    "    gpu=False,\n",
    "    snapshots_per_session=1,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    segmentation_version=3.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf65b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=65,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/mnt/md2/cache/precompute_cache_3p6/\",\n",
    "    gpu=False,\n",
    "    snapshots_per_session=1,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    segmentation_version=3.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=65,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/mnt/md2/cache/precompute_cache_3p6x/\",\n",
    "    gpu=False,\n",
    "    snapshots_per_session=1,\n",
    "    n_parallel=8,\n",
    "    paired=True,\n",
    "    segmentation_version=3.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparez(a, b):\n",
    "    for k, v in a.items():\n",
    "        if k not in b:\n",
    "            print(\"B missing\", k)\n",
    "        else:\n",
    "            vb = b[k]\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                if (~v.isfinite()).all():\n",
    "                    pass  # all infinite\n",
    "                elif (v.isclose(vb, rtol=1e-3) * 1.0).mean() > 0.99:\n",
    "                    # print(k,\"pass\")\n",
    "                    # print((v.isclose(vb,rtol=1e-3)*1.0).mean())\n",
    "                    pass\n",
    "                else:\n",
    "                    # print((v.isclose(vb,rtol=1e-3)*1.0).mean())\n",
    "                    print(k, \"fail\", (v.isclose(vb) * 1.0).mean(), v, vb)\n",
    "\n",
    "\n",
    "for idx in range(30):\n",
    "    for ridx in range(2):\n",
    "        z1 = ds1[idx][ridx]\n",
    "        z2 = ds2[idx][ridx]\n",
    "        z3 = ds3[idx][ridx]\n",
    "        comparez(z1, z2)\n",
    "        comparez(z2, z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48583fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "~torch.tensor(torch.inf).isfinite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[0][0][\"windowed_beamformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1[0][0][\"windowed_beamformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146027d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
