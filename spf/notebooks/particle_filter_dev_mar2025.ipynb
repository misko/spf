{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.filters.filters import dual_radio_mse_theta_metrics\n",
    "import torch\n",
    "from spf.filters.filters import (\n",
    "    ParticleFilter,\n",
    "    add_noise,\n",
    "    theta_phi_to_bins,\n",
    ")\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "from spf.rf import rotate_dist, torch_pi_norm_pi\n",
    "from spf.dataset.spf_dataset import v5_collate_keys_fast\n",
    "from spf.model_training_and_inference.models.single_point_networks_inference import (\n",
    "    convert_datasets_config_to_inference,\n",
    "    get_inference_on_ds,\n",
    "    load_model_and_config_from_config_fn_and_checkpoint,\n",
    ")\n",
    "import torch\n",
    "from spf.scripts.train_single_point import (\n",
    "    global_config_to_keys_used,\n",
    "    load_config_from_fn,\n",
    ")\n",
    "\n",
    "nthetas = 65\n",
    "\n",
    "\n",
    "def cached_model_inference_to_absolute_north(ds, cached_model_inference):\n",
    "    _rx_heading = torch.concatenate(\n",
    "        [\n",
    "            torch_pi_norm_pi(\n",
    "                ds.cached_keys[ridx][\"rx_heading_in_pis\"][:, None] * torch.pi\n",
    "            )\n",
    "            for ridx in range(2)\n",
    "        ],\n",
    "        dim=1,\n",
    "    ).reshape(-1, 1)\n",
    "    _cached_model_inference = cached_model_inference.reshape(-1, 65)\n",
    "    cached_model_inference_rotated = rotate_dist(\n",
    "        _cached_model_inference,\n",
    "        rotations=_rx_heading,\n",
    "    ).reshape(cached_model_inference.shape)\n",
    "    return cached_model_inference_rotated\n",
    "\n",
    "\n",
    "class PFSingleThetaDualRadioNN(ParticleFilter):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ds,\n",
    "        checkpoint_fn,\n",
    "        config_fn,\n",
    "        inference_cache=None,\n",
    "        device=\"cpu\",\n",
    "        absolute=False,\n",
    "    ):\n",
    "        self.ds = ds\n",
    "        self.absolute = absolute\n",
    "        self.generator = torch.Generator()\n",
    "        self.generator.manual_seed(0)\n",
    "\n",
    "        checkpoint_config = load_config_from_fn(config_fn)\n",
    "        assert (\n",
    "            self.ds.empirical_data_fn\n",
    "            == checkpoint_config[\"datasets\"][\"empirical_data_fn\"]\n",
    "        )\n",
    "\n",
    "        if not self.ds.temp_file:\n",
    "            # cache model results\n",
    "            self.cached_model_inference = torch.as_tensor(\n",
    "                get_inference_on_ds(\n",
    "                    ds_fn=ds.zarr_fn,\n",
    "                    config_fn=config_fn,\n",
    "                    checkpoint_fn=checkpoint_fn,\n",
    "                    device=device,\n",
    "                    inference_cache=inference_cache,\n",
    "                    batch_size=64,\n",
    "                    workers=0,\n",
    "                    precompute_cache=ds.precompute_cache,\n",
    "                    crash_if_not_cached=False,\n",
    "                )[\"paired\"]\n",
    "            )\n",
    "            if self.absolute:\n",
    "                self.cached_model_inference = cached_model_inference_to_absolute_north(\n",
    "                    ds, self.cached_model_inference\n",
    "                )\n",
    "        else:\n",
    "            # load the model and such\n",
    "            self.model, self.model_config = (\n",
    "                load_model_and_config_from_config_fn_and_checkpoint(\n",
    "                    config_fn=config_fn, checkpoint_fn=checkpoint_fn, device=device\n",
    "                )\n",
    "            )\n",
    "            self.model.eval()\n",
    "\n",
    "            self.model_datasets_config = convert_datasets_config_to_inference(\n",
    "                self.model_config[\"datasets\"],\n",
    "                ds_fn=ds.zarr_fn,\n",
    "                precompute_cache=self.ds.precompute_cache,\n",
    "            )\n",
    "\n",
    "            self.model_optim_config = {\"device\": device, \"dtype\": torch.float32}\n",
    "\n",
    "            self.model_keys_to_get = global_config_to_keys_used(\n",
    "                global_config=self.model_config[\"global\"]\n",
    "            )\n",
    "            assert not self.absolute  # this needs to be implemented\n",
    "\n",
    "    def model_inference_at_observation_idx(self, idx):\n",
    "        if not self.ds.temp_file:\n",
    "            return self.cached_model_inference[idx]\n",
    "\n",
    "        z = v5_collate_keys_fast(self.model_keys_to_get, [self.ds[idx]]).to(\n",
    "            self.model_optim_config[\"device\"]\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            return self.model(z)[\"paired\"].cpu()\n",
    "\n",
    "    def observation(self, idx):\n",
    "        # even though the model outputs one paired dist for each reciever\n",
    "        # they should be identical\n",
    "        return self.model_inference_at_observation_idx(idx)[0, 0]\n",
    "\n",
    "    def fix_particles(self):\n",
    "        self.particles[:, 0] = torch_pi_norm_pi(self.particles[:, 0])\n",
    "\n",
    "    def predict(self, our_state, dt, noise_std):\n",
    "        if noise_std is None:\n",
    "            noise_std = torch.tensor([[0.1, 0.001]])\n",
    "        self.particles[:, 0] += dt * self.particles[:, 1]\n",
    "        add_noise(self.particles, noise_std=noise_std, generator=self.generator)\n",
    "\n",
    "    def update(self, z):\n",
    "        #\n",
    "        # z is not the raw observation, but the processed model output\n",
    "        theta_bin = theta_phi_to_bins(self.particles[:, 0], nbins=z.shape[0])\n",
    "        prob_theta_given_observation = torch.take(z, theta_bin)\n",
    "\n",
    "        self.weights *= prob_theta_given_observation\n",
    "        self.weights += 1.0e-30  # avoid round-off to zero\n",
    "        self.weights /= torch.sum(self.weights)  # normalize\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        return dual_radio_mse_theta_metrics(\n",
    "            trajectory,\n",
    "            (\n",
    "                self.ds.craft_ground_truth_thetas\n",
    "                if not self.absolute\n",
    "                else self.ds.absolute_thetas.mean(axis=0)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def trajectory(self, **kwargs):\n",
    "        trajectory = super().trajectory(**kwargs)\n",
    "        for x in trajectory:\n",
    "            x[\"craft_theta\"] = x[\"mu\"][0]\n",
    "            x[\"P_theta\"] = x[\"var\"][0]\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_traj(ds, traj_paired):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "    ax[1].axhline(y=torch.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1].axhline(y=-torch.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    n = len(traj_paired)\n",
    "    colors = [\"blue\", \"orange\"]\n",
    "    for rx_idx in (0, 1):\n",
    "        ax[0].scatter(\n",
    "            range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "            ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "            label=f\"r{rx_idx} estimated phi\",\n",
    "            s=1.0,\n",
    "            alpha=0.1,\n",
    "            color=colors[rx_idx],\n",
    "        )\n",
    "        ax[0].plot(\n",
    "            ds.ground_truth_phis[rx_idx][:n],\n",
    "            color=colors[rx_idx],\n",
    "            label=f\"r{rx_idx} perfect phi\",\n",
    "            linestyle=\"dashed\",\n",
    "        )\n",
    "\n",
    "    ax[1].plot(\n",
    "        # torch_pi_norm_pi(ds[0][0][\"craft_y_rad\"][0]),\n",
    "        torch_pi_norm_pi(ds.craft_ground_truth_thetas),\n",
    "        label=\"craft gt theta\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    ax[1].plot(\n",
    "        torch_pi_norm_pi(ds.absolute_thetas.mean(axis=0)),\n",
    "        label=\"absolute theta\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "\n",
    "    xs = torch.hstack([x[\"mu\"][0] for x in traj_paired])\n",
    "    stds = torch.sqrt(torch.hstack([x[\"var\"][0] for x in traj_paired]))\n",
    "\n",
    "    ax[1].fill_between(\n",
    "        torch.arange(xs.shape[0]),\n",
    "        xs - stds,\n",
    "        xs + stds,\n",
    "        label=\"PF-std\",\n",
    "        color=\"red\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    ax[1].scatter(range(xs.shape[0]), xs, label=\"PF-x\", color=\"orange\", s=0.5)\n",
    "\n",
    "    ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title(f\"Radio 0 & 1\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(\"time step\")\n",
    "    ax[1].set_ylabel(\"Theta between target and receiver craft\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fn = \"/home/mouse9911/gits/spf/checkpoints/march16/paired_wd0p02_gains_vehicle_0p2dropout_noroverbounceREAL_lowdrop_x2/config.yml\"\n",
    "checkpoint_fn = \"/home/mouse9911/gits/spf/checkpoints/march16/paired_wd0p02_gains_vehicle_0p2dropout_noroverbounceREAL_lowdrop_x2/best.pth\"\n",
    "\n",
    "empirical_data_fn = \"/home/mouse9911/gits/spf/empirical_dists/full.pkl\"\n",
    "precompute_cache = \"/mnt/md2/cache/precompute_cache_3p5_chunk1/\"\n",
    "inference_cache = \"/mnt/md2/cache/inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = v5spfdataset(\n",
    "    \"/mnt/md2/cache/nosig_data/wallarrayv3_2024_08_21_03_09_04_nRX2_rx_circle_spacing0p05075.zarr\",\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=precompute_cache,\n",
    "    empirical_data_fn=empirical_data_fn,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")\n",
    "pf = PFSingleThetaDualRadioNN(\n",
    "    ds,\n",
    "    device=\"cpu\",\n",
    "    config_fn=config_fn,\n",
    "    checkpoint_fn=checkpoint_fn,\n",
    "    inference_cache=inference_cache,\n",
    "    absolute=True,\n",
    ")\n",
    "\n",
    "trajectory = pf.trajectory(\n",
    "    mean=torch.tensor([[0, 0]]),\n",
    "    std=torch.tensor([[1, 0.1]]),\n",
    "    return_particles=False,\n",
    "    debug=True,\n",
    "    N=512 * 16,  # * 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(ds, traj_paired=trajectory)\n",
    "metrics = pf.metrics(trajectory=trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = v5spfdataset(\n",
    "    # \"/mnt/md2/cache/nosig_data/wallarrayv3_2024_08_21_03_09_04_nRX2_rx_circle_spacing0p05075.zarr\",\n",
    "    \"/mnt/md2/cache/nosig_data/rover_2025_03_02_22_20_28_nRX2_center_spacing0p043_tag_RO3.rover_2025_03_02_22_19_58_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=precompute_cache,\n",
    "    empirical_data_fn=empirical_data_fn,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")\n",
    "pf = PFSingleThetaDualRadioNN(\n",
    "    ds,\n",
    "    device=\"cpu\",\n",
    "    config_fn=config_fn,\n",
    "    checkpoint_fn=checkpoint_fn,\n",
    "    inference_cache=inference_cache,\n",
    "    absolute=True,\n",
    ")\n",
    "\n",
    "trajectory = pf.trajectory(\n",
    "    mean=torch.tensor([[0, 0]]),\n",
    "    std=torch.tensor([[1, 0.1]]),\n",
    "    return_particles=False,\n",
    "    debug=True,\n",
    "    N=512 * 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(ds, traj_paired=trajectory)\n",
    "metrics = pf.metrics(trajectory=trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = v5spfdataset(\n",
    "    # \"/mnt/md2/cache/nosig_data/wallarrayv3_2024_08_21_03_09_04_nRX2_rx_circle_spacing0p05075.zarr\",\n",
    "    \"/mnt/md2/cache/nosig_data/rover_2025_03_22_19_21_42_nRX2_diamond_spacing0p035_tag_RO1.rover_2025_03_22_19_21_01_nRX1_circle_spacing0p05075_tag_RO2.zarr\",\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=precompute_cache,\n",
    "    empirical_data_fn=empirical_data_fn,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")\n",
    "pf = PFSingleThetaDualRadioNN(\n",
    "    ds,\n",
    "    device=\"cpu\",\n",
    "    config_fn=config_fn,\n",
    "    checkpoint_fn=checkpoint_fn,\n",
    "    inference_cache=inference_cache,\n",
    "    absolute=True,\n",
    ")\n",
    "\n",
    "trajectory = pf.trajectory(\n",
    "    mean=torch.tensor([[0, 0]]),\n",
    "    std=torch.tensor([[1, 0.1]]),\n",
    "    # noise_std=torch.tensor([[0.01, 0.001]]),\n",
    "    return_particles=False,\n",
    "    debug=True,\n",
    "    N=512 * 16 * 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pf.metrics(trajectory=trajectory)\n",
    "print(metrics)\n",
    "plot_traj(ds, traj_paired=trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_model_inference = torch.as_tensor(\n",
    "    get_inference_on_ds(\n",
    "        ds_fn=ds.zarr_fn,\n",
    "        config_fn=config_fn,\n",
    "        checkpoint_fn=checkpoint_fn,\n",
    "        device=\"cpu\",\n",
    "        inference_cache=inference_cache,\n",
    "        batch_size=64,\n",
    "        workers=0,\n",
    "        precompute_cache=ds.precompute_cache,\n",
    "        crash_if_not_cached=False,\n",
    "    )[\"paired\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cached_model_inference[:100, 1, 0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import rotate_dist\n",
    "\n",
    "# correct predictions to be relative to true north\n",
    "_rx_heading = torch.concatenate(\n",
    "    [\n",
    "        torch_pi_norm_pi(ds.cached_keys[ridx][\"rx_heading_in_pis\"][:, None] * torch.pi)\n",
    "        for ridx in range(2)\n",
    "    ],\n",
    "    dim=1,\n",
    ").reshape(-1, 1)\n",
    "_cached_model_inference = cached_model_inference.reshape(-1, 65)\n",
    "cached_model_inference_rotated = rotate_dist(\n",
    "    _cached_model_inference,\n",
    "    rotations=_rx_heading,\n",
    ").reshape(cached_model_inference.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cached_model_inference_rotated[:100, 1, 0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cached_keys[0][\"rx_heading_in_pis\"][:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concatenate(\n",
    "    [\n",
    "        ds.cached_keys[ridx][\"rx_heading_in_pis\"][:, None] * 0 + ridx\n",
    "        for ridx in range(2)\n",
    "    ],\n",
    "    dim=1,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_model_inference.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cached_model_inference.clone()\n",
    "a[0, 0] = 0\n",
    "a[0, 1] = 1\n",
    "a.reshape(-1, 65)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
