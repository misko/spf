{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from spf.dataset.fake_dataset import create_fake_dataset, fake_yaml\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "n = 1025\n",
    "noise = 1.0\n",
    "nthetas = 65\n",
    "orbits = 4\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "tmpdirname = tmpdir.name\n",
    "ds_fn = f\"{tmpdirname}/sample_dataset_for_ekf_n{n}_noise{noise}\"\n",
    "\n",
    "create_fake_dataset(\n",
    "    filename=ds_fn, yaml_config_str=fake_yaml, n=n, noise=noise, orbits=orbits\n",
    ")\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=tmpdirname,\n",
    "    paired=True,\n",
    "    skip_signal_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=tmpdirname,\n",
    "    paired=True,\n",
    "    skip_signal_matrix=True,\n",
    "    gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "# ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "\n",
    "\n",
    "nthetas = 65\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/home/mouse9911/precompute_cache_chunk16\",\n",
    "    paired=True,\n",
    "    skip_signal_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_prefix = \"./\" + os.path.basename(ds_fn) + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[rx_idx].scatter(\n",
    "        range(len(ds)),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"radio{rx_idx} est phi\",\n",
    "        s=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\", color=\"blue\")\n",
    "    ax[rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(len(ds))],\n",
    "        label=f\"radio{rx_idx} gt theta\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    ax[rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[rx_idx].set_xlabel(\"Time step\")\n",
    "    ax[rx_idx].set_ylabel(\"tehta/phi\")\n",
    "    ax[rx_idx].legend()\n",
    "    ax[rx_idx].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "fig.suptitle(\"Phase(phi) recovered from radios after segmentation\")\n",
    "fig.savefig(f\"{output_prefix}_raw_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "x = [ theta dtheta/dt ]\n",
    "z = [ phi ]\n",
    "\n",
    "F = [ [ 1 dt ],\n",
    "      [ 0  1 ]]\n",
    "\n",
    "h(x) = sin(x[0]) * (d * 2 * pi / wavelength )\n",
    "\n",
    "H(x) = [ dh/dx_1 , dh/dx_2 ] = cos(x[0]) * (d * 2 * pi / wavelength )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def hx(x):\n",
    "    return np.array([np.sin(x[0, 0]) * antenna_spacing * 2 * np.pi / wavelength])\n",
    "\n",
    "\n",
    "def HJacobian_at(x):\n",
    "    \"\"\"compute Jacobian of H matrix at x\"\"\"\n",
    "    r = np.array([[np.cos(x[0, 0]) * antenna_spacing * 2 * np.pi / wavelength, 0]])\n",
    "    # if np.abs(r[0,0])<0.1:\n",
    "    #    r=r*0+np.sign(r)*0.1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "Q_discrete_white_noise(2, dt=1.0, var=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "x = 1.9 * np.pi\n",
    "y = -1.9 * np.pi\n",
    "for x in np.linspace(-np.pi, np.pi, 32):\n",
    "    for y in np.linspace(-np.pi, np.pi, 32):\n",
    "        assert np.isclose(residual(x, y), pi_norm(x - y), atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import pi_norm_halfpi, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "@cache\n",
    "def Q_discrete_white_noise_cached(**kwargs):\n",
    "    return Q_discrete_white_noise(**kwargs)\n",
    "\n",
    "\n",
    "@cache\n",
    "def F_cached(dt):\n",
    "    return np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "\n",
    "class SingleRadioConstantTheta(ExtendedKalmanFilter):\n",
    "\n",
    "    def __init__(self, phi_std=0.5, p=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "    def R_at_x(self):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(self.x[0, 0])) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        self.x[0] = pi_norm_halfpi(self.x[0])\n",
    "        return\n",
    "        while np.abs(self.x[0]) > np.pi / 2:\n",
    "            if self.debug:\n",
    "                print(\"FLIPPING\", self.x)\n",
    "            self.x[0] = np.sign(self.x[0]) * np.pi - self.x[0]\n",
    "            self.x[1] *= -1\n",
    "            if self.debug:\n",
    "                print(\"FLIPPED\", self.x)\n",
    "\n",
    "    ###\n",
    "    #    x[0] = theta , ?\n",
    "    #    x[1] = theta dot , ? / s\n",
    "    ###\n",
    "    def predict(self, dt, q_var):\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=q_var\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "        # do some house keeping\n",
    "        self.x_prior = np.copy(self.x)\n",
    "        self.P_prior = np.copy(self.P)\n",
    "\n",
    "    def update(self, z):\n",
    "        if self.debug:\n",
    "            print(\"DEBUG\")\n",
    "        # find a good z!\n",
    "        # print(self.R.shape)\n",
    "        # if z is > 0 consider z and z-2*pi\n",
    "        # if z is < 0 consider z and z+2*pi\n",
    "        # if abs(self.x[0]) > 1.5:\n",
    "        #     predict_phi = hx(self.x)[0]\n",
    "        #     candidates = np.array([z, z - np.sign(z) * np.pi])\n",
    "        #     closer_candidate = np.argmax(-np.abs(predict_phi - candidates))\n",
    "        #     z = candidates[closer_candidate]\n",
    "        # self.R = np.eye(2) * self.R_at_x(self.x)\n",
    "        # print(closer_candidate, np.abs(predict_phi - candidates))\n",
    "        # r = np.array([[self.R_at_x()]]) * 30\n",
    "        r = (np.array([[self.R_at_x()]]) ** 2) * 5\n",
    "        if self.debug:\n",
    "            print(\"R\", r)\n",
    "            print(\"P\", self.P)\n",
    "        super().update(\n",
    "            # np.array([[z]]),\n",
    "            np.array([[z]]),\n",
    "            HJacobian_at,\n",
    "            hx,\n",
    "            residual=residual,\n",
    "            R=r,\n",
    "        )\n",
    "        # self.x[0] = reduce_theta_to_positive_y(self.x[0])\n",
    "        self.fix_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_for_phi(rx_idx, ds):\n",
    "    ekf = SingleRadioConstantTheta(dim_x=2, dim_z=1, phi_std=5.0, p=5)\n",
    "    ekf.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "    traj = []\n",
    "    n = 48 + len(ds)\n",
    "    jacobian = []\n",
    "    zs = []\n",
    "    for idx in range(min(n, len(ds))):\n",
    "        # ekf.predict(dt=0.1, q_var=0.3) # simulated data\n",
    "        z = ds[idx][rx_idx][\"mean_phase_segmentation\"]\n",
    "        debug = idx >= n - 8\n",
    "        ekf.debug = debug\n",
    "        if debug:\n",
    "            print(idx, \"X\", ekf.x)\n",
    "            print(idx, \"z\", z)\n",
    "        # ekf.predict(dt=1.0, q_var=0.003)\n",
    "        ekf.predict(dt=0.05, q_var=0.3)\n",
    "        if debug:\n",
    "            print(idx, \"X^'\", ekf.x)\n",
    "        ekf.update(z)\n",
    "        zs.append(z)\n",
    "        jacobian.append(HJacobian_at(ekf.x)[0, 0])\n",
    "        if debug:\n",
    "            print(idx, \"X^\", ekf.x)\n",
    "        traj.append({\"theta\": ekf.x[0, 0], \"P_theta\": ekf.P[0, 0]})\n",
    "    return traj, jacobian, zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory, jacobian = trajectory_for_phi(0, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds[450][0][\"windowed_beamformer\"].mean(axis=0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mean_phase[f\"r{rx_idx}\"][450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    trajectory, jacobian, zs = trajectory_for_phi(rx_idx, ds)\n",
    "    jacobian = np.array(jacobian)\n",
    "    zs = np.array(zs)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[0, rx_idx].plot(jacobian, label=\"jacobian\")\n",
    "    ax[0, rx_idx].plot(zs, label=\"zs\")\n",
    "    ax[0, rx_idx].plot(np.clip(zs / jacobian, a_min=-5, a_max=5), label=\"zs/j\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "    ax[1, rx_idx].fill_between(\n",
    "        np.arange(xs.shape[0]),\n",
    "        xs - stds,\n",
    "        xs + stds,\n",
    "        label=\"EKF-std\",\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "from spf.rf import pi_norm, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def trajectory_for_phi(rx_idx, ds):\n",
    "    rk = ExtendedKalmanFilter(dim_x=2, dim_z=1)\n",
    "    # initialize with first ground truth state\n",
    "    y_rad = ds[rx_idx][0][\"ground_truth_theta\"].item()\n",
    "    # y_rad_reduced=reduce_theta_to_positive_y(y_rad)\n",
    "    rk.x = np.array([[y_rad], [0]])\n",
    "\n",
    "    # dt = 0.1  # 1.0  # 0.1\n",
    "    dt = 0.1  # 1.0  # 0.1\n",
    "    rk.F = np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "    phi_std = 0.5\n",
    "    rk.R = phi_std**2  # np.diag([phi_std**2])\n",
    "    # TODO R:\n",
    "    # Use gt state x to get a good R, then worry about how to use estimated x\n",
    "    # Motion model , f , wrap around\n",
    "    # make class for motion model and measurement model\n",
    "    # Plot how x and p evolve\n",
    "    rk.Q = Q_discrete_white_noise(2, dt=dt, var=0.3)\n",
    "    rk.P *= 5  # initialized as identity?\n",
    "\n",
    "    traj = []\n",
    "    for idx in range(len(ds)):\n",
    "        rk.update(\n",
    "            np.array([ds[idx][rx_idx][\"mean_phase_segmentation\"]]),\n",
    "            HJacobian_at,\n",
    "            hx,\n",
    "            residual=residual,\n",
    "        )\n",
    "        traj.append(rk.x[0, 0])\n",
    "        rk.predict()\n",
    "        rk.x = pi_norm(rk.x)  # this should not be for theta dot ! TODO BUG!\n",
    "    return np.array(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(ds.mean_phase[f\"r{rx_idx}\"].shape[0]),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(len(ds))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    ax[1, rx_idx].plot(trajectory_for_phi(rx_idx, ds), label=\"EKF\")\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired EKF\n",
    "\n",
    "offsets = [\n",
    "    ds.yaml_config[\"receivers\"][0][\"theta-in-pis\"] * np.pi,\n",
    "    ds.yaml_config[\"receivers\"][1][\"theta-in-pis\"] * np.pi,\n",
    "]\n",
    "\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def hx_paired(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0, 0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "            np.sin(x[0, 0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def HJacobian_at_paired(x):\n",
    "    \"\"\"compute Jacobian of H matrix at x\"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                np.cos(x[0, 0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "                0,\n",
    "            ],\n",
    "            [\n",
    "                np.cos(x[0, 0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "                0,\n",
    "            ],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "from spf.rf import pi_norm, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def residual_paired(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([residual(a[0], b[0]), residual(a[1], b[1])])\n",
    "\n",
    "\n",
    "def trajectory_for_phi_paired(ds):\n",
    "    rk = ExtendedKalmanFilter(dim_x=2, dim_z=2)\n",
    "    # initialize with first ground truth state\n",
    "    y_rad = ds[rx_idx][0][\"ground_truth_theta\"].item()\n",
    "    # y_rad_reduced=reduce_theta_to_positive_y(y_rad)\n",
    "    rk.x = np.array([[y_rad], [0]])\n",
    "\n",
    "    dt = 0.05\n",
    "    rk.F = np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "    phi_std = 0.5\n",
    "    rk.R *= phi_std**2  # can this change dependent on state?\n",
    "    rk.Q = Q_discrete_white_noise(2, dt=dt, var=1.0)\n",
    "    rk.P *= 0.1  # initialized as identity?\n",
    "\n",
    "    traj = []\n",
    "    for idx in range(len(ds)):\n",
    "        rk.update(\n",
    "            np.array(\n",
    "                [\n",
    "                    [ds[idx][0][\"mean_phase_segmentation\"]],\n",
    "                    [ds[idx][1][\"mean_phase_segmentation\"]],\n",
    "                ]\n",
    "            ),\n",
    "            HJacobian_at_paired,\n",
    "            hx_paired,\n",
    "            residual=residual_paired,\n",
    "        )\n",
    "        traj.append(rk.x[0, 0])\n",
    "        rk.predict()\n",
    "        rk.x = pi_norm(rk.x)\n",
    "    return np.array(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[rx_idx].scatter(\n",
    "        range(ds.mean_phase[f\"r{rx_idx}\"].shape[0]),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\")\n",
    "\n",
    "    ax[rx_idx].legend()\n",
    "    ax[rx_idx].set_xlabel(\"time step\")\n",
    "    ax[rx_idx].set_ylabel(\"phi\")\n",
    "    ax[rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "\n",
    "ax[2].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "ax[2].set_title(\"Paired radio EKF\")\n",
    "ax[2].plot(trajectory_for_phi_paired(ds), label=\"EKF\")\n",
    "\n",
    "ax[2].legend()\n",
    "fig.suptitle(\"EKF: When two (radios) become one\")\n",
    "fig.savefig(f\"{output_prefix}_when_two_become_one_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y, pi_norm\n",
    "\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "\n",
    "@cache\n",
    "def Q_discrete_white_noise_cached(**kwargs):\n",
    "    return Q_discrete_white_noise(**kwargs)\n",
    "\n",
    "\n",
    "@cache\n",
    "def F_cached(dt):\n",
    "    return np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "\n",
    "class DualRadioConstantTheta(ExtendedKalmanFilter):\n",
    "\n",
    "    def __init__(self, phi_std=0.5, p=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P[0, 0] *= p  # initialized as identity?\n",
    "        self.P[1, 1] *= 0.1\n",
    "\n",
    "    def R_at_x(self, x_for_radio):\n",
    "        # return 30  # return 1.5\n",
    "        # return 30 + +2.5 * np.exp(-((abs(x_for_radio) - np.pi / 2) ** 2)) * 30\n",
    "        return (5 + np.exp(-((abs(x_for_radio) - np.pi / 2) ** 2))) ** 2\n",
    "\n",
    "    ###\n",
    "    #    x[0] = theta , ?\n",
    "    #    x[1] = theta dot , ? / s\n",
    "    ###\n",
    "    def predict(self, dt, q_var):\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=q_var\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.x[0] = pi_norm(self.x[0])\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "        # do some house keeping\n",
    "        self.x_prior = np.copy(self.x)\n",
    "        self.P_prior = np.copy(self.P)\n",
    "\n",
    "    def update(self, z):\n",
    "        # find a good z!\n",
    "        r = np.array(\n",
    "            [\n",
    "                [self.R_at_x(pi_norm(self.x[0, 0] - offsets[0])), 0],\n",
    "                [0, self.R_at_x(pi_norm(self.x[0, 0] - offsets[1]))],\n",
    "            ]\n",
    "        )\n",
    "        super().update(\n",
    "            # np.array([[z]]),\n",
    "            np.array(z),\n",
    "            HJacobian_at_paired,\n",
    "            hx_paired,\n",
    "            residual=residual_paired,\n",
    "            R=r,\n",
    "        )\n",
    "        # self.x[0] = reduce_theta_to_positive_y(self.x[0])\n",
    "        self.x[0] = pi_norm(self.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_for_phi_paired(ds):\n",
    "    ekf = DualRadioConstantTheta(dim_x=2, dim_z=1, phi_std=0.0, p=5)\n",
    "    ekf.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "    traj = []\n",
    "    for idx in range(min(25000, len(ds))):\n",
    "        # ekf.predict(dt=0.1, q_var=0.3) # simulated data\n",
    "        ekf.predict(dt=0.05, q_var=1.0)  # works for paired\n",
    "        # ekf.predict(dt=1.0, q_var=0.001)\n",
    "        ekf.update(\n",
    "            np.array(\n",
    "                [\n",
    "                    [ds[idx][0][\"mean_phase_segmentation\"]],\n",
    "                    [ds[idx][1][\"mean_phase_segmentation\"]],\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        traj.append({\"theta\": ekf.x[0, 0], \"P_theta\": ekf.P[0, 0]})\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "ax[1].fill_between(\n",
    "    np.arange(xs.shape[0]),\n",
    "    xs - stds,\n",
    "    xs + stds,\n",
    "    label=\"EKF-std\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=0.05, var=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=1.0, var=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt):\n",
    "    F = F_cached(dt)\n",
    "    return np.dot(F, x)\n",
    "\n",
    "\n",
    "def hx_paired_ukf(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "            np.sin(x[0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def ukf_paired_residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([residual(a[0], b[0]), residual(a[1], b[1])])\n",
    "\n",
    "\n",
    "def ukf_paired_residual_x(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([pi_norm(a[0] - b[0]), a[0] - b[0]])\n",
    "\n",
    "\n",
    "def state_mean(sigmas, Wm):\n",
    "    x = np.zeros(2)\n",
    "    sum_sin, sum_cos = 0.0, 0.0\n",
    "\n",
    "    for i in range(len(sigmas)):\n",
    "        s = sigmas[i]\n",
    "        x[1] += s[1] * Wm[i]\n",
    "        sum_sin += np.sin(s[0]) * Wm[i]\n",
    "        sum_cos += np.cos(s[0]) * Wm[i]\n",
    "    x[1] /= len(sigmas)\n",
    "    x[0] = np.arctan2(sum_sin, sum_cos)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman.sigma_points import MerweScaledSigmaPoints\n",
    "from filterpy.kalman import UnscentedKalmanFilter\n",
    "\n",
    "dt = 1.0\n",
    "points = MerweScaledSigmaPoints(2, alpha=0.1, beta=2.0, kappa=0)  # -1)\n",
    "kf = UnscentedKalmanFilter(\n",
    "    dim_x=2,\n",
    "    dim_z=2,\n",
    "    dt=dt,\n",
    "    fx=fx,\n",
    "    hx=hx_paired_ukf,\n",
    "    points=points,\n",
    "    residual_z=ukf_paired_residual,\n",
    "    # x_mean_fn=state_mean,\n",
    "    residual_x=ukf_paired_residual_x,\n",
    ")\n",
    "kf.x = np.array([0, 0])  # initial state\n",
    "kf.P[0, 0] *= 5  # initial uncertainty\n",
    "kf.P[1, 1] *= 0.2  # initial uncertainty\n",
    "z_std = 5\n",
    "kf.R = np.diag([z_std**2, z_std**2])  # 1 standard\n",
    "kf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=0.01**2)\n",
    "\n",
    "trajectory = []\n",
    "\n",
    "#    for idx in range(min(2500, len(ds))):\n",
    "for idx in range(min(800, len(ds))):\n",
    "    print(kf.x)\n",
    "    kf.predict()\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    # kf.x[0] = pi_norm(kf.x[0])\n",
    "    print(kf.x)\n",
    "    z = np.array(\n",
    "        [\n",
    "            ds[idx][0][\"mean_phase_segmentation\"],\n",
    "            ds[idx][1][\"mean_phase_segmentation\"],\n",
    "        ]\n",
    "    )\n",
    "    # print(kf.x)\n",
    "    kf.update(z)\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    trajectory.append({\"theta\": kf.x[0]})  # , \"P_theta\": ekf.P[0, 0]})\n",
    "    # print(kf.x, \"log-likelihood\", kf.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "# trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "# stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "# zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "# ax[1].fill_between(\n",
    "#     np.arange(xs.shape[0]),\n",
    "#     xs - stds,\n",
    "#     xs + stds,\n",
    "#     label=\"EKF-std\",\n",
    "#     color=\"orange\",\n",
    "#     alpha=0.2,\n",
    "# )\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a particle filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianWalk(pypfilt.Model):\n",
    "    def field_types(self, ctx):\n",
    "        return [(\"x\", np.dtype(float))]\n",
    "\n",
    "    def update(self, ctx, time_step, is_fs, prev, curr):\n",
    "        \"\"\"Perform a single time-step.\"\"\"\n",
    "        rnd = ctx.component[\"random\"][\"model\"]\n",
    "        step = rnd.normal(loc=0, scale=1, size=curr.shape)\n",
    "        curr[\"x\"] = prev[\"x\"] + step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lorenz63(OdeModel):\n",
    "    def field_types(self, ctx):\n",
    "        r\"\"\"\n",
    "        Define the state vector :math:`[\\sigma, \\rho, \\beta, x, y, z]^T`.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (\"tehta\", float),\n",
    "            (\"tehta_vel\", float),\n",
    "        ]\n",
    "\n",
    "    def d_dt(self, time, xt, ctx, is_forecast):\n",
    "        rates = np.zeros(xt.shape, xt.dtype)\n",
    "        rates[\"theta\"] = xt[\"tehta_vel\"]\n",
    "        return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "import numpy as np\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "\n",
    "ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "# ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "\n",
    "\n",
    "nthetas = 65\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/home/mouse9911/precompute_cache_chunk16\",\n",
    "    paired=True,\n",
    "    skip_signal_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "full_p = pickle.load(open(\"full_p.pkl\", \"rb\"))[\"full_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def fix_particles(particles):\n",
    "    while np.abs(particles[:, 0]).max() > np.pi / 2:\n",
    "        mask = np.abs(particles[:, 0]) > np.pi / 2\n",
    "        particles[mask, 0] = np.sign(particles[mask, 0]) * np.pi - particles[mask, 0]\n",
    "        particles[mask, 1] *= -1\n",
    "    return particles\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "def pf_trajectory_for_phi(rx_idx, ds):\n",
    "    N = 128 * 8\n",
    "    particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "    weights = np.ones((N,)) / N\n",
    "    trajectory = []\n",
    "    thetas = []\n",
    "    vs = []\n",
    "    for idx in range(len(ds)):\n",
    "        particles = fix_particles(particles)\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles = fix_particles(particles)\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles = fix_particles(particles)\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(\n",
    "#     np.array(\n",
    "#         [\n",
    "#             theta_phi_to_p(np.pi / 4, phi, full_p)\n",
    "#             for phi in np.linspace(-np.pi, np.pi, 50)\n",
    "#         ]\n",
    "#     ).reshape(-1, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in thetas]\n",
    "# y = [p[1] for p in thetas]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in vs]\n",
    "# y = [p[1] for p in vs]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0, 1]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    trajectory = pf_trajectory_for_phi(rx_idx, ds)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    # stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    # zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"PF-x\", color=\"orange\")\n",
    "    # ax[1, rx_idx].fill_between(\n",
    "    #     np.arange(xs.shape[0]),\n",
    "    #     xs - stds,\n",
    "    #     xs + stds,\n",
    "    #     label=\"EKF-std\",\n",
    "    #     color=\"orange\",\n",
    "    #     alpha=0.2,\n",
    "    # )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    # ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import pi_norm\n",
    "\n",
    "pi_norm(0.99 * np.pi - (-0.99 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS WORKS\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights[1:][change_mask] *= 0.75\n",
    "    weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        #weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8 *8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKS2\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.01\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
