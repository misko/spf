{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from spf.dataset.fake_dataset import create_fake_dataset, fake_yaml\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "n = 1025\n",
    "noise = 0.3\n",
    "nthetas = 65\n",
    "orbits = 4\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "tmpdirname = tmpdir.name\n",
    "temp_ds_fn = f\"{tmpdirname}/sample_dataset_for_ekf_n{n}_noise{noise}\"\n",
    "\n",
    "create_fake_dataset(\n",
    "    filename=temp_ds_fn, yaml_config_str=fake_yaml, n=n, noise=noise, orbits=orbits\n",
    ")\n",
    "ds = v5spfdataset(\n",
    "    temp_ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=tmpdirname,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_data = False\n",
    "if use_real_data:\n",
    "    ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "    # ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "    precompute_cache_dir = \"/home/mouse9911/precompute_cache_chunk16_sept\"\n",
    "else:\n",
    "    ds_fn = temp_ds_fn\n",
    "    precompute_cache_dir = tmpdirname\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=precompute_cache_dir,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPFFilter:\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the known state : i.e. RX position\n",
    "    \"\"\"\n",
    "\n",
    "    def our_state(self, idx):\n",
    "        return None\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, our_state, dt, noise_std) -> None:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx use the internally\n",
    "    \"\"\"\n",
    "\n",
    "    def update(self) -> None:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions):\n",
    "        pass\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(self, initial_conditions={}, dt=1.0, noise_std=0.01):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        for idx in range(len(self.ds)):\n",
    "            prior = self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "                our_state=self.our_state(idx),\n",
    "            )\n",
    "\n",
    "            posterior = self.update(prior=prior, observation=self.observation(idx))\n",
    "\n",
    "            trajectory.append(self.posterior_to_mu_var(posterior))\n",
    "\n",
    "        return {\"trajectory\": trajectory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_prefix = \"./\" + os.path.basename(ds_fn) + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[rx_idx].scatter(\n",
    "        range(len(ds)),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"radio{rx_idx} est phi\",\n",
    "        s=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\", color=\"blue\")\n",
    "    ax[rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(len(ds))],\n",
    "        label=f\"radio{rx_idx} gt theta\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    ax[rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[rx_idx].set_xlabel(\"Time step\")\n",
    "    ax[rx_idx].set_ylabel(\"tehta/phi\")\n",
    "    ax[rx_idx].legend()\n",
    "    ax[rx_idx].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "fig.suptitle(\"Phase(phi) recovered from radios after segmentation\")\n",
    "fig.savefig(f\"{output_prefix}_raw_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "\"\"\"\n",
    "x = [ theta dtheta/dt ]\n",
    "z = [ phi ]\n",
    "\n",
    "F = [ [ 1 dt ],\n",
    "      [ 0  1 ]]\n",
    "\n",
    "h(x) = sin(x[0]) *  2 * pi  * (d/ wavelength )\n",
    "\n",
    "H(x) = [ dh/dx_1 , dh/dx_2 ] = [ cos(x[0]) * 2 * pi (d/ wavelength ) , 0]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Convert a state (x) representing [ theta dtheta/dt ] into an observation of phi\n",
    "given the spacing between antennas as a fraction of wavelength\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def h_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths):\n",
    "    assert x.ndim == 2 and x.shape[0] == 2 and x.shape[1] == 1\n",
    "    return np.array([np.sin(x[0, 0]) * 2 * np.pi * antenna_spacing_in_wavelengths])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Compute the derivative of the observation generated from state x (theta,dtheta/dt)\n",
    "with respect to state variables (theta,dtheta/dt)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def hjacobian_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths):\n",
    "    assert x.ndim == 2 and x.shape[0] == 2 and x.shape[1] == 1\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                np.cos(x[0, 0]) * 2 * np.pi * antenna_spacing_in_wavelengths,\n",
    "                0,\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def single_h_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths):\n",
    "    assert x[0, 0] >= -np.pi / 2 and x[0, 0] <= np.pi / 2\n",
    "    return h_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths)\n",
    "\n",
    "\n",
    "def single_hjacobian_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths\n",
    "):\n",
    "    assert x[0, 0] >= -np.pi / 2 and x[0, 0] <= np.pi / 2\n",
    "    return hjacobian_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "(np.array([-np.pi * 0.7])) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "from functools import cache, partial\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "\n",
    "@cache\n",
    "def Q_discrete_white_noise_cached(**kwargs):\n",
    "    return Q_discrete_white_noise(**kwargs)\n",
    "\n",
    "\n",
    "@cache\n",
    "def F_cached(dt):\n",
    "    return np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # we are dealing in phi space here, not theta space\n",
    "    # in phi space lets make sure we use the closer of the\n",
    "    # two points\n",
    "    return pi_norm(a - b)\n",
    "\n",
    "\n",
    "class SPFKalmanFilter(ExtendedKalmanFilter, SPFFilter):\n",
    "    def __init__(self, ds, rx_idx, phi_std=0.5, p=5, dynamic_R=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "        self.ds = ds\n",
    "        # flip the sign of antennas\n",
    "        assert (\n",
    "            ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "            == ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "        )\n",
    "        antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "\n",
    "        assert ds.wavelengths[0] == ds.wavelengths[1]\n",
    "        wavelength = ds.wavelengths[0]\n",
    "\n",
    "        self.antenna_spacing_in_wavelengths = antenna_spacing / wavelength\n",
    "        self.rx_idx = rx_idx\n",
    "\n",
    "        self.x_dim = 2  # theta, dtheta\n",
    "        self.dynamic_R = dynamic_R\n",
    "\n",
    "    def R_at_x(self):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(self.x[0, 0])) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        self.x[0] = reduce_theta_to_positive_y(self.x[0])\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    Predict and return prior\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, dt, noise_std):  # q_var -> noise_std\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=noise_std\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "    def update(self, observation):\n",
    "        super().update(\n",
    "            np.array(observation),\n",
    "            partial(\n",
    "                single_hjacobian_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "            ),\n",
    "            partial(\n",
    "                single_h_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "            ),\n",
    "            residual=residual,\n",
    "            R=self.R if not self.dynamic_R else (np.array([[self.R_at_x()]]) ** 2) * 5,\n",
    "        )\n",
    "        self.fix_x()\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        return ds[idx][self.rx_idx][\"mean_phase_segmentation\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions={}):\n",
    "        self.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(\n",
    "        self,\n",
    "        initial_conditions={},\n",
    "        dt=1.0,\n",
    "        noise_std=0.01,\n",
    "        max_iterations=None,\n",
    "        debug=False,\n",
    "    ):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        n = (\n",
    "            len(self.ds)\n",
    "            if max_iterations is None\n",
    "            else min(max_iterations, len(self.ds))\n",
    "        )\n",
    "        for idx in range(n):\n",
    "            # compute the prior\n",
    "            self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "            )\n",
    "\n",
    "            if debug:\n",
    "                hx = single_h_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                )\n",
    "                jacobian = single_hjacobian_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                )\n",
    "\n",
    "            # compute update = likelihood * prior\n",
    "            observation = self.observation(idx)\n",
    "            self.update(observation=observation)\n",
    "\n",
    "            current_instance = {\n",
    "                \"mu\": self.x,\n",
    "                \"var\": self.P,\n",
    "            }\n",
    "            if debug:\n",
    "                current_instance.update(\n",
    "                    {\n",
    "                        \"jacobian\": jacobian[0, 0],\n",
    "                        \"hx\": hx,\n",
    "                        \"theta\": self.x[0, 0],\n",
    "                        \"P_theta\": self.P[0, 0],\n",
    "                        \"observation\": observation.item(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            trajectory.append(current_instance)\n",
    "\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = SPFKalmanFilter(\n",
    "    ds=ds, rx_idx=0, dim_x=2, dim_z=1, phi_std=5.0, p=5\n",
    ")  # , phi_std=0.5, p=5, **kwargs):\n",
    "kf.trajectory(max_iterations=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "\n",
    "    kf = SPFKalmanFilter(\n",
    "        ds=ds, rx_idx=rx_idx, dim_x=2, dim_z=1, phi_std=5.0, p=5, dynamic_R=False\n",
    "    )  # , phi_std=0.5, p=5, **kwargs):\n",
    "    trajectory = kf.trajectory(max_iterations=500, debug=True)\n",
    "    jacobian = [x[\"jacobian\"] for x in trajectory]\n",
    "    zs = [x[\"observation\"] for x in trajectory]\n",
    "    # trajectory, jacobian, zs = trajectory_for_phi(rx_idx, ds)\n",
    "    jacobian = np.array(jacobian)\n",
    "    zs = np.array(zs)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[0, rx_idx].plot(jacobian, label=\"jacobian\")\n",
    "    ax[0, rx_idx].plot(zs, label=\"zs\")\n",
    "    ax[0, rx_idx].plot(np.clip(zs / jacobian, a_min=-5, a_max=5), label=\"zs/j\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "    ax[1, rx_idx].fill_between(\n",
    "        np.arange(xs.shape[0]),\n",
    "        xs - stds,\n",
    "        xs + stds,\n",
    "        label=\"EKF-std\",\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = array([[5, 10], [10, 5], [15, 15]])\n",
    "\n",
    "ekf = run_localization(\n",
    "    landmarks, std_vel=0.1, std_steer=np.radians(1), std_range=0.3, std_bearing=0.1\n",
    ")\n",
    "print(\"Final P:\", ekf.P.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "Q_discrete_white_noise(2, dt=1.0, var=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "x = 1.9 * np.pi\n",
    "y = -1.9 * np.pi\n",
    "for x in np.linspace(-np.pi, np.pi, 32):\n",
    "    for y in np.linspace(-np.pi, np.pi, 32):\n",
    "        assert np.isclose(residual(x, y), pi_norm(x - y), atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import pi_norm_halfpi, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "class SingleRadioConstantTheta(ExtendedKalmanFilter):\n",
    "\n",
    "    def __init__(self, phi_std=0.5, p=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "    def R_at_x(self):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(self.x[0, 0])) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        self.x[0] = pi_norm_halfpi(self.x[0])\n",
    "        return\n",
    "        while np.abs(self.x[0]) > np.pi / 2:\n",
    "            if self.debug:\n",
    "                print(\"FLIPPING\", self.x)\n",
    "            self.x[0] = np.sign(self.x[0]) * np.pi - self.x[0]\n",
    "            self.x[1] *= -1\n",
    "            if self.debug:\n",
    "                print(\"FLIPPED\", self.x)\n",
    "\n",
    "    ###\n",
    "    #    x[0] = theta , ?\n",
    "    #    x[1] = theta dot , ? / s\n",
    "    ###\n",
    "    def predict(self, dt, q_var):\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=q_var\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "        # do some house keeping\n",
    "        self.x_prior = np.copy(self.x)\n",
    "        self.P_prior = np.copy(self.P)\n",
    "\n",
    "    def update(self, z):\n",
    "        if self.debug:\n",
    "            print(\"DEBUG\")\n",
    "        # find a good z!\n",
    "        # print(self.R.shape)\n",
    "        # if z is > 0 consider z and z-2*pi\n",
    "        # if z is < 0 consider z and z+2*pi\n",
    "        # if abs(self.x[0]) > 1.5:\n",
    "        #     predict_phi = hx(self.x)[0]\n",
    "        #     candidates = np.array([z, z - np.sign(z) * np.pi])\n",
    "        #     closer_candidate = np.argmax(-np.abs(predict_phi - candidates))\n",
    "        #     z = candidates[closer_candidate]\n",
    "        # self.R = np.eye(2) * self.R_at_x(self.x)\n",
    "        # print(closer_candidate, np.abs(predict_phi - candidates))\n",
    "        # r = np.array([[self.R_at_x()]]) * 30\n",
    "        r = (np.array([[self.R_at_x()]]) ** 2) * 5\n",
    "        if self.debug:\n",
    "            print(\"R\", r)\n",
    "            print(\"P\", self.P)\n",
    "        super().update(\n",
    "            # np.array([[z]]),\n",
    "            np.array([[z]]),\n",
    "            HJacobian_at,\n",
    "            hx,\n",
    "            residual=residual,\n",
    "            R=r,\n",
    "        )\n",
    "        # self.x[0] = reduce_theta_to_positive_y(self.x[0])\n",
    "        self.fix_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_for_phi(rx_idx, ds):\n",
    "    ekf = SingleRadioConstantTheta(dim_x=2, dim_z=1, phi_std=5.0, p=5)\n",
    "    ekf.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "    traj = []\n",
    "    n = 48 + len(ds)\n",
    "    jacobian = []\n",
    "    zs = []\n",
    "    for idx in range(min(n, len(ds))):\n",
    "        # ekf.predict(dt=0.1, q_var=0.3) # simulated data\n",
    "        z = ds[idx][rx_idx][\"mean_phase_segmentation\"]\n",
    "        debug = idx >= n - 8\n",
    "        ekf.debug = debug\n",
    "        if debug:\n",
    "            print(idx, \"X\", ekf.x)\n",
    "            print(idx, \"z\", z)\n",
    "        # ekf.predict(dt=1.0, q_var=0.003)\n",
    "        ekf.predict(dt=0.05, q_var=0.3)\n",
    "        if debug:\n",
    "            print(idx, \"X^'\", ekf.x)\n",
    "        ekf.update(z)\n",
    "        zs.append(z)\n",
    "        jacobian.append(HJacobian_at(ekf.x)[0, 0])\n",
    "        if debug:\n",
    "            print(idx, \"X^\", ekf.x)\n",
    "        traj.append({\"theta\": ekf.x[0, 0], \"P_theta\": ekf.P[0, 0]})\n",
    "    return traj, jacobian, zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory, jacobian = trajectory_for_phi(0, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds[450][0][\"windowed_beamformer\"].mean(axis=0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mean_phase[f\"r{rx_idx}\"][450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    trajectory, jacobian, zs = trajectory_for_phi(rx_idx, ds)\n",
    "    jacobian = np.array(jacobian)\n",
    "    zs = np.array(zs)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[0, rx_idx].plot(jacobian, label=\"jacobian\")\n",
    "    ax[0, rx_idx].plot(zs, label=\"zs\")\n",
    "    ax[0, rx_idx].plot(np.clip(zs / jacobian, a_min=-5, a_max=5), label=\"zs/j\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "    ax[1, rx_idx].fill_between(\n",
    "        np.arange(xs.shape[0]),\n",
    "        xs - stds,\n",
    "        xs + stds,\n",
    "        label=\"EKF-std\",\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "from spf.rf import pi_norm, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def trajectory_for_phi(rx_idx, ds):\n",
    "    rk = ExtendedKalmanFilter(dim_x=2, dim_z=1)\n",
    "    # initialize with first ground truth state\n",
    "    y_rad = ds[rx_idx][0][\"ground_truth_theta\"].item()\n",
    "    # y_rad_reduced=reduce_theta_to_positive_y(y_rad)\n",
    "    rk.x = np.array([[y_rad], [0]])\n",
    "\n",
    "    # dt = 0.1  # 1.0  # 0.1\n",
    "    dt = 0.1  # 1.0  # 0.1\n",
    "    rk.F = np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "    phi_std = 0.5\n",
    "    rk.R = phi_std**2  # np.diag([phi_std**2])\n",
    "    # TODO R:\n",
    "    # Use gt state x to get a good R, then worry about how to use estimated x\n",
    "    # Motion model , f , wrap around\n",
    "    # make class for motion model and measurement model\n",
    "    # Plot how x and p evolve\n",
    "    rk.Q = Q_discrete_white_noise(2, dt=dt, var=0.3)\n",
    "    rk.P *= 5  # initialized as identity?\n",
    "\n",
    "    traj = []\n",
    "    for idx in range(len(ds)):\n",
    "        rk.update(\n",
    "            np.array([ds[idx][rx_idx][\"mean_phase_segmentation\"]]),\n",
    "            HJacobian_at,\n",
    "            hx,\n",
    "            residual=residual,\n",
    "        )\n",
    "        traj.append(rk.x[0, 0])\n",
    "        rk.predict()\n",
    "        rk.x = pi_norm(rk.x)  # this should not be for theta dot ! TODO BUG!\n",
    "    return np.array(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(ds.mean_phase[f\"r{rx_idx}\"].shape[0]),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(len(ds))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    ax[1, rx_idx].plot(trajectory_for_phi(rx_idx, ds), label=\"EKF\")\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired EKF\n",
    "\n",
    "offsets = [\n",
    "    ds.yaml_config[\"receivers\"][0][\"theta-in-pis\"] * np.pi,\n",
    "    ds.yaml_config[\"receivers\"][1][\"theta-in-pis\"] * np.pi,\n",
    "]\n",
    "\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def hx_paired(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0, 0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "            np.sin(x[0, 0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def HJacobian_at_paired(x):\n",
    "    \"\"\"compute Jacobian of H matrix at x\"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                np.cos(x[0, 0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "                0,\n",
    "            ],\n",
    "            [\n",
    "                np.cos(x[0, 0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "                0,\n",
    "            ],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "from spf.rf import pi_norm, reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    y = a - b\n",
    "    y = y % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y > np.pi:  # move to [-pi, pi)\n",
    "        y -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def residual_paired(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([residual(a[0], b[0]), residual(a[1], b[1])])\n",
    "\n",
    "\n",
    "def trajectory_for_phi_paired(ds):\n",
    "    rk = ExtendedKalmanFilter(dim_x=2, dim_z=2)\n",
    "    # initialize with first ground truth state\n",
    "    y_rad = ds[rx_idx][0][\"ground_truth_theta\"].item()\n",
    "    # y_rad_reduced=reduce_theta_to_positive_y(y_rad)\n",
    "    rk.x = np.array([[y_rad], [0]])\n",
    "\n",
    "    dt = 0.05\n",
    "    rk.F = np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "    phi_std = 0.5\n",
    "    rk.R *= phi_std**2  # can this change dependent on state?\n",
    "    rk.Q = Q_discrete_white_noise(2, dt=dt, var=1.0)\n",
    "    rk.P *= 0.1  # initialized as identity?\n",
    "\n",
    "    traj = []\n",
    "    for idx in range(len(ds)):\n",
    "        rk.update(\n",
    "            np.array(\n",
    "                [\n",
    "                    [ds[idx][0][\"mean_phase_segmentation\"]],\n",
    "                    [ds[idx][1][\"mean_phase_segmentation\"]],\n",
    "                ]\n",
    "            ),\n",
    "            HJacobian_at_paired,\n",
    "            hx_paired,\n",
    "            residual=residual_paired,\n",
    "        )\n",
    "        traj.append(rk.x[0, 0])\n",
    "        rk.predict()\n",
    "        rk.x = pi_norm(rk.x)\n",
    "    return np.array(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import torch_pi_norm\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[rx_idx].scatter(\n",
    "        range(ds.mean_phase[f\"r{rx_idx}\"].shape[0]),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\")\n",
    "\n",
    "    ax[rx_idx].legend()\n",
    "    ax[rx_idx].set_xlabel(\"time step\")\n",
    "    ax[rx_idx].set_ylabel(\"phi\")\n",
    "    ax[rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "\n",
    "ax[2].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "ax[2].set_title(\"Paired radio EKF\")\n",
    "ax[2].plot(trajectory_for_phi_paired(ds), label=\"EKF\")\n",
    "\n",
    "ax[2].legend()\n",
    "fig.suptitle(\"EKF: When two (radios) become one\")\n",
    "fig.savefig(f\"{output_prefix}_when_two_become_one_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y, pi_norm\n",
    "\n",
    "\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "\n",
    "@cache\n",
    "def Q_discrete_white_noise_cached(**kwargs):\n",
    "    return Q_discrete_white_noise(**kwargs)\n",
    "\n",
    "\n",
    "@cache\n",
    "def F_cached(dt):\n",
    "    return np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "\n",
    "class DualRadioConstantTheta(ExtendedKalmanFilter):\n",
    "\n",
    "    def __init__(self, phi_std=0.5, p=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P[0, 0] *= p  # initialized as identity?\n",
    "        self.P[1, 1] *= 0.1\n",
    "\n",
    "    def R_at_x(self, x_for_radio):\n",
    "        # return 30  # return 1.5\n",
    "        # return 30 + +2.5 * np.exp(-((abs(x_for_radio) - np.pi / 2) ** 2)) * 30\n",
    "        return (5 + np.exp(-((abs(x_for_radio) - np.pi / 2) ** 2))) ** 2\n",
    "\n",
    "    ###\n",
    "    #    x[0] = theta , ?\n",
    "    #    x[1] = theta dot , ? / s\n",
    "    ###\n",
    "    def predict(self, dt, q_var):\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=q_var\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.x[0] = pi_norm(self.x[0])\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "        # do some house keeping\n",
    "        self.x_prior = np.copy(self.x)\n",
    "        self.P_prior = np.copy(self.P)\n",
    "\n",
    "    def update(self, z):\n",
    "        # find a good z!\n",
    "        r = np.array(\n",
    "            [\n",
    "                [self.R_at_x(pi_norm(self.x[0, 0] - offsets[0])), 0],\n",
    "                [0, self.R_at_x(pi_norm(self.x[0, 0] - offsets[1]))],\n",
    "            ]\n",
    "        )\n",
    "        super().update(\n",
    "            # np.array([[z]]),\n",
    "            np.array(z),\n",
    "            HJacobian_at_paired,\n",
    "            hx_paired,\n",
    "            residual=residual_paired,\n",
    "            R=r,\n",
    "        )\n",
    "        # self.x[0] = reduce_theta_to_positive_y(self.x[0])\n",
    "        self.x[0] = pi_norm(self.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_for_phi_paired(ds):\n",
    "    ekf = DualRadioConstantTheta(dim_x=2, dim_z=1, phi_std=0.0, p=5)\n",
    "    ekf.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "    traj = []\n",
    "    for idx in range(min(25000, len(ds))):\n",
    "        # ekf.predict(dt=0.1, q_var=0.3) # simulated data\n",
    "        ekf.predict(dt=0.05, q_var=1.0)  # works for paired\n",
    "        # ekf.predict(dt=1.0, q_var=0.001)\n",
    "        ekf.update(\n",
    "            np.array(\n",
    "                [\n",
    "                    [ds[idx][0][\"mean_phase_segmentation\"]],\n",
    "                    [ds[idx][1][\"mean_phase_segmentation\"]],\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        traj.append({\"theta\": ekf.x[0, 0], \"P_theta\": ekf.P[0, 0]})\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "ax[1].fill_between(\n",
    "    np.arange(xs.shape[0]),\n",
    "    xs - stds,\n",
    "    xs + stds,\n",
    "    label=\"EKF-std\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=0.05, var=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=1.0, var=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt):\n",
    "    F = F_cached(dt)\n",
    "    return np.dot(F, x)\n",
    "\n",
    "\n",
    "def hx_paired_ukf(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "            np.sin(x[0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def ukf_paired_residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([residual(a[0], b[0]), residual(a[1], b[1])])\n",
    "\n",
    "\n",
    "def ukf_paired_residual_x(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([pi_norm(a[0] - b[0]), a[0] - b[0]])\n",
    "\n",
    "\n",
    "def state_mean(sigmas, Wm):\n",
    "    x = np.zeros(2)\n",
    "    sum_sin, sum_cos = 0.0, 0.0\n",
    "\n",
    "    for i in range(len(sigmas)):\n",
    "        s = sigmas[i]\n",
    "        x[1] += s[1] * Wm[i]\n",
    "        sum_sin += np.sin(s[0]) * Wm[i]\n",
    "        sum_cos += np.cos(s[0]) * Wm[i]\n",
    "    x[1] /= len(sigmas)\n",
    "    x[0] = np.arctan2(sum_sin, sum_cos)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman.sigma_points import MerweScaledSigmaPoints\n",
    "from filterpy.kalman import UnscentedKalmanFilter\n",
    "\n",
    "dt = 1.0\n",
    "points = MerweScaledSigmaPoints(2, alpha=0.1, beta=2.0, kappa=0)  # -1)\n",
    "kf = UnscentedKalmanFilter(\n",
    "    dim_x=2,\n",
    "    dim_z=2,\n",
    "    dt=dt,\n",
    "    fx=fx,\n",
    "    hx=hx_paired_ukf,\n",
    "    points=points,\n",
    "    residual_z=ukf_paired_residual,\n",
    "    # x_mean_fn=state_mean,\n",
    "    residual_x=ukf_paired_residual_x,\n",
    ")\n",
    "kf.x = np.array([0, 0])  # initial state\n",
    "kf.P[0, 0] *= 5  # initial uncertainty\n",
    "kf.P[1, 1] *= 0.2  # initial uncertainty\n",
    "z_std = 5\n",
    "kf.R = np.diag([z_std**2, z_std**2])  # 1 standard\n",
    "kf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=0.01**2)\n",
    "\n",
    "trajectory = []\n",
    "\n",
    "#    for idx in range(min(2500, len(ds))):\n",
    "for idx in range(min(800, len(ds))):\n",
    "    print(kf.x)\n",
    "    kf.predict()\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    # kf.x[0] = pi_norm(kf.x[0])\n",
    "    print(kf.x)\n",
    "    z = np.array(\n",
    "        [\n",
    "            ds[idx][0][\"mean_phase_segmentation\"],\n",
    "            ds[idx][1][\"mean_phase_segmentation\"],\n",
    "        ]\n",
    "    )\n",
    "    # print(kf.x)\n",
    "    kf.update(z)\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    trajectory.append({\"theta\": kf.x[0]})  # , \"P_theta\": ekf.P[0, 0]})\n",
    "    # print(kf.x, \"log-likelihood\", kf.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "# trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "# stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "# zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "# ax[1].fill_between(\n",
    "#     np.arange(xs.shape[0]),\n",
    "#     xs - stds,\n",
    "#     xs + stds,\n",
    "#     label=\"EKF-std\",\n",
    "#     color=\"orange\",\n",
    "#     alpha=0.2,\n",
    "# )\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a particle filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianWalk(pypfilt.Model):\n",
    "    def field_types(self, ctx):\n",
    "        return [(\"x\", np.dtype(float))]\n",
    "\n",
    "    def update(self, ctx, time_step, is_fs, prev, curr):\n",
    "        \"\"\"Perform a single time-step.\"\"\"\n",
    "        rnd = ctx.component[\"random\"][\"model\"]\n",
    "        step = rnd.normal(loc=0, scale=1, size=curr.shape)\n",
    "        curr[\"x\"] = prev[\"x\"] + step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lorenz63(OdeModel):\n",
    "    def field_types(self, ctx):\n",
    "        r\"\"\"\n",
    "        Define the state vector :math:`[\\sigma, \\rho, \\beta, x, y, z]^T`.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (\"tehta\", float),\n",
    "            (\"tehta_vel\", float),\n",
    "        ]\n",
    "\n",
    "    def d_dt(self, time, xt, ctx, is_forecast):\n",
    "        rates = np.zeros(xt.shape, xt.dtype)\n",
    "        rates[\"theta\"] = xt[\"tehta_vel\"]\n",
    "        return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "import numpy as np\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "\n",
    "ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "# ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "\n",
    "\n",
    "nthetas = 65\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/home/mouse9911/precompute_cache_chunk16\",\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "full_p = pickle.load(open(\"full_p.pkl\", \"rb\"))[\"full_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def fix_particles(particles):\n",
    "    while np.abs(particles[:, 0]).max() > np.pi / 2:\n",
    "        mask = np.abs(particles[:, 0]) > np.pi / 2\n",
    "        particles[mask, 0] = np.sign(particles[mask, 0]) * np.pi - particles[mask, 0]\n",
    "        particles[mask, 1] *= -1\n",
    "    return particles\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "def pf_trajectory_for_phi(rx_idx, ds):\n",
    "    N = 128 * 8 * 2\n",
    "    particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "    weights = np.ones((N,)) / N\n",
    "    trajectory = []\n",
    "    thetas = []\n",
    "    vs = []\n",
    "    for idx in range(len(ds)):\n",
    "        particles = fix_particles(particles)\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles = fix_particles(particles)\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles = fix_particles(particles)\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(\n",
    "#     np.array(\n",
    "#         [\n",
    "#             theta_phi_to_p(np.pi / 4, phi, full_p)\n",
    "#             for phi in np.linspace(-np.pi, np.pi, 50)\n",
    "#         ]\n",
    "#     ).reshape(-1, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in thetas]\n",
    "# y = [p[1] for p in thetas]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in vs]\n",
    "# y = [p[1] for p in vs]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0, 1]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    trajectory = pf_trajectory_for_phi(rx_idx, ds)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    # stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    # zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"PF-x\", color=\"orange\")\n",
    "    # ax[1, rx_idx].fill_between(\n",
    "    #     np.arange(xs.shape[0]),\n",
    "    #     xs - stds,\n",
    "    #     xs + stds,\n",
    "    #     label=\"EKF-std\",\n",
    "    #     color=\"orange\",\n",
    "    #     alpha=0.2,\n",
    "    # )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    # ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import pi_norm\n",
    "\n",
    "pi_norm(0.99 * np.pi - (-0.99 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS WORKS\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights[1:][change_mask] *= 0.75\n",
    "    weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        #weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8 *8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKS2\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.01\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import math\n",
    "import sympy\n",
    "from sympy.abc import alpha, x, y, v, w, R, theta\n",
    "from sympy import symbols, Matrix\n",
    "\n",
    "sympy.init_printing(use_latex=\"mathjax\", fontsize=\"16pt\")\n",
    "time = symbols(\"t\")\n",
    "d = v * time\n",
    "beta = (d / w) * sympy.tan(alpha)\n",
    "r = w / sympy.tan(alpha)\n",
    "\n",
    "fxu = Matrix(\n",
    "    [\n",
    "        [x - r * sympy.sin(theta) + r * sympy.sin(theta + beta)],\n",
    "        [y + r * sympy.cos(theta) - r * sympy.cos(theta + beta)],\n",
    "        [theta + beta],\n",
    "    ]\n",
    ")\n",
    "F = fxu.jacobian(Matrix([x, y, theta]))\n",
    "F\n",
    "\n",
    "from filterpy.stats import plot_covariance_ellipse\n",
    "from math import sqrt, tan, cos, sin, atan2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = 1.0\n",
    "\n",
    "from math import atan2\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def H_of(x, landmark_pos):\n",
    "    \"\"\"compute Jacobian of H matrix where h(x) computes\n",
    "    the range and bearing to a landmark for state x\"\"\"\n",
    "\n",
    "    px = landmark_pos[0]\n",
    "    py = landmark_pos[1]\n",
    "    hyp = (px - x[0, 0]) ** 2 + (py - x[1, 0]) ** 2\n",
    "    dist = sqrt(hyp)\n",
    "\n",
    "    H = array(\n",
    "        [\n",
    "            [-(px - x[0, 0]) / dist, -(py - x[1, 0]) / dist, 0],\n",
    "            [(py - x[1, 0]) / hyp, -(px - x[0, 0]) / hyp, -1],\n",
    "        ]\n",
    "    )\n",
    "    return H\n",
    "\n",
    "\n",
    "def Hx(x, landmark_pos):\n",
    "    \"\"\"takes a state variable and returns the measurement\n",
    "    that would correspond to that state.\n",
    "    \"\"\"\n",
    "    px = landmark_pos[0]\n",
    "    py = landmark_pos[1]\n",
    "    dist = sqrt((px - x[0, 0]) ** 2 + (py - x[1, 0]) ** 2)\n",
    "\n",
    "    Hx = array([[dist], [atan2(py - x[1, 0], px - x[0, 0]) - x[2, 0]]])\n",
    "    return Hx\n",
    "\n",
    "\n",
    "from filterpy.kalman import ExtendedKalmanFilter as EKF\n",
    "from numpy import array, sqrt\n",
    "\n",
    "\n",
    "class RobotEKF(EKF):\n",
    "    def __init__(self, dt, wheelbase, std_vel, std_steer):\n",
    "        EKF.__init__(self, 3, 2, 2)\n",
    "        self.dt = dt\n",
    "        self.wheelbase = wheelbase\n",
    "        self.std_vel = std_vel\n",
    "        self.std_steer = std_steer\n",
    "\n",
    "        a, x, y, v, w, theta, time = symbols(\"a, x, y, v, w, theta, t\")\n",
    "        d = v * time\n",
    "        beta = (d / w) * sympy.tan(a)\n",
    "        r = w / sympy.tan(a)\n",
    "\n",
    "        self.fxu = Matrix(\n",
    "            [\n",
    "                [x - r * sympy.sin(theta) + r * sympy.sin(theta + beta)],\n",
    "                [y + r * sympy.cos(theta) - r * sympy.cos(theta + beta)],\n",
    "                [theta + beta],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.F_j = self.fxu.jacobian(Matrix([x, y, theta]))\n",
    "        self.V_j = self.fxu.jacobian(Matrix([v, a]))\n",
    "\n",
    "        # save dictionary and it's variables for later use\n",
    "        self.subs = {x: 0, y: 0, v: 0, a: 0, time: dt, w: wheelbase, theta: 0}\n",
    "        (\n",
    "            self.x_x,\n",
    "            self.x_y,\n",
    "        ) = (\n",
    "            x,\n",
    "            y,\n",
    "        )\n",
    "        self.v, self.a, self.theta = v, a, theta\n",
    "\n",
    "    def predict(self, u):\n",
    "        self.x = self.move(self.x, u, self.dt)\n",
    "        self.subs[self.x_x] = self.x[0, 0]\n",
    "        self.subs[self.x_y] = self.x[1, 0]\n",
    "\n",
    "        self.subs[self.theta] = self.x[2, 0]\n",
    "        self.subs[self.v] = u[0]\n",
    "        self.subs[self.a] = u[1]\n",
    "\n",
    "        F = array(self.F_j.evalf(subs=self.subs)).astype(float)\n",
    "        V = array(self.V_j.evalf(subs=self.subs)).astype(float)\n",
    "\n",
    "        # covariance of motion noise in control space\n",
    "        M = array([[self.std_vel**2, 0], [0, self.std_steer**2]])\n",
    "\n",
    "        self.P = F @ self.P @ F.T + V @ M @ V.T\n",
    "        print(\"P\", self.P.shape, \"F\", F.shape)\n",
    "\n",
    "    def move(self, x, u, dt):\n",
    "        hdg = x[2, 0]\n",
    "        vel = u[0]\n",
    "        steering_angle = u[1]\n",
    "        dist = vel * dt\n",
    "\n",
    "        if abs(steering_angle) > 0.001:  # is robot turning?\n",
    "            beta = (dist / self.wheelbase) * tan(steering_angle)\n",
    "            r = self.wheelbase / tan(steering_angle)  # radius\n",
    "\n",
    "            dx = np.array(\n",
    "                [\n",
    "                    [-r * sin(hdg) + r * sin(hdg + beta)],\n",
    "                    [r * cos(hdg) - r * cos(hdg + beta)],\n",
    "                    [beta],\n",
    "                ]\n",
    "            )\n",
    "        else:  # moving in straight line\n",
    "            dx = np.array([[dist * cos(hdg)], [dist * sin(hdg)], [0]])\n",
    "        return x + dx\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    \"\"\"compute residual (a-b) between measurements containing\n",
    "    [range, bearing]. Bearing is normalized to [-pi, pi)\"\"\"\n",
    "    y = a - b\n",
    "    y[1] = y[1] % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y[1] > np.pi:  # move to [-pi, pi)\n",
    "        y[1] -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def z_landmark(lmark, sim_pos, std_rng, std_brg):\n",
    "    x, y = sim_pos[0, 0], sim_pos[1, 0]\n",
    "    d = np.sqrt((lmark[0] - x) ** 2 + (lmark[1] - y) ** 2)\n",
    "    a = atan2(lmark[1] - y, lmark[0] - x) - sim_pos[2, 0]\n",
    "    z = np.array([[d + randn() * std_rng], [a + randn() * std_brg]])\n",
    "    return z\n",
    "\n",
    "\n",
    "def ekf_update(ekf, z, landmark):\n",
    "    print(\"EKF UPDATE\", \"Z\", z.shape)\n",
    "    print(\"\\t\", \"x\", ekf.x.shape, \"Hx\", Hx(ekf.x, landmark).shape)\n",
    "    print(\"\\t\", \"x\", ekf.x.shape, \"H_of\", H_of(ekf.x, landmark).shape)\n",
    "    ekf.update(\n",
    "        z, HJacobian=H_of, Hx=Hx, residual=residual, args=(landmark), hx_args=(landmark)\n",
    "    )\n",
    "\n",
    "\n",
    "def run_localization(\n",
    "    landmarks,\n",
    "    std_vel,\n",
    "    std_steer,\n",
    "    std_range,\n",
    "    std_bearing,\n",
    "    step=10,\n",
    "    ellipse_step=20,\n",
    "    ylim=None,\n",
    "):\n",
    "    ekf = RobotEKF(dt, wheelbase=0.5, std_vel=std_vel, std_steer=std_steer)\n",
    "    ekf.x = array([[2, 6, 0.3]]).T  # x, y, steer angle\n",
    "    ekf.P = np.diag([0.1, 0.1, 0.1])\n",
    "    ekf.R = np.diag([std_range**2, std_bearing**2])\n",
    "\n",
    "    sim_pos = ekf.x.copy()  # simulated position\n",
    "    # steering command (vel, steering angle radians)\n",
    "    u = array([1.1, 0.01])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], marker=\"s\", s=60)\n",
    "\n",
    "    track = []\n",
    "    for i in range(2):\n",
    "        sim_pos = ekf.move(sim_pos, u, dt / 10.0)  # simulate robot\n",
    "        track.append(sim_pos)\n",
    "\n",
    "        if i % step == 0:\n",
    "            print(\"U\", u.shape)\n",
    "            ekf.predict(u=u)\n",
    "            print(\"x\", ekf.x.shape)\n",
    "\n",
    "            if i % ellipse_step == 0:\n",
    "                plot_covariance_ellipse(\n",
    "                    (ekf.x[0, 0], ekf.x[1, 0]),\n",
    "                    ekf.P[0:2, 0:2],\n",
    "                    std=6,\n",
    "                    facecolor=\"k\",\n",
    "                    alpha=0.3,\n",
    "                )\n",
    "\n",
    "            x, y = sim_pos[0, 0], sim_pos[1, 0]\n",
    "            for lmark in landmarks:\n",
    "                z = z_landmark(lmark, sim_pos, std_range, std_bearing)\n",
    "                ekf_update(ekf, z, lmark)\n",
    "\n",
    "            if i % ellipse_step == 0:\n",
    "                plot_covariance_ellipse(\n",
    "                    (ekf.x[0, 0], ekf.x[1, 0]),\n",
    "                    ekf.P[0:2, 0:2],\n",
    "                    std=6,\n",
    "                    facecolor=\"g\",\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "    track = np.array(track)\n",
    "    plt.plot(track[:, 0], track[:, 1], color=\"k\", lw=2)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"EKF Robot localization\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.show()\n",
    "    return ekf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
