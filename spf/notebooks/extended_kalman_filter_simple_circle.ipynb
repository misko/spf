{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from spf.dataset.fake_dataset import create_fake_dataset, fake_yaml\n",
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "\n",
    "n = 1025\n",
    "noise = 0.3\n",
    "nthetas = 65\n",
    "orbits = 4\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "tmpdirname = tmpdir.name\n",
    "temp_ds_fn = f\"{tmpdirname}/sample_dataset_for_ekf_n{n}_noise{noise}\"\n",
    "\n",
    "create_fake_dataset(\n",
    "    filename=temp_ds_fn, yaml_config_str=fake_yaml, n=n, noise=noise, orbits=orbits\n",
    ")\n",
    "ds = v5spfdataset(\n",
    "    temp_ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=tmpdirname,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_data = False\n",
    "if use_real_data:\n",
    "    # ds_fn = \"/mnt/md1/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "    ds_fn = \"/mnt/md1/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "    precompute_cache_dir = \"/home/mouse9911/precompute_cache_chunk16_sept\"\n",
    "else:\n",
    "    ds_fn = temp_ds_fn\n",
    "    precompute_cache_dir = tmpdirname\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=precompute_cache_dir,\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\", \"windowed_beamformer\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPFFilter:\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the known state : i.e. RX position\n",
    "    \"\"\"\n",
    "\n",
    "    def our_state(self, idx):\n",
    "        return None\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, our_state, dt, noise_std) -> None:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx use the internally\n",
    "    \"\"\"\n",
    "\n",
    "    def update(self) -> None:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions):\n",
    "        pass\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(self, initial_conditions={}, dt=1.0, noise_std=0.01):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        for idx in range(len(self.ds)):\n",
    "            prior = self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "                our_state=self.our_state(idx),\n",
    "            )\n",
    "\n",
    "            posterior = self.update(prior=prior, observation=self.observation(idx))\n",
    "\n",
    "            trajectory.append(self.posterior_to_mu_var(posterior))\n",
    "\n",
    "        return {\"trajectory\": trajectory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_prefix = \"./\" + os.path.basename(ds_fn) + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for rx_idx in [0, 1]:\n",
    "    ax[rx_idx].scatter(\n",
    "        range(len(ds)),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"],\n",
    "        label=f\"radio{rx_idx} est phi\",\n",
    "        s=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[rx_idx].plot(ds.ground_truth_phis[rx_idx], label=\"perfect phi\", color=\"blue\")\n",
    "    ax[rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(len(ds))],\n",
    "        label=f\"radio{rx_idx} gt theta\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    ax[rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[rx_idx].set_xlabel(\"Time step\")\n",
    "    ax[rx_idx].set_ylabel(\"tehta/phi\")\n",
    "    ax[rx_idx].legend()\n",
    "    ax[rx_idx].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "fig.suptitle(\"Phase(phi) recovered from radios after segmentation\")\n",
    "fig.savefig(f\"{output_prefix}_raw_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "\"\"\"\n",
    "x = [ theta dtheta/dt ]\n",
    "z = [ phi ]\n",
    "\n",
    "F = [ [ 1 dt ],\n",
    "      [ 0  1 ]]\n",
    "\n",
    "h(x) = sin(x[0]) *  2 * pi  * (d/ wavelength )\n",
    "\n",
    "H(x) = [ dh/dx_1 , dh/dx_2 ] = [ cos(x[0]) * 2 * pi (d/ wavelength ) , 0]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Convert a state (x) representing [ theta dtheta/dt ] into an observation of phi\n",
    "given the spacing between antennas as a fraction of wavelength\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def h_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offset=0\n",
    "):\n",
    "    assert x.ndim == 2 and x.shape[0] == 2 and x.shape[1] == 1\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0, 0] - radio_array_angle_offset)\n",
    "            * 2\n",
    "            * np.pi\n",
    "            * antenna_spacing_in_wavelengths\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Compute the derivative of the observation generated from state x (theta,dtheta/dt)\n",
    "with respect to state variables (theta,dtheta/dt)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def hjacobian_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offset=0\n",
    "):\n",
    "    assert x.ndim == 2 and x.shape[0] == 2 and x.shape[1] == 1\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                np.cos(x[0, 0] - radio_array_angle_offset)\n",
    "                * 2\n",
    "                * np.pi\n",
    "                * antenna_spacing_in_wavelengths,\n",
    "                0,\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def single_h_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths):\n",
    "    assert x[0, 0] >= -np.pi / 2 and x[0, 0] <= np.pi / 2\n",
    "    return h_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths)\n",
    "\n",
    "\n",
    "def single_hjacobian_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths\n",
    "):\n",
    "    assert x[0, 0] >= -np.pi / 2 and x[0, 0] <= np.pi / 2\n",
    "    return hjacobian_phi_observation_from_theta_state(x, antenna_spacing_in_wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "\n",
    "(np.array([-np.pi * 0.7])) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import ExtendedKalmanFilter\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "from functools import cache, partial\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "\n",
    "@cache\n",
    "def Q_discrete_white_noise_cached(**kwargs):\n",
    "    return Q_discrete_white_noise(**kwargs)\n",
    "\n",
    "\n",
    "@cache\n",
    "def F_cached(dt):\n",
    "    return np.eye(2) + np.array([[0, 1], [0, 0]]) * dt\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    # we are dealing in phi space here, not theta space\n",
    "    # in phi space lets make sure we use the closer of the\n",
    "    # two points\n",
    "    return pi_norm(a - b)\n",
    "\n",
    "\n",
    "class SPFKalmanFilter(ExtendedKalmanFilter, SPFFilter):\n",
    "    def __init__(self, ds, rx_idx, phi_std=0.5, p=5, dynamic_R=False, **kwargs):\n",
    "        super().__init__(dim_x=2, dim_z=1, **kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "        self.ds = ds\n",
    "        # flip the sign of antennas\n",
    "        assert (\n",
    "            ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "            == ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "        )\n",
    "        antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "\n",
    "        assert ds.wavelengths[0] == ds.wavelengths[1]\n",
    "        wavelength = ds.wavelengths[0]\n",
    "\n",
    "        self.antenna_spacing_in_wavelengths = antenna_spacing / wavelength\n",
    "        self.rx_idx = rx_idx\n",
    "\n",
    "        self.dynamic_R = dynamic_R\n",
    "\n",
    "    def R_at_x(self):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(self.x[0, 0])) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        self.x[0] = reduce_theta_to_positive_y(pi_norm(self.x[0]))\n",
    "        assert self.x[0] >= -np.pi / 2 and self.x[0] <= np.pi / 2\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    Predict and return prior\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, dt, noise_std):  # q_var -> noise_std\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=noise_std\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "    def update(self, observation):\n",
    "        super().update(\n",
    "            np.array(observation),\n",
    "            partial(\n",
    "                single_hjacobian_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "            ),\n",
    "            partial(\n",
    "                single_h_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "            ),\n",
    "            residual=residual,\n",
    "            R=self.R if not self.dynamic_R else (np.array([[self.R_at_x()]]) ** 2) * 5,\n",
    "        )\n",
    "        self.fix_x()\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        return ds[idx][self.rx_idx][\"mean_phase_segmentation\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions={}):\n",
    "        self.x = np.array([[ds[rx_idx][0][\"ground_truth_theta\"].item()], [0]])\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(\n",
    "        self,\n",
    "        initial_conditions={},\n",
    "        dt=1.0,\n",
    "        noise_std=0.01,\n",
    "        max_iterations=None,\n",
    "        debug=False,\n",
    "    ):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        n = (\n",
    "            len(self.ds)\n",
    "            if max_iterations is None\n",
    "            else min(max_iterations, len(self.ds))\n",
    "        )\n",
    "        for idx in range(n):\n",
    "            # compute the prior\n",
    "            self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "            )\n",
    "\n",
    "            if debug:\n",
    "                hx = single_h_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                )\n",
    "                jacobian = single_hjacobian_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                )\n",
    "\n",
    "            # compute update = likelihood * prior\n",
    "            observation = self.observation(idx)\n",
    "            self.update(observation=observation)\n",
    "\n",
    "            current_instance = {\n",
    "                \"mu\": self.x,\n",
    "                \"var\": self.P,\n",
    "            }\n",
    "            if debug:\n",
    "                current_instance.update(\n",
    "                    {\n",
    "                        \"jacobian\": jacobian[0, 0],\n",
    "                        \"hx\": hx,\n",
    "                        \"theta\": self.x[0, 0],\n",
    "                        \"P_theta\": self.P[0, 0],\n",
    "                        \"observation\": observation.item(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            trajectory.append(current_instance)\n",
    "\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = SPFKalmanFilter(\n",
    "    ds=ds, rx_idx=0, phi_std=5.0, p=5\n",
    ")  # , phi_std=0.5, p=5, **kwargs):\n",
    "kf.trajectory(max_iterations=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0, 1]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "\n",
    "    kf = SPFKalmanFilter(\n",
    "        ds=ds, rx_idx=rx_idx, phi_std=5.0, p=5, dynamic_R=True\n",
    "    )  # , phi_std=0.5, p=5, **kwargs):\n",
    "    trajectory = kf.trajectory(max_iterations=None, debug=True)\n",
    "    jacobian = [x[\"jacobian\"] for x in trajectory]\n",
    "    zs = [x[\"observation\"] for x in trajectory]\n",
    "    # trajectory, jacobian, zs = trajectory_for_phi(rx_idx, ds)\n",
    "    jacobian = np.array(jacobian)\n",
    "    zs = np.array(zs)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[0, rx_idx].plot(jacobian, label=\"jacobian\")\n",
    "    ax[0, rx_idx].plot(zs, label=\"zs\")\n",
    "    ax[0, rx_idx].plot(np.clip(zs / jacobian, a_min=-5, a_max=5), label=\"zs/j\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "    ax[1, rx_idx].fill_between(\n",
    "        np.arange(xs.shape[0]),\n",
    "        xs - stds,\n",
    "        xs + stds,\n",
    "        label=\"EKF-std\",\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def paired_h_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offsets\n",
    "):\n",
    "    return np.vstack(\n",
    "        [\n",
    "            h_phi_observation_from_theta_state(\n",
    "                x,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[0],\n",
    "            ),\n",
    "            h_phi_observation_from_theta_state(\n",
    "                x,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[1],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def paired_hjacobian_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offsets\n",
    "):\n",
    "    return np.vstack(\n",
    "        [\n",
    "            hjacobian_phi_observation_from_theta_state(\n",
    "                x,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[0],\n",
    "            ),\n",
    "            hjacobian_phi_observation_from_theta_state(\n",
    "                x,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[1],\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPFPairedKalmanFilter(ExtendedKalmanFilter, SPFFilter):\n",
    "    def __init__(self, ds, phi_std=0.5, p=5, dynamic_R=False, **kwargs):\n",
    "        super().__init__(dim_x=2, dim_z=2, **kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "        self.ds = ds\n",
    "        # flip the sign of antennas\n",
    "        assert (\n",
    "            ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "            == ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "        )\n",
    "        antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "\n",
    "        assert ds.wavelengths[0] == ds.wavelengths[1]\n",
    "        wavelength = ds.wavelengths[0]\n",
    "\n",
    "        self.radio_array_angle_offsets = [\n",
    "            ds.yaml_config[\"receivers\"][0][\"theta-in-pis\"] * np.pi,\n",
    "            ds.yaml_config[\"receivers\"][1][\"theta-in-pis\"] * np.pi,\n",
    "        ]\n",
    "\n",
    "        self.antenna_spacing_in_wavelengths = antenna_spacing / wavelength\n",
    "\n",
    "        self.dynamic_R = dynamic_R\n",
    "\n",
    "    def R_at_x(self, angle):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(angle)) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        self.x[0] = pi_norm(self.x[0])\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    Predict and return prior\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, dt, noise_std):  # q_var -> noise_std\n",
    "        self.F = F_cached(dt)\n",
    "        self.Q = Q_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=noise_std\n",
    "        )  # TODO Cache this\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "    def update(self, observation):\n",
    "        r = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.R_at_x(\n",
    "                        pi_norm(self.x[0, 0] - self.radio_array_angle_offsets[0])\n",
    "                    ),\n",
    "                    0,\n",
    "                ],\n",
    "                [\n",
    "                    0,\n",
    "                    self.R_at_x(\n",
    "                        pi_norm(self.x[0, 0] - self.radio_array_angle_offsets[1])\n",
    "                    ),\n",
    "                ],\n",
    "            ]\n",
    "        )\n",
    "        super().update(\n",
    "            np.array(observation),\n",
    "            partial(\n",
    "                paired_hjacobian_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "            ),\n",
    "            partial(\n",
    "                paired_h_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "            ),\n",
    "            residual=residual,\n",
    "            R=self.R if not self.dynamic_R else r,\n",
    "        )\n",
    "        self.fix_x()\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        return np.vstack(\n",
    "            [\n",
    "                ds[idx][0][\"mean_phase_segmentation\"],\n",
    "                ds[idx][1][\"mean_phase_segmentation\"],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions={}):\n",
    "        self.x = np.array([[ds[rx_idx][0][\"craft_ground_truth_theta\"].item()], [0]])\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(\n",
    "        self,\n",
    "        initial_conditions={},\n",
    "        dt=1.0,\n",
    "        noise_std=0.01,\n",
    "        max_iterations=None,\n",
    "        debug=False,\n",
    "    ):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        n = (\n",
    "            len(self.ds)\n",
    "            if max_iterations is None\n",
    "            else min(max_iterations, len(self.ds))\n",
    "        )\n",
    "        for idx in range(n):\n",
    "            # compute the prior\n",
    "            self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "            )\n",
    "\n",
    "            if debug:\n",
    "                hx = paired_h_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                    radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "                )\n",
    "                jacobian = paired_hjacobian_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                    radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "                )\n",
    "\n",
    "            # compute update = likelihood * prior\n",
    "            observation = self.observation(idx)\n",
    "            self.update(observation=observation)\n",
    "\n",
    "            current_instance = {\n",
    "                \"mu\": self.x,\n",
    "                \"var\": self.P,\n",
    "            }\n",
    "            if debug:\n",
    "                current_instance.update(\n",
    "                    {\n",
    "                        \"jacobian\": jacobian[0, 0],\n",
    "                        \"hx\": hx,\n",
    "                        \"theta\": self.x[0, 0],\n",
    "                        \"P_theta\": self.P[0, 0],\n",
    "                        \"observation\": observation,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            trajectory.append(current_instance)\n",
    "\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = SPFPairedKalmanFilter(\n",
    "    ds=ds, phi_std=5.0, p=5, dynamic_R=False\n",
    ")  # , phi_std=0.5, p=5, **kwargs):\n",
    "trajectory = kf.trajectory(max_iterations=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "kf = SPFPairedKalmanFilter(ds=ds, phi_std=5.0, p=5, dynamic_R=False)\n",
    "trajectory = kf.trajectory(max_iterations=None, debug=True)\n",
    "\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "ground_truth_theta = [\n",
    "    pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(trajectory))\n",
    "]\n",
    "ax[1].plot(\n",
    "    ground_truth_theta,\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "zscores = (xs - np.array(ground_truth_theta)) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "ax[1].fill_between(\n",
    "    np.arange(xs.shape[0]),\n",
    "    xs - stds,\n",
    "    xs + stds,\n",
    "    label=\"EKF-std\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairedXY_h_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offsets\n",
    "):\n",
    "    rel_x, rel_y = x[0, 0] - x[4, 0], x[1, 0] - x[5, 0]\n",
    "    target_theta = pi_norm(np.arctan2(rel_x, rel_y))\n",
    "    two_state_theta_dtheta = np.array([[target_theta], [0]])\n",
    "    return np.vstack(\n",
    "        [\n",
    "            h_phi_observation_from_theta_state(\n",
    "                two_state_theta_dtheta,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[0],\n",
    "            ),\n",
    "            h_phi_observation_from_theta_state(\n",
    "                two_state_theta_dtheta,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[1],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def pairedXY_hjacobian_phi_observation_from_theta_state(\n",
    "    x, antenna_spacing_in_wavelengths, radio_array_angle_offsets\n",
    "):\n",
    "    rel_x, rel_y = x[0, 0] - x[4, 0], x[1, 0] - x[5, 0]\n",
    "    target_theta = pi_norm(np.arctan2(rel_x, rel_y))\n",
    "    # print(\"Target\", target_theta)\n",
    "    two_state_theta_dtheta = np.array([[target_theta], [0]])\n",
    "    two_state_jacobian = np.vstack(\n",
    "        [\n",
    "            hjacobian_phi_observation_from_theta_state(\n",
    "                two_state_theta_dtheta,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[0],\n",
    "            ),\n",
    "            hjacobian_phi_observation_from_theta_state(\n",
    "                two_state_theta_dtheta,\n",
    "                antenna_spacing_in_wavelengths=antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offset=radio_array_angle_offsets[1],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    d2 = rel_x**2 + rel_y**2\n",
    "    dtheta_drel_x = rel_y / d2\n",
    "    dtheta_drel_y = -rel_x / d2\n",
    "    dphi0_dtheta = two_state_jacobian[0, 0]\n",
    "    dphi1_dtheta = two_state_jacobian[1, 0]\n",
    "    jacobian = np.zeros((2, 6))\n",
    "    jacobian[0, 0] = dphi0_dtheta * dtheta_drel_x  #  * drel_x/dx\n",
    "    jacobian[0, 1] = dphi0_dtheta * dtheta_drel_y  # * drel_y/dy\n",
    "    jacobian[1, 0] = dphi1_dtheta * dtheta_drel_x  # * drel_x/dx\n",
    "    jacobian[1, 1] = dphi1_dtheta * dtheta_drel_y  # * drel_y/dy\n",
    "    # print(\"jacobian\",jacobian)\n",
    "    return jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arctan2(-0.01, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=1, block_size=2, order_by_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def Qxy_discrete_white_noise_cached(**kwargs):\n",
    "    q = np.zeros((6, 6))\n",
    "    q[:4, :4] = Q_discrete_white_noise(**kwargs)\n",
    "    return q\n",
    "\n",
    "\n",
    "@cache\n",
    "def Fxy_cached(dt):\n",
    "    return (\n",
    "        np.eye(6)\n",
    "        + np.array(\n",
    "            [\n",
    "                [0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0],  # no updates for dtx_x/dt\n",
    "                [0, 0, 0, 0, 0, 0],  # no updates for dtx_y/dt\n",
    "                [0, 0, 0, 0, 0, 0],  # no updates for rx_x\n",
    "                [0, 0, 0, 0, 0, 0],  # no updates for rx_y\n",
    "            ]\n",
    "        )\n",
    "        * dt\n",
    "    )\n",
    "\n",
    "\n",
    "class SPFPairedXYKalmanFilter(ExtendedKalmanFilter, SPFFilter):\n",
    "    def __init__(self, ds, phi_std=0.5, p=5, dynamic_R=False, **kwargs):\n",
    "        # state x = [ tx_x, tx_y, dtx_x/dt, dtx_y/dt, rx_x, rx_y] , x,y relative to (0,0) not craft\n",
    "        super().__init__(dim_x=6, dim_z=2, **kwargs)\n",
    "        self.R *= phi_std**2\n",
    "        self.P *= p  # initialized as identity?\n",
    "\n",
    "        self.ds = ds\n",
    "        # flip the sign of antennas\n",
    "        assert (\n",
    "            ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "            == ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "        )\n",
    "        antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "\n",
    "        assert ds.wavelengths[0] == ds.wavelengths[1]\n",
    "        wavelength = ds.wavelengths[0]\n",
    "\n",
    "        self.radio_array_angle_offsets = [\n",
    "            ds.yaml_config[\"receivers\"][0][\"theta-in-pis\"] * np.pi,\n",
    "            ds.yaml_config[\"receivers\"][1][\"theta-in-pis\"] * np.pi,\n",
    "        ]\n",
    "\n",
    "        self.antenna_spacing_in_wavelengths = antenna_spacing / wavelength\n",
    "\n",
    "        self.dynamic_R = dynamic_R\n",
    "\n",
    "    def R_at_x(self, angle):\n",
    "        return 2.5 * np.exp(-((abs(pi_norm(angle)) - np.pi / 2) ** 2))\n",
    "\n",
    "    def fix_x(self):\n",
    "        # self.x[[2, 3]] = np.clip(self.x[[2, 3]], a_min=-0.1, a_max=0.1)\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Given current RX known state, time difference and noise level\n",
    "    Predict and return prior\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, dt, noise_std):  # q_var -> noise_std\n",
    "        self.F = Fxy_cached(dt)\n",
    "        self.Q = Qxy_discrete_white_noise_cached(\n",
    "            dim=2, dt=dt, var=noise_std, block_size=2, order_by_dim=False\n",
    "        )  # TODO Cache thisQ_discrete_white_noise(dim=2, dt=1,block_size=2,order_by_dim=False)\n",
    "        ### predict self.x\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.fix_x()\n",
    "        ###\n",
    "        # print(\"P\", self.P.shape, \"Q\", self.Q.shape)\n",
    "\n",
    "        # update covar\n",
    "        self.P = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "    def update(self, observation):\n",
    "\n",
    "        rel_x, rel_y = self.x[0, 0] - self.x[4, 0], self.x[1, 0] - self.x[5, 0]\n",
    "        target_theta = np.arctan2(rel_x, rel_y)\n",
    "        r = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.R_at_x(\n",
    "                        pi_norm(target_theta - self.radio_array_angle_offsets[0])\n",
    "                    ),\n",
    "                    0,\n",
    "                ],\n",
    "                [\n",
    "                    0,\n",
    "                    self.R_at_x(\n",
    "                        pi_norm(target_theta - self.radio_array_angle_offsets[1])\n",
    "                    ),\n",
    "                ],\n",
    "            ]\n",
    "        )\n",
    "        # print(\"Update\", self.x)\n",
    "        super().update(\n",
    "            np.array(observation),\n",
    "            partial(\n",
    "                pairedXY_hjacobian_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "            ),\n",
    "            partial(\n",
    "                pairedXY_h_phi_observation_from_theta_state,\n",
    "                antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "            ),\n",
    "            residual=residual,\n",
    "            R=self.R if not self.dynamic_R else r,\n",
    "        )\n",
    "        self.fix_x()\n",
    "\n",
    "    \"\"\"\n",
    "    Given an idx return the observation at that point\n",
    "    \"\"\"\n",
    "\n",
    "    def observation(self, idx):\n",
    "        return np.vstack(\n",
    "            [\n",
    "                ds[idx][0][\"mean_phase_segmentation\"],\n",
    "                ds[idx][1][\"mean_phase_segmentation\"],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    Given a trajectory compute metrics over it\n",
    "    \"\"\"\n",
    "\n",
    "    def metrics(self, trajectory):\n",
    "        pass\n",
    "\n",
    "    def setup(self, initial_conditions={}):\n",
    "        self.x = np.array(\n",
    "            [\n",
    "                [ds[0][0][\"tx_pos_x_mm\"].item()],\n",
    "                [ds[0][0][\"tx_pos_y_mm\"].item()],\n",
    "                [0],\n",
    "                [0],\n",
    "                [ds[0][0][\"rx_pos_x_mm\"].item()],\n",
    "                [ds[0][0][\"rx_pos_y_mm\"].item()],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def posterior_to_mu_var(self, posterior):\n",
    "        return {\"var\": None, \"mu\": None}\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate over the dataset and generate a trajectory\n",
    "    \"\"\"\n",
    "\n",
    "    def trajectory(\n",
    "        self,\n",
    "        initial_conditions={},\n",
    "        dt=1.0,\n",
    "        noise_std=0.01,\n",
    "        max_iterations=None,\n",
    "        debug=False,\n",
    "    ):\n",
    "        self.setup(initial_conditions)\n",
    "        trajectory = []\n",
    "        n = (\n",
    "            len(self.ds)\n",
    "            if max_iterations is None\n",
    "            else min(max_iterations, len(self.ds))\n",
    "        )\n",
    "        for idx in range(n):\n",
    "            self.P[4:, 4:] = 0\n",
    "            self.predict(\n",
    "                dt=dt,\n",
    "                noise_std=noise_std,\n",
    "            )\n",
    "\n",
    "            observation = self.observation(idx)\n",
    "\n",
    "            self.x[4] = ds[idx][0][\"rx_pos_x_mm\"].item()\n",
    "            self.x[5] = ds[idx][0][\"rx_pos_y_mm\"].item()\n",
    "            if debug:\n",
    "                hx = pairedXY_h_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                    radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "                )\n",
    "                jacobian = pairedXY_hjacobian_phi_observation_from_theta_state(\n",
    "                    x=self.x,\n",
    "                    antenna_spacing_in_wavelengths=self.antenna_spacing_in_wavelengths,\n",
    "                    radio_array_angle_offsets=self.radio_array_angle_offsets,\n",
    "                )\n",
    "\n",
    "            self.update(observation=observation)\n",
    "\n",
    "            current_instance = {\n",
    "                \"mu\": self.x,\n",
    "                \"var\": self.P[:4, :4],\n",
    "            }\n",
    "            if debug:\n",
    "                self.x[4] = ds[idx][0][\"rx_pos_x_mm\"].item()\n",
    "                self.x[5] = ds[idx][0][\"rx_pos_y_mm\"].item()\n",
    "                rel_x, rel_y = self.x[0, 0] - self.x[4, 0], self.x[1, 0] - self.x[5, 0]\n",
    "                target_theta = pi_norm(np.arctan2(rel_x, rel_y))\n",
    "                current_instance.update(\n",
    "                    {\n",
    "                        \"jacobian\": jacobian[0, 0],\n",
    "                        \"hx\": hx,\n",
    "                        \"theta\": target_theta,\n",
    "                        \"P_theta\": 0.01,  # self.P[0, 0],\n",
    "                        \"observation\": observation,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            trajectory.append(current_instance)\n",
    "\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = SPFPairedXYKalmanFilter(\n",
    "    ds=ds, phi_std=5.0, p=0.001, dynamic_R=False\n",
    ")  # , phi_std=0.5, p=5, **kwargs):\n",
    "trajectory = kf.trajectory(max_iterations=5, debug=True, dt=0.05)\n",
    "# trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "kf = SPFPairedXYKalmanFilter(ds=ds, phi_std=5, p=0.1, dynamic_R=True)\n",
    "trajectory = kf.trajectory(\n",
    "    max_iterations=1600, debug=True, noise_std=10.0, dt=1\n",
    ")  # , noise_std=1)\n",
    "\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "ground_truth_theta = [\n",
    "    pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(trajectory))\n",
    "]\n",
    "ax[1].plot(\n",
    "    ground_truth_theta,\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "zscores = (xs - np.array(ground_truth_theta)) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "ax[1].fill_between(\n",
    "    np.arange(xs.shape[0]),\n",
    "    xs - stds,\n",
    "    xs + stds,\n",
    "    label=\"EKF-std\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "# ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")\n",
    "\n",
    "pos_x = np.array([x[\"mu\"][0] for x in trajectory])\n",
    "pos_y = np.array([x[\"mu\"][1] for x in trajectory])\n",
    "rpos_x = np.array([x[\"mu\"][4] for x in trajectory])\n",
    "rpos_y = np.array([x[\"mu\"][5] for x in trajectory])\n",
    "vel_x = np.array([x[\"mu\"][2] for x in trajectory])\n",
    "vel_y = np.array([x[\"mu\"][3] for x in trajectory])\n",
    "gt_x = [ds[idx][0][\"tx_pos_x_mm\"].item() for idx in range(len(trajectory))]\n",
    "gt_y = [ds[idx][0][\"tx_pos_y_mm\"].item() for idx in range(len(trajectory))]\n",
    "ax[2].plot(gt_x, color=\"red\")\n",
    "ax[2].plot(gt_y, color=\"green\")\n",
    "ax[2].scatter(range(len(pos_x)), pos_x, color=\"red\")\n",
    "ax[2].scatter(range(len(pos_y)), pos_y, color=\"green\")\n",
    "ax[2].plot(range(len(rpos_x)), rpos_x, color=\"blue\")\n",
    "ax[2].plot(range(len(rpos_y)), rpos_y, color=\"black\")\n",
    "# ax[2].scatter(range(len(vel_x)), vel_x, color=\"red\")\n",
    "# ax[2].scatter(range(len(vel_y)), vel_y, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[3][0][\"tx_pos_x_mm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tx_pos = torch.vstack(\n",
    "    [\n",
    "        torch.tensor([ds[idx][0][\"tx_pos_x_mm\"], ds[idx][0][\"tx_pos_y_mm\"]])\n",
    "        for idx in range(10)\n",
    "    ]\n",
    ")\n",
    "rx_pos = torch.vstack(\n",
    "    [\n",
    "        torch.tensor([ds[idx][0][\"rx_pos_x_mm\"], ds[idx][0][\"rx_pos_y_mm\"]])\n",
    "        for idx in range(10)\n",
    "    ]\n",
    ")\n",
    "craft_theta = [\n",
    "    torch.tensor(ds[idx][0][\"craft_ground_truth_theta\"]) for idx in range(10)\n",
    "]\n",
    "d = tx_pos - rx_pos\n",
    "torch.arctan2(d[:, 0], d[:, 1]) - torch.tensor(craft_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craft_ground_truth_theta\n",
    "#tx_pos_x_mm,tx_pos_y_mm\n",
    "#rx_pos_x_mm,rx_pos_y_mm\n",
    "# plot g.t. theta vs compute\n",
    "\n",
    "tx_pos = torch.vstack(\n",
    "                [\n",
    "                    self.cached_keys[ridx][\"tx_pos_x_mm\"],\n",
    "                    self.cached_keys[ridx][\"tx_pos_y_mm\"],\n",
    "                ]\n",
    "            )\n",
    "            rx_pos = torch.vstack(\n",
    "                [\n",
    "                    self.cached_keys[ridx][\"rx_pos_x_mm\"],\n",
    "                    self.cached_keys[ridx][\"rx_pos_y_mm\"],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # compute the angle of the tx with respect to rx\n",
    "            d = tx_pos - rx_pos\n",
    "\n",
    "            rx_to_tx_theta = torch.arctan2(d[0], d[1])\n",
    "#ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "ax[1].fill_between(\n",
    "    np.arange(xs.shape[0]),\n",
    "    xs - stds,\n",
    "    xs + stds,\n",
    "    label=\"EKF-std\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=0.05, var=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_discrete_white_noise(dim=2, dt=1.0, var=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt):\n",
    "    F = F_cached(dt)\n",
    "    return np.dot(F, x)\n",
    "\n",
    "\n",
    "def hx_paired_ukf(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.sin(x[0] - offsets[0]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "            np.sin(x[0] - offsets[1]) * antenna_spacing * 2 * np.pi / wavelength,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def ukf_paired_residual(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([residual(a[0], b[0]), residual(a[1], b[1])])\n",
    "\n",
    "\n",
    "def ukf_paired_residual_x(a, b):\n",
    "    # return pi_norm(a - b)\n",
    "    return np.array([pi_norm(a[0] - b[0]), a[0] - b[0]])\n",
    "\n",
    "\n",
    "def state_mean(sigmas, Wm):\n",
    "    x = np.zeros(2)\n",
    "    sum_sin, sum_cos = 0.0, 0.0\n",
    "\n",
    "    for i in range(len(sigmas)):\n",
    "        s = sigmas[i]\n",
    "        x[1] += s[1] * Wm[i]\n",
    "        sum_sin += np.sin(s[0]) * Wm[i]\n",
    "        sum_cos += np.cos(s[0]) * Wm[i]\n",
    "    x[1] /= len(sigmas)\n",
    "    x[0] = np.arctan2(sum_sin, sum_cos)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman.sigma_points import MerweScaledSigmaPoints\n",
    "from filterpy.kalman import UnscentedKalmanFilter\n",
    "\n",
    "dt = 1.0\n",
    "points = MerweScaledSigmaPoints(2, alpha=0.1, beta=2.0, kappa=0)  # -1)\n",
    "kf = UnscentedKalmanFilter(\n",
    "    dim_x=2,\n",
    "    dim_z=2,\n",
    "    dt=dt,\n",
    "    fx=fx,\n",
    "    hx=hx_paired_ukf,\n",
    "    points=points,\n",
    "    residual_z=ukf_paired_residual,\n",
    "    # x_mean_fn=state_mean,\n",
    "    residual_x=ukf_paired_residual_x,\n",
    ")\n",
    "kf.x = np.array([0, 0])  # initial state\n",
    "kf.P[0, 0] *= 5  # initial uncertainty\n",
    "kf.P[1, 1] *= 0.2  # initial uncertainty\n",
    "z_std = 5\n",
    "kf.R = np.diag([z_std**2, z_std**2])  # 1 standard\n",
    "kf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=0.01**2)\n",
    "\n",
    "trajectory = []\n",
    "\n",
    "#    for idx in range(min(2500, len(ds))):\n",
    "for idx in range(min(800, len(ds))):\n",
    "    print(kf.x)\n",
    "    kf.predict()\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    # kf.x[0] = pi_norm(kf.x[0])\n",
    "    print(kf.x)\n",
    "    z = np.array(\n",
    "        [\n",
    "            ds[idx][0][\"mean_phase_segmentation\"],\n",
    "            ds[idx][1][\"mean_phase_segmentation\"],\n",
    "        ]\n",
    "    )\n",
    "    # print(kf.x)\n",
    "    kf.update(z)\n",
    "    kf.x[0] = pi_norm(kf.x[0])\n",
    "    trajectory.append({\"theta\": kf.x[0]})  # , \"P_theta\": ekf.P[0, 0]})\n",
    "    # print(kf.x, \"log-likelihood\", kf.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax[1].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "ax[1].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "# trajectory = trajectory_for_phi_paired(ds)\n",
    "n = len(trajectory)\n",
    "ax[0].scatter(\n",
    "    range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "    ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "    label=f\"r{rx_idx} estimated phi\",\n",
    "    s=1.0,\n",
    "    alpha=1.0,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax[0].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "# ax[1].plot(\n",
    "#     [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "#     label=f\"r{rx_idx} gt theta\",\n",
    "# )\n",
    "ax[1].plot(\n",
    "    [torch_pi_norm(ds[idx][0][\"craft_y_rad\"].item()) for idx in range(len(ds))],\n",
    "    label=\"craft gt theta\",\n",
    ")\n",
    "reduced_gt_theta = np.array(\n",
    "    [\n",
    "        reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "        for idx in range(min(n, len(ds)))\n",
    "    ]\n",
    ")\n",
    "ax[1].plot(\n",
    "    reduced_gt_theta,\n",
    "    label=f\"r{rx_idx} reduced gt theta\",\n",
    ")\n",
    "\n",
    "xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "# stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "# zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "ax[1].plot(xs, label=\"EKF-x\", color=\"orange\")\n",
    "# ax[1].fill_between(\n",
    "#     np.arange(xs.shape[0]),\n",
    "#     xs - stds,\n",
    "#     xs + stds,\n",
    "#     label=\"EKF-std\",\n",
    "#     color=\"orange\",\n",
    "#     alpha=0.2,\n",
    "# )\n",
    "\n",
    "ax[0].set_ylabel(\"radio phi\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"Radio {rx_idx}\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"time step\")\n",
    "ax[1].set_ylabel(\"radio theta\")\n",
    "\n",
    "ax[2].hist(zscores.reshape(-1), bins=25)\n",
    "# fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "# fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a particle filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianWalk(pypfilt.Model):\n",
    "    def field_types(self, ctx):\n",
    "        return [(\"x\", np.dtype(float))]\n",
    "\n",
    "    def update(self, ctx, time_step, is_fs, prev, curr):\n",
    "        \"\"\"Perform a single time-step.\"\"\"\n",
    "        rnd = ctx.component[\"random\"][\"model\"]\n",
    "        step = rnd.normal(loc=0, scale=1, size=curr.shape)\n",
    "        curr[\"x\"] = prev[\"x\"] + step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lorenz63(OdeModel):\n",
    "    def field_types(self, ctx):\n",
    "        r\"\"\"\n",
    "        Define the state vector :math:`[\\sigma, \\rho, \\beta, x, y, z]^T`.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (\"tehta\", float),\n",
    "            (\"tehta_vel\", float),\n",
    "        ]\n",
    "\n",
    "    def d_dt(self, time, xt, ctx, is_forecast):\n",
    "        rates = np.zeros(xt.shape, xt.dtype)\n",
    "        rates[\"theta\"] = xt[\"tehta_vel\"]\n",
    "        return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.dataset.spf_dataset import v5spfdataset\n",
    "import numpy as np\n",
    "\n",
    "from spf.rf import pi_norm\n",
    "\n",
    "ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_10_03_38_21_nRX2_rx_circle.zarr\"\n",
    "# ds_fn = \"/mnt/md0/spf/2d_wallarray_v2_data/june_fix/wallarrayv3_2024_06_15_11_44_13_nRX2_bounce.zarr\"\n",
    "\n",
    "\n",
    "nthetas = 65\n",
    "ds = v5spfdataset(\n",
    "    ds_fn,\n",
    "    nthetas=nthetas,\n",
    "    ignore_qc=True,\n",
    "    precompute_cache=\"/home/mouse9911/precompute_cache_chunk16\",\n",
    "    paired=True,\n",
    "    skip_fields=set([\"signal_matrix\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "full_p = pickle.load(open(\"full_p.pkl\", \"rb\"))[\"full_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def fix_particles(particles):\n",
    "    while np.abs(particles[:, 0]).max() > np.pi / 2:\n",
    "        mask = np.abs(particles[:, 0]) > np.pi / 2\n",
    "        particles[mask, 0] = np.sign(particles[mask, 0]) * np.pi - particles[mask, 0]\n",
    "        particles[mask, 1] *= -1\n",
    "    return particles\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "def pf_trajectory_for_phi(rx_idx, ds):\n",
    "    N = 128 * 8 * 2\n",
    "    particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "    weights = np.ones((N,)) / N\n",
    "    trajectory = []\n",
    "    thetas = []\n",
    "    vs = []\n",
    "    for idx in range(len(ds)):\n",
    "        particles = fix_particles(particles)\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles = fix_particles(particles)\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles = fix_particles(particles)\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(\n",
    "#     np.array(\n",
    "#         [\n",
    "#             theta_phi_to_p(np.pi / 4, phi, full_p)\n",
    "#             for phi in np.linspace(-np.pi, np.pi, 50)\n",
    "#         ]\n",
    "#     ).reshape(-1, 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in thetas]\n",
    "# y = [p[1] for p in thetas]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [p[0] for p in vs]\n",
    "# y = [p[1] for p in vs]\n",
    "# plt.scatter(x, y, s=1.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spf.rf import reduce_theta_to_positive_y\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "for rx_idx in [0, 1]:  # [0, 1]:\n",
    "    ax[1, rx_idx].axhline(y=np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    ax[1, rx_idx].axhline(y=-np.pi / 2, ls=\":\", c=(0.7, 0.7, 0.7))\n",
    "    trajectory = pf_trajectory_for_phi(rx_idx, ds)\n",
    "    n = len(trajectory)\n",
    "    ax[0, rx_idx].scatter(\n",
    "        range(min(n, ds.mean_phase[f\"r{rx_idx}\"].shape[0])),\n",
    "        ds.mean_phase[f\"r{rx_idx}\"][:n],\n",
    "        label=f\"r{rx_idx} estimated phi\",\n",
    "        s=1.0,\n",
    "        alpha=1.0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax[0, rx_idx].plot(ds.ground_truth_phis[rx_idx][:n], label=\"perfect phi\")\n",
    "    ax[1, rx_idx].plot(\n",
    "        [ds[idx][rx_idx][\"ground_truth_theta\"] for idx in range(min(n, len(ds)))],\n",
    "        label=f\"r{rx_idx} gt theta\",\n",
    "    )\n",
    "    reduced_gt_theta = np.array(\n",
    "        [\n",
    "            reduce_theta_to_positive_y(ds[idx][rx_idx][\"ground_truth_theta\"])\n",
    "            for idx in range(min(n, len(ds)))\n",
    "        ]\n",
    "    )\n",
    "    ax[1, rx_idx].plot(\n",
    "        reduced_gt_theta,\n",
    "        label=f\"r{rx_idx} reduced gt theta\",\n",
    "    )\n",
    "\n",
    "    xs = np.array([x[\"theta\"] for x in trajectory])\n",
    "    # stds = np.sqrt(np.array([x[\"P_theta\"] for x in trajectory]))\n",
    "    # zscores = (xs - reduced_gt_theta) / stds\n",
    "\n",
    "    ax[1, rx_idx].plot(xs, label=\"PF-x\", color=\"orange\")\n",
    "    # ax[1, rx_idx].fill_between(\n",
    "    #     np.arange(xs.shape[0]),\n",
    "    #     xs - stds,\n",
    "    #     xs + stds,\n",
    "    #     label=\"EKF-std\",\n",
    "    #     color=\"orange\",\n",
    "    #     alpha=0.2,\n",
    "    # )\n",
    "\n",
    "    ax[0, rx_idx].set_ylabel(\"radio phi\")\n",
    "\n",
    "    ax[0, rx_idx].legend()\n",
    "    ax[0, rx_idx].set_title(f\"Radio {rx_idx}\")\n",
    "    ax[1, rx_idx].legend()\n",
    "    ax[1, rx_idx].set_xlabel(\"time step\")\n",
    "    ax[1, rx_idx].set_ylabel(\"radio theta\")\n",
    "\n",
    "    # ax[2, rx_idx].hist(zscores.reshape(-1), bins=25)\n",
    "fig.suptitle(\"Single ladies (radios) EKF\")\n",
    "fig.savefig(f\"{output_prefix}_single_ladies_ekf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spf.rf import pi_norm\n",
    "\n",
    "pi_norm(0.99 * np.pi - (-0.99 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS WORKS\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.001\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights[1:][change_mask] *= 0.75\n",
    "    weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        #weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8 *8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKS2\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from filterpy.monte_carlo import systematic_resample\n",
    "\n",
    "# flip the order of the antennas\n",
    "antenna_spacing = -ds.yaml_config[\"receivers\"][0][\"antenna-spacing-m\"]\n",
    "assert antenna_spacing == -ds.yaml_config[\"receivers\"][1][\"antenna-spacing-m\"]\n",
    "\n",
    "wavelength = ds.wavelengths[0]\n",
    "assert wavelength == ds.wavelengths[1]\n",
    "\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    # print(indexes)\n",
    "    particles[:] = particles[indexes]\n",
    "    # weights[:] = weights[indexes]\n",
    "    # add noise to the new samples\n",
    "    noise = np.random.randn(*particles.shape)\n",
    "    # noise[:, 0] *= 0.01\n",
    "    # noise[:, 1] *= 0.01\n",
    "    noise[:, 0] *= 0.01\n",
    "    noise[:, 1] *= 0.01\n",
    "    change_mask = indexes[:-1] == indexes[1:]\n",
    "    particles[1:][change_mask] += noise[1:][change_mask]\n",
    "    # weights.resize(len(particles))\n",
    "    weights.fill(1.0 / len(weights))\n",
    "    weights[1:][change_mask] *= 0.01\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def create_gaussian_particles(mean, std, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = mean[0] + (np.random.randn(N) * std[0])\n",
    "    particles[:, 1] = mean[1] + (np.random.randn(N) * std[1])\n",
    "    return particles\n",
    "\n",
    "\n",
    "def predict(particles, std, dt=1.0):\n",
    "    N = len(particles)\n",
    "    particles[:, 0] += dt * particles[:, 1]\n",
    "    # particles[:, 0] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "    # particles[:, 1] += np.random.randn(particles.shape[0]) * 0.0001\n",
    "\n",
    "\n",
    "def hx_pf(x):\n",
    "    return np.sin(x[:, 0]) * antenna_spacing * 2 * np.pi / wavelength\n",
    "\n",
    "\n",
    "def theta_phi_to_p(theta, phi, full_p):\n",
    "    theta_bins = full_p.shape[0]\n",
    "    phi_bins = full_p.shape[1]\n",
    "    theta_bin = int(theta_bins * (theta + np.pi) / (2 * np.pi)) % theta_bins\n",
    "    phi_bin = int(phi_bins * (phi + np.pi) / (2 * np.pi)) % phi_bins\n",
    "    return full_p[theta_bin, phi_bin]\n",
    "\n",
    "\n",
    "def update(particles, weights, z, R):\n",
    "    # weights *= scipy.stats.norm(hx_pf(particles), R).pdf(z)\n",
    "    # print(weights.shape, z.shape, particles.shape)\n",
    "    # print(z)\n",
    "    for idx in range(weights.shape[0]):\n",
    "        weights[idx] *= theta_phi_to_p(particles[idx, 0], z, full_p=full_p)\n",
    "        # weights[idx] *= scipy.stats.norm(0, 0.0001).pdf(particles[idx, 1])\n",
    "    weights += 1.0e-300  # avoid round-off to zero\n",
    "    weights /= sum(weights)  # normalize\n",
    "\n",
    "\n",
    "def estimate(particles, weights):\n",
    "    mean = np.average(particles, weights=weights, axis=0)\n",
    "    var = np.average((particles - mean) ** 2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def neff(weights):\n",
    "    return 1.0 / np.sum(np.square(weights))\n",
    "\n",
    "\n",
    "N = 128 * 8\n",
    "particles = create_gaussian_particles(mean=np.array([0, 0]), std=(2, 0.01), N=N)\n",
    "weights = np.ones((N,)) / N\n",
    "trajectory = []\n",
    "thetas = []\n",
    "vs = []\n",
    "for rx_idx in [0]:\n",
    "    for idx in range(len(ds)):\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        predict(particles=particles, std=(0.5, 0.1), dt=0.1)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        z = np.array(ds[idx][rx_idx][\"mean_phase_segmentation\"])\n",
    "        update(particles=particles, weights=weights, z=z, R=2)\n",
    "        particles[:, 0] = pi_norm(particles[:, 0])\n",
    "        # print(neff(weights))\n",
    "        # print(particles.shape)\n",
    "        # resample if too few effective particles\n",
    "        if neff(weights) < N / 2:\n",
    "            # print(\"RESAMPLE\")\n",
    "            indexes = systematic_resample(weights)\n",
    "            resample_from_index(particles, weights, indexes)\n",
    "            # assert np.allclose(weights, 1 / N)\n",
    "        mu, var = estimate(particles, weights)\n",
    "        # particles = create_gaussian_particles(mean=mu, std=np.sqrt(var), N=N)\n",
    "        trajectory.append({\"theta\": mu[0]})\n",
    "        for particle in particles:\n",
    "            thetas.append((idx, particle[0]))\n",
    "            vs.append((idx, particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import math\n",
    "import sympy\n",
    "from sympy.abc import alpha, x, y, v, w, R, theta\n",
    "from sympy import symbols, Matrix\n",
    "\n",
    "sympy.init_printing(use_latex=\"mathjax\", fontsize=\"16pt\")\n",
    "time = symbols(\"t\")\n",
    "d = v * time\n",
    "beta = (d / w) * sympy.tan(alpha)\n",
    "r = w / sympy.tan(alpha)\n",
    "\n",
    "fxu = Matrix(\n",
    "    [\n",
    "        [x - r * sympy.sin(theta) + r * sympy.sin(theta + beta)],\n",
    "        [y + r * sympy.cos(theta) - r * sympy.cos(theta + beta)],\n",
    "        [theta + beta],\n",
    "    ]\n",
    ")\n",
    "F = fxu.jacobian(Matrix([x, y, theta]))\n",
    "F\n",
    "\n",
    "from filterpy.stats import plot_covariance_ellipse\n",
    "from math import sqrt, tan, cos, sin, atan2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = 1.0\n",
    "\n",
    "from math import atan2\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def H_of(x, landmark_pos):\n",
    "    \"\"\"compute Jacobian of H matrix where h(x) computes\n",
    "    the range and bearing to a landmark for state x\"\"\"\n",
    "\n",
    "    px = landmark_pos[0]\n",
    "    py = landmark_pos[1]\n",
    "    hyp = (px - x[0, 0]) ** 2 + (py - x[1, 0]) ** 2\n",
    "    dist = sqrt(hyp)\n",
    "\n",
    "    H = array(\n",
    "        [\n",
    "            [-(px - x[0, 0]) / dist, -(py - x[1, 0]) / dist, 0],\n",
    "            [(py - x[1, 0]) / hyp, -(px - x[0, 0]) / hyp, -1],\n",
    "        ]\n",
    "    )\n",
    "    return H\n",
    "\n",
    "\n",
    "def Hx(x, landmark_pos):\n",
    "    \"\"\"takes a state variable and returns the measurement\n",
    "    that would correspond to that state.\n",
    "    \"\"\"\n",
    "    px = landmark_pos[0]\n",
    "    py = landmark_pos[1]\n",
    "    dist = sqrt((px - x[0, 0]) ** 2 + (py - x[1, 0]) ** 2)\n",
    "\n",
    "    Hx = array([[dist], [atan2(py - x[1, 0], px - x[0, 0]) - x[2, 0]]])\n",
    "    return Hx\n",
    "\n",
    "\n",
    "from filterpy.kalman import ExtendedKalmanFilter as EKF\n",
    "from numpy import array, sqrt\n",
    "\n",
    "\n",
    "class RobotEKF(EKF):\n",
    "    def __init__(self, dt, wheelbase, std_vel, std_steer):\n",
    "        EKF.__init__(self, 3, 2, 2)\n",
    "        self.dt = dt\n",
    "        self.wheelbase = wheelbase\n",
    "        self.std_vel = std_vel\n",
    "        self.std_steer = std_steer\n",
    "\n",
    "        a, x, y, v, w, theta, time = symbols(\"a, x, y, v, w, theta, t\")\n",
    "        d = v * time\n",
    "        beta = (d / w) * sympy.tan(a)\n",
    "        r = w / sympy.tan(a)\n",
    "\n",
    "        self.fxu = Matrix(\n",
    "            [\n",
    "                [x - r * sympy.sin(theta) + r * sympy.sin(theta + beta)],\n",
    "                [y + r * sympy.cos(theta) - r * sympy.cos(theta + beta)],\n",
    "                [theta + beta],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.F_j = self.fxu.jacobian(Matrix([x, y, theta]))\n",
    "        self.V_j = self.fxu.jacobian(Matrix([v, a]))\n",
    "\n",
    "        # save dictionary and it's variables for later use\n",
    "        self.subs = {x: 0, y: 0, v: 0, a: 0, time: dt, w: wheelbase, theta: 0}\n",
    "        (\n",
    "            self.x_x,\n",
    "            self.x_y,\n",
    "        ) = (\n",
    "            x,\n",
    "            y,\n",
    "        )\n",
    "        self.v, self.a, self.theta = v, a, theta\n",
    "\n",
    "    def predict(self, u):\n",
    "        self.x = self.move(self.x, u, self.dt)\n",
    "        self.subs[self.x_x] = self.x[0, 0]\n",
    "        self.subs[self.x_y] = self.x[1, 0]\n",
    "\n",
    "        self.subs[self.theta] = self.x[2, 0]\n",
    "        self.subs[self.v] = u[0]\n",
    "        self.subs[self.a] = u[1]\n",
    "\n",
    "        F = array(self.F_j.evalf(subs=self.subs)).astype(float)\n",
    "        V = array(self.V_j.evalf(subs=self.subs)).astype(float)\n",
    "\n",
    "        # covariance of motion noise in control space\n",
    "        M = array([[self.std_vel**2, 0], [0, self.std_steer**2]])\n",
    "\n",
    "        self.P = F @ self.P @ F.T + V @ M @ V.T\n",
    "        print(\"P\", self.P.shape, \"F\", F.shape)\n",
    "\n",
    "    def move(self, x, u, dt):\n",
    "        hdg = x[2, 0]\n",
    "        vel = u[0]\n",
    "        steering_angle = u[1]\n",
    "        dist = vel * dt\n",
    "\n",
    "        if abs(steering_angle) > 0.001:  # is robot turning?\n",
    "            beta = (dist / self.wheelbase) * tan(steering_angle)\n",
    "            r = self.wheelbase / tan(steering_angle)  # radius\n",
    "\n",
    "            dx = np.array(\n",
    "                [\n",
    "                    [-r * sin(hdg) + r * sin(hdg + beta)],\n",
    "                    [r * cos(hdg) - r * cos(hdg + beta)],\n",
    "                    [beta],\n",
    "                ]\n",
    "            )\n",
    "        else:  # moving in straight line\n",
    "            dx = np.array([[dist * cos(hdg)], [dist * sin(hdg)], [0]])\n",
    "        return x + dx\n",
    "\n",
    "\n",
    "def residual(a, b):\n",
    "    \"\"\"compute residual (a-b) between measurements containing\n",
    "    [range, bearing]. Bearing is normalized to [-pi, pi)\"\"\"\n",
    "    y = a - b\n",
    "    y[1] = y[1] % (2 * np.pi)  # force in range [0, 2 pi)\n",
    "    if y[1] > np.pi:  # move to [-pi, pi)\n",
    "        y[1] -= 2 * np.pi\n",
    "    return y\n",
    "\n",
    "\n",
    "def z_landmark(lmark, sim_pos, std_rng, std_brg):\n",
    "    x, y = sim_pos[0, 0], sim_pos[1, 0]\n",
    "    d = np.sqrt((lmark[0] - x) ** 2 + (lmark[1] - y) ** 2)\n",
    "    a = atan2(lmark[1] - y, lmark[0] - x) - sim_pos[2, 0]\n",
    "    z = np.array([[d + randn() * std_rng], [a + randn() * std_brg]])\n",
    "    return z\n",
    "\n",
    "\n",
    "def ekf_update(ekf, z, landmark):\n",
    "    print(\"EKF UPDATE\", \"Z\", z.shape)\n",
    "    print(\"\\t\", \"x\", ekf.x.shape, \"Hx\", Hx(ekf.x, landmark).shape)\n",
    "    print(\"\\t\", \"x\", ekf.x.shape, \"H_of\", H_of(ekf.x, landmark).shape)\n",
    "    ekf.update(\n",
    "        z, HJacobian=H_of, Hx=Hx, residual=residual, args=(landmark), hx_args=(landmark)\n",
    "    )\n",
    "\n",
    "\n",
    "def run_localization(\n",
    "    landmarks,\n",
    "    std_vel,\n",
    "    std_steer,\n",
    "    std_range,\n",
    "    std_bearing,\n",
    "    step=10,\n",
    "    ellipse_step=20,\n",
    "    ylim=None,\n",
    "):\n",
    "    ekf = RobotEKF(dt, wheelbase=0.5, std_vel=std_vel, std_steer=std_steer)\n",
    "    ekf.x = array([[2, 6, 0.3]]).T  # x, y, steer angle\n",
    "    ekf.P = np.diag([0.1, 0.1, 0.1])\n",
    "    ekf.R = np.diag([std_range**2, std_bearing**2])\n",
    "\n",
    "    sim_pos = ekf.x.copy()  # simulated position\n",
    "    # steering command (vel, steering angle radians)\n",
    "    u = array([1.1, 0.01])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], marker=\"s\", s=60)\n",
    "\n",
    "    track = []\n",
    "    for i in range(2):\n",
    "        sim_pos = ekf.move(sim_pos, u, dt / 10.0)  # simulate robot\n",
    "        track.append(sim_pos)\n",
    "\n",
    "        if i % step == 0:\n",
    "            print(\"U\", u.shape)\n",
    "            ekf.predict(u=u)\n",
    "            print(\"x\", ekf.x.shape)\n",
    "\n",
    "            if i % ellipse_step == 0:\n",
    "                plot_covariance_ellipse(\n",
    "                    (ekf.x[0, 0], ekf.x[1, 0]),\n",
    "                    ekf.P[0:2, 0:2],\n",
    "                    std=6,\n",
    "                    facecolor=\"k\",\n",
    "                    alpha=0.3,\n",
    "                )\n",
    "\n",
    "            x, y = sim_pos[0, 0], sim_pos[1, 0]\n",
    "            for lmark in landmarks:\n",
    "                z = z_landmark(lmark, sim_pos, std_range, std_bearing)\n",
    "                ekf_update(ekf, z, lmark)\n",
    "\n",
    "            if i % ellipse_step == 0:\n",
    "                plot_covariance_ellipse(\n",
    "                    (ekf.x[0, 0], ekf.x[1, 0]),\n",
    "                    ekf.P[0:2, 0:2],\n",
    "                    std=6,\n",
    "                    facecolor=\"g\",\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "    track = np.array(track)\n",
    "    plt.plot(track[:, 0], track[:, 1], color=\"k\", lw=2)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"EKF Robot localization\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.show()\n",
    "    return ekf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
